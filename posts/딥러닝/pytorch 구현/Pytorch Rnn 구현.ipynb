{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title : pytorch로 Rnn구현하기\n",
    "author : 신호연\n",
    "date : 2022-12-24\n",
    "categories : [Deep learning]\n",
    "toc : true\n",
    "echo : true\n",
    "format :\n",
    "  html :\n",
    "    code-fold : false\n",
    "---\n",
    "hi?hi!가 반복되는 텍스트 데이터에서 다음 문자가 뭐가 나올지 예측하는 RNN모형 만들기\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "- raw sequence data가 다음과 같이 주어졌다고 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'i', '!', 'h', 'i', '?', 'h', 'i', '!', 'h']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "txt = list(\"hi!hi?\")*10\n",
    "map_dict = {'!':0, '?':1, 'h':2, 'i':3} \n",
    "txt[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- cleaning,tokenization(cleaning할 요소 없음,캐릭터 단위 모델링이므로 토큰화도 없음.둘 다 스킵)\n",
    "- vectorization\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorization\n",
    "- 여러가지 방법이 있으나(tf-idf,dense vector,one-hot encoding 등등...) 여기서는 원핫인코딩 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 0, 2, 3, 1, 2, 3, 0, 2]\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def mapping(txt,map_dict):\n",
    "    return [map_dict[chr]for chr in txt]\n",
    "txt_mapped = mapping(txt,map_dict)\n",
    "print(txt_mapped[:10])\n",
    "\n",
    "def onehot_encoding(txt_mapped):\n",
    "    seq_encoded = torch.nn.functional.one_hot(torch.tensor(txt_mapped))\n",
    "    return seq_encoded.float()\n",
    "sequence_data_encoded = onehot_encoding(txt_mapped)\n",
    "print(sequence_data_encoded[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 살짝 변형<br>\n",
    "하나의 긴 sequence data를 RNN의 입력으로 해도 되지만 처리속도,성능을 고려했을 때 자그마한 sequencedata로 분리하여 입력해주는게 더 좋은 방법임. 분리하는 방법도 여러가지가 있을 수 있겠는데 여기서는 다음과 같이 분리함<br><br>\n",
    "raw sequence data : hi?hi!hi?hi!hi?hi! ...........<br>\n",
    "sequence1 : (x,y) = (hi?,h)<br>\n",
    "sequence2 : (x,y) = (i?h,i)<br>\n",
    "sequence3 : (x,y) = (?hi,!)<br>\n",
    "...<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 3, 4]) torch.Size([57, 4])\n"
     ]
    }
   ],
   "source": [
    "def create_seqdataset(seq_data,seq_length):\n",
    "    #x = seq_data[:-1]\n",
    "    #y = seq_data[1:]\n",
    "    seqs_x = []\n",
    "    seqs_y = []\n",
    "    for idx in range(0,len(seq_data)-seq_length):\n",
    "        seqs_x.append(seq_data[idx:idx+seq_length])\n",
    "        seqs_y.append(seq_data[idx+seq_length])\n",
    "    return torch.stack(seqs_x),torch.stack(seqs_y)\n",
    "    #return seq_x,seq_y\n",
    "\n",
    "x_data,y_data = create_seqdataset(sequence_data_encoded,3)\n",
    "print(x_data.shape,y_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 저런 shape을 맞춰 주는가?\n",
    "여기서 나오는 x_data.shape = $(57,3,4)$가 살짝 난해함. <br>\n",
    "파이토치 공식문서에 따르면 batch_first = True로 설정할 경우,rnn계열의 모델에 넣어줘야 하는 텐서의 shape은 $(N,L,H_{in})$ = (batch size,sequnce length,input_size)이고 dataloader라는 일종의 데이터 중간관리자?를 한 번 거쳐서 모델에 입력됨. \n",
    "dataloader에서 나오는 output.shape = $(N,L,H_{in})$이 되기 위해서는 input.shape = $(D,L,H_{in}$(D는 분리된 시퀀스의 갯수)이어야 함(즉 입력텐서의 차원이 3개여야 출력텐서의 차원도3개이고 차원이 나오는 순서도 저런식이 되어야 함). 따라서 저렇게 설정함.<br><br>\n",
    "\n",
    "### 파라미터 잠깐 설명 \n",
    "batch size는 배치의 총 갯수(배치안에 있는 원소의 갯수 아님!), sequnce length는 시퀀스데이터의 길이이자 timestemp(시점)의 총 갯수(길이), $H_{in}$은 each timestep(각 시점)마다 입력되는 벡터의 길이라고 볼 수 있음. 위처럼 원핫인코딩을 한 경우 $H_{in}$은 시퀀스데이터에 있는 문자의 갯수로 결정되므로 4이고 L은 create_seqdataset함수에서 인수로 넣어준 3(sequnce_length)이고 마지막으로 N(batch_size)은 torch.utils.data.DataLoader안에 인수로 넣어주는 batch_size로 인해서 일정한 갯수로 배치를 나누었을때 나오는 배치들의 총 숫자임.rnn 문서에서 설명하는 batch_size는 torch.utils.dada.DataLoader에서 설정한 batch_size의 갯수만큼 데이터를 모아서 여러개의 배치로 만들었을때 나오는 배치의 총 갯수라고 보면됨.(헷갈리는 부분....)<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 준비하기\n",
    "- define architecture,loss,optimizer\n",
    "- data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture,loss,optimizer \n",
    "torch.manual_seed(2022)\n",
    "rnn = torch.nn.RNN(4,20,batch_first = True)\n",
    "linr = torch.nn.Linear(20,4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 4]) torch.Size([8, 4])\n",
      "torch.Size([8, 3, 4]) torch.Size([8, 4])\n",
      "torch.Size([8, 3, 4]) torch.Size([8, 4])\n",
      "torch.Size([8, 3, 4]) torch.Size([8, 4])\n",
      "torch.Size([8, 3, 4]) torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "ds = torch.utils.data.TensorDataset(x_data,y_data)\n",
    "dl = torch.utils.data.DataLoader(ds,batch_size=8,drop_last=True)\n",
    "\n",
    "for idx,(x,y) in enumerate(dl):\n",
    "    if idx ==5:\n",
    "        break\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 언급했듯이 데이터로더를 거쳐서 나오는 텐서는 RNN에 바로 입력될 것임.<br>\n",
    "input.shape = $(N,L,H_{in}) = (8,3,4)$<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모형학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0,loss : 1.31779\n",
      "epoch : 10,loss : 0.69453\n",
      "epoch : 20,loss : 0.19338\n",
      "epoch : 30,loss : 0.05891\n",
      "epoch : 40,loss : 0.02861\n",
      "epoch : 50,loss : 0.01791\n",
      "epoch : 60,loss : 0.0126\n",
      "epoch : 70,loss : 0.00947\n",
      "epoch : 80,loss : 0.00744\n",
      "epoch : 90,loss : 0.00602\n",
      "epoch : 100,loss : 0.00499\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,101):\n",
    "    for tr_x,tr_y in dl:\n",
    "        #1 output\n",
    "        hidden,hT = rnn(tr_x)\n",
    "        #print(hidden.shape)\n",
    "        output = linr(hT[-1])\n",
    "        #2 loss\n",
    "        loss = loss_fn(output,tr_y)\n",
    "        #3 derivative\n",
    "        loss.backward()\n",
    "        #4 update & clean\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch : {epoch},loss : {round(loss.tolist(),5)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch의 rnn을 거쳐서 나오는 output은 두 가지임.<br>\n",
    "- hidden : 가장 깊이 위치한 히든레이어의 각각의 시점에서의 출력값을 모아놓은 텐서<br>\n",
    "- hT : 모든 히든레이어에의 마지막 시점(시점T)에서의 출력값을 모아놓은 텐서<br>\n",
    "- 외우기! 위치 : 가장깊은 <=> 모든 , 시점 : 각각의 <=> 마지막<br>\n",
    "\n",
    "위와같은 설정에서는 가장 깊이 위치한 히든레이어의 마지막시점에서의 출력값만이 우리는 다음에올 문자열을 예측할 때 필요하므로 hT[-1]을 하여 그 값을 가져옴."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1e2e192cdf0>,\n",
       "  <matplotlib.axis.XTick at 0x1e2e192cdc0>,\n",
       "  <matplotlib.axis.XTick at 0x1e2e1961ee0>,\n",
       "  <matplotlib.axis.XTick at 0x1e2e197c970>],\n",
       " [Text(0, 1, '!'), Text(1, 1, '?'), Text(2, 1, 'h'), Text(3, 1, 'i')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "\n",
    "hidden,hT = rnn(x_data)\n",
    "plt.matshow(soft(linr(hT[:,:,:])[0]).data[-30:],cmap=\"bwr\",vmin=-1,vmax=1)\n",
    "plt.xticks(range(4),labels=map_dict.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0478b8cb1c47bafb71305148a49d30528a4d9c22ca2de336c01aa5a8230a459a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
