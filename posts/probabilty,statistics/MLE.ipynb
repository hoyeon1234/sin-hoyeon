{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "author: 신호연\n",
    "date: 2022-12-29\n",
    "title: 최대가능도 추정법(MLE)\n",
    "format: html\n",
    "categories: [probability&statistics]\n",
    "---\n",
    "최대가능도 추정법(MLE)에 대한 정리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelyhood(가능도)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모수의 가능도(Likelyhood)는 어떤 모숫값(parameter)$\\theta$을 가정했을때,데이터(샘플,실현)가 가능성(확률,확률밀도)을 나타냅니다. 일반적으로 $\\theta$에 따라서 변하는 함수이기에 가능도함수라고도 합니다.수학적으로 표현하면 다음과 같습니다.<br>\n",
    "\n",
    "\\begin{aligned}\n",
    "&\\text{Suppose}\\,(x_1,x_2,...,x_n)\\ \\text{are a realization of a random sample }(X_1,X_2,\\dots,X_n) \\\\\n",
    "&\\text{where,}\\, X_1 \\sim f_1(x;\\theta),X_2 \\sim f_2(x;\\theta),\\dots,X_n \\sim f_n(x;\\theta) \\\\\\\\\n",
    "\n",
    "&\\large{\\text{likelyhood function}}\\,L(\\theta) \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "\\begin{aligned}\n",
    "L(\\theta|X_1 = x_1,X_2 = x_2,\\dots,X_n = x_n) &= p_{X_1,X_2,\\dots,X_n}(x_1,x_2,\\dots,x_n|\\theta) \\\\\n",
    "&= \\overset{i=n}{\\underset{i=1}{\\large{\\Pi}}}f_i(x_i)\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "주어진 샘플에 대한 확률(또는 확률밀도)은 $Y_1 = y_1,Y_2 = y_2 \\dots Y_n = y_n$인 사건이 동시에 일어날 결합확률(확률밀도)입니다. 그러므로 가능도 = 동시에 뽑일 가능성(확률,확률밀도) = 결합확률이라고 할 수 있습니다.\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE(최대가능도 추정법)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최대가능도추정법(MLE)는 확률분포의 모수를 추정하는 점추정방법 중 하나로 가능도를 가장크게하는 모숫값을 모수에 대한 추정값 하는 방법입니다.다음과 같습니다.<br>\n",
    "\n",
    "\\begin{aligned}\n",
    "\\hat{\\theta}_{MLE} &= \\underset{\\theta}{\\text{argmax}}\\,L(\\theta|X_1 = x_1,X_2 = x_2 \\dots X_n = x_n) \\\\\n",
    "&=  \\underset{\\theta}{\\text{argmax}},p_{X_1,X_2,\\dots,X_n}(x_1,x_2,\\dots,x_n|\\theta) \\\\\n",
    "&= \\underset{\\theta}{\\text{argmax}}\\,\\overset{i=n}{\\underset{i=1}{\\large{\\Pi}}}f_i(x_i)\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LL은 log likelyhood의 약자로 likelyhood에 log를 취해준 값입니다. 로그함수를 취해도 함수가 MLE의 계산결과(가능도가 최대인 모수에 대한 추정값)의 위치가 변하지 않고 계산을 곱셈을 더하기로 바꿔서 계산하기에 더 편리하기 때문에 LL을 사용합니다.<br>\n",
    "$$LL = \\text{ln }L(\\theta|X_1 = x_1,X_2 = x_2 \\dots X_n = x_n)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLL은 LL에 -(negative)를 곱해준 값입니다. 함수가 최대인 지점을 찾는 문제를 최소인 지점을 찾는 문제로 바꿀 수 있습니다.(주로 최적화에서 이런 방식을 많이 사용합니다.)\n",
    "$$NLL = -\\text{ln }L(\\theta|X_1 = x_1,X_2 = x_2 \\dots X_n = x_n)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리 - MLE\n",
    "MLE를 통해서 모수에 대한 추정량을 구하면 다음과 같습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\hat{\\theta}_{MLE} &= \\underset{\\theta}{\\text{argmax}}\\,L(\\theta|X_1 = x_1,X_2 = x_2 \\dots X_n = x_n)\\\\\n",
    "&= \\underset{\\theta}{\\text{argmax}},p_{X_1,X_2,\\dots,X_n}(x_1,x_2,\\dots,x_n|\\theta) \\\\\n",
    "&= \\underset{\\theta}{argmin}\\,-\\text{ln}\\,L(\\theta|X_1=x_1,X_2=x_2\\dots X_n=x_n)\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[링크1(random sample vs random variable)](https://stats.stackexchange.com/questions/239500/what-is-the-difference-between-random-variable-and-random-sample)<br>\n",
    "[링크2(추정,추정량,추정값)](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=soohwan2-&logNo=100200023641)<br>\n",
    "[링크3(mle)](https://angeloyeo.github.io/2020/07/17/MLE.html)\n",
    "[링크4(mle)](https://datascienceschool.net/02%20mathematics/09.02%20%EC%B5%9C%EB%8C%80%EA%B0%80%EB%8A%A5%EB%8F%84%20%EC%B6%94%EC%A0%95%EB%B2%95.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0478b8cb1c47bafb71305148a49d30528a4d9c22ca2de336c01aa5a8230a459a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
