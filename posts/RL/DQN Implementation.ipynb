{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1e455b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(20000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9812d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a8ebc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d5f960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00834963, -0.0212837 ,  0.00747146, -0.0150546 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,_ = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2fc4c6",
   "metadata": {},
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dfde68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\"replay_memory\",[\"state\",\"action\",\"next_state\",\"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4a2929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self,capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "    def push(self,*args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    def sample(self,N):\n",
    "        return random.sample(self.memory,N)\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3653298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self,n_observations,n_actions):\n",
    "        \"\"\"\n",
    "        Input\n",
    "        n_observations : int\n",
    "        length of observation vector, the number of observed values\n",
    "        n_action : int\n",
    "        the number of actions which are possible to take in that state\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(n_observations,128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(128,64)\n",
    "        #relu\n",
    "        self.layer3 = nn.Linear(64,32)\n",
    "        #relu\n",
    "        self.layer4 = nn.Linear(32,16)\n",
    "        #relu\n",
    "        self.layer5 = nn.Linear(16,n_actions)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Input : tensor\n",
    "            4-dimensional observation vector\n",
    "        output : tensor\n",
    "            2-dimensional Q_values\n",
    "        \"\"\"\n",
    "        out = self.relu(self.layer1(x)) #l1_out\n",
    "        out = self.relu(self.layer2(out)) #l2_out\n",
    "        out = self.relu(self.layer3(out)) #l3_out\n",
    "        out = self.relu(self.layer4(out))\n",
    "        out = self.layer5(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "#_ob = torch.tensor([1.2,1.5,2.9,3.88])\n",
    "#net(_ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "304d79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "ϵ_START = 1\n",
    "ϵ_END = 0.005\n",
    "ϵ_DECAY = 0.0001\n",
    "TAU = 0.005\n",
    "\n",
    "steps_done = 0\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = ϵ_END + (ϵ_START - ϵ_END) * math.exp(-1 * steps_done / ϵ_DECAY) \n",
    "    #1. ϵ의 upper bound, lower bound를 부여\n",
    "    #2. EPS_DECAY의 비율만큼 서서히 감쇄\n",
    "    #※ ϵ_DECAY 비율에 의해서 ϵ이 너무 빨리 떨어져서 exploration이 조기에 종료될 수 있음.\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        \"\"\"\n",
    "        1-ϵ확률로 greedy하게\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1,1)\n",
    "        #max(1) : dimension을 반영하여 최댓값을 알려줌, 최댓값(value)와 위치(index)를 포함\n",
    "        #max(1)[1] : index만 가져옴\n",
    "        #max(1)[1].view(1,1) : 차원변환\n",
    "    elif sample <= eps_threshold:\n",
    "        \"\"\"\n",
    "        ϵ의 확률로 random action\n",
    "        \"\"\"\n",
    "        return torch.tensor([[env.action_space.sample()]],device=device, dtype = torch.long)\n",
    "        #exploration\n",
    "    if steps_done % 50 == 0:\n",
    "        print(steps_done,epsilon_threshold)\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # 도표가 업데이트되도록 잠시 멈춤\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c33e409",
   "metadata": {},
   "source": [
    "\\begin{case}\n",
    "L(\\theta_i) = r + \\gamma \\text{max}_{a'} Q(S_{t+1},a';\\theta^-) - Q(S_{t},A_t;\\theta) $$\n",
    "hi\n",
    "\\end{d}{case}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d34237",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ReplayMemory(10000)\n",
    "policy_net = DQN(4,2).to(device) #policy network\n",
    "target_net = DQN(4,2).to(device) #target network\n",
    "target_net.load_state_dict(policy_net.state_dict()) #몰랐던 부분\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(),lr=0.001,amsgrad=True)\n",
    "criterion = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce0088d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        \"\"\"\n",
    "        buffer에 있는 transition이 BATCH_SIZE보다 적으면 학습 X.\n",
    "        \"\"\"\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    state_batch = torch.cat(batch.state,axis=0)\n",
    "    action_batch = torch.cat(batch.action,axis=0)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    #현재 Q값 계산\n",
    "    Q = policy_net(state_batch).gather(1,action_batch)\n",
    "    \n",
    "    #Q-target 계산\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s : s is not None,batch.next_state)),device=device,dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None],axis=0).to(device).type(torch.float32)\n",
    "    max_q = torch.zeros(BATCH_SIZE,device=device)\n",
    "    with torch.no_grad():\n",
    "        max_q[non_final_mask] = target_net(non_final_next_states).max(dim=1).values #max_q\n",
    "    Q_targets = (max_q * GAMMA) + reward_batch\n",
    "    loss = criterion(Q,Q_targets.unsqueeze(1))\n",
    "    print(\"loss :\",loss)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(),100)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "optimize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44bd53fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4216\\4197008751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#print(s1,state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#count(),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mterminated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtruncated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4216\\3345034595.py\u001b[0m in \u001b[0;36mselect_action\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \"\"\"\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;31m#max(1) : dimension을 반영하여 최댓값을 알려줌, 최댓값(value)와 위치(index)를 포함\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#max(1)[1] : index만 가져옴\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4216\\1904813899.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;36m2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mQ_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \"\"\"\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#l1_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#l2_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#l3_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "for i_episode in range(5000):\n",
    "    s1 = torch.tensor(env.reset()[0],device=device,dtype = torch.float32).unsqueeze(0) #전처리는 없음\n",
    "    state = s1\n",
    "    #print(s1,state)\n",
    "    for t in count(): #count(),\n",
    "        action = select_action(state)\n",
    "        observation,reward,terminated,truncated,_ = env.step(action.item())\n",
    "        \n",
    "        reward = torch.tensor(reward,device=device,dtype=torch.float32).view(1)\n",
    "        done = terminated or truncated\n",
    "        #terminal state에 도달하거나 timelimit따위로 episoder가 끝날때 done = True\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation,dtype=torch.float32,device=device).unsqueeze(0)\n",
    "        \n",
    "        #메모리에 변이 저장\n",
    "        \"\"\"\n",
    "        next_state = None,reward = 1 if terminated == True\n",
    "        next_state = arbitary,reward = 1 o.w\n",
    "        \"\"\"\n",
    "        memory.push(state,action,next_state,reward)\n",
    "        \n",
    "        optimize_model()\n",
    "        #다음 상태로 이동\n",
    "        state = next_state\n",
    "        \n",
    "        \"\"\"\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "        \"\"\"\n",
    "    print(\"last time step : {t}\")\n",
    "    if i_episode % 50 == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e135f87",
   "metadata": {},
   "source": [
    "# Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab4273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_not_none(s):\n",
    "    return s is not None\n",
    "is_not_none(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7b2b8",
   "metadata": {},
   "source": [
    "# map function(function,iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd745fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "d = map(lambda s : s + 1,[1,2,3,4])\n",
    "for i in d:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba90a5",
   "metadata": {},
   "source": [
    "# zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4a605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a', True), (2, 'b', False), (3, 'c', False), (4, 'd', True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*[[1,2,3,4],[\"a\",\"b\",\"c\",\"d\"],[True,False,False,True]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3de1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
