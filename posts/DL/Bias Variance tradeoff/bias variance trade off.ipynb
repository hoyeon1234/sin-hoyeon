{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"[Probability & Statistics] Bias Variance tradeoff\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\"> **Bias Variancce Tradeoff**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `supervised learning`의 목적 중 하나는 unknown data에 대해서 `generalization`을 잘 하도록 모델을 학습시키는 것입니다.\n",
    "- 이는 `expected generalization error`에 포함하는 `bias`와 `variance`를 줄이도록 학습하는 것입니다.\n",
    "- 그러나 학습과정에서 `bias`와 `variance`는 서로간에 상충합니다. \n",
    "- 다시말하면 , `bias`가 작아지면 `variance`는 커지고 `variance`가 작아지면 `bias`가 커지는 `bias variance tradeoff` 현상이 나타납니다.\n",
    "- bias와 variance를 조금 구체적으로 살펴보면 다음과 같습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bias**\n",
    "\n",
    "- `bias`는 학습알고리즘에서의 잘못된 가정으로 인해 발생하는 `오류`이다.<br> \n",
    "- `High bias`는 학습알고리즘이 training data의 **feature와 target간의 `regularities` 를 놓치게 합니다.**(`underfitting의 원인`)<br>\n",
    "- 이는 **`unknown data`에 대해서 `generalization error`가 나오게** 합니다.\n",
    "\n",
    "**vairance**\n",
    "\n",
    "- `variance`는 훈련데이터에서의 작은 변동에 학습알고리즘이 민감하게 반응하여 발생하는 `오류`이다.<br>\n",
    "- `High variance`는 학습알고리즘이 training data에 있는 **feature와 target간의 `regularities` 를 너무 과하게 학습하게 합니다.**(`overfitting의 결과`)\n",
    "- 마찬가지로 이는 **`unknown data`에 대해서 `generalization error`가 나오게** 합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./bias%20variance%20tdoff%20.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1번그림\n",
    "\n",
    "- bias가 작아서 알고리즘이 어떤 방향으로 편향되지 않습니다.\n",
    "- variance또한 작아서 데이터의 변화에 의한 학습된 알고리즘의 변동,편차는 거의 없습니다.\n",
    "- 전체적으로 bias,variance가 작기 때문에 학습된 알고리즘은 True값에 가깝습니다.\n",
    "\n",
    "2번그림\n",
    "\n",
    "- bias가 크기 때문에 오른쪽 방향으로 편향되어 있습니다.<br>\n",
    "- variance는 작아서 데이터의 변화에 의한 학습된 알고리즘의 변동,편차는 거의 없습니다.<br>\n",
    "\n",
    "3번그림\n",
    "\n",
    "- bias가 작아서 어떤 방향으로 편향되지 않습니다. \n",
    "- variance는 크기때문에 작은 데이터의 변화에 의한 학습된 알고리즘의 성능변화가 매우 심합니다.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\"> **Bias,Variancce trade off**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- supervise learning의 목적은 unknown data에 대해서 잘 **generalization**된 모델을 생성하는 것입니다.\n",
    "- 따라서 에러에 해당하는 **`bias`와 `variance`를 모두 최소화해야 합니다.**\n",
    "- 그러나 **에러를 최소화 과정에서 서로간의 `상충(coflict)`이 발생**하는데 이를 `Bias Variance trade off`라 합니다.\n",
    "- 길게 풀어쓰자면 `bias`가 감소하면 `variance`는 증가하고 `variance`가 증가하면 `bias`가 증가한다는 것입니다.\n",
    "- `bias-variance decomposition`은 `bias`,`variance`,`irreducible error`로 구성되는 학습알고리즘의 `expected generalization error`를 살펴봄으로서 학습알고리즘을 분석하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
