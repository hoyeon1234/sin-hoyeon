{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"[Probability & Statistics] Bias Variance Tradeoff\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\"> **Bias Variancce Tradeoff**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\"> **Intuition**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `supervised learning`의 목적 중 하나는 unknown data에 대해서 `generalization`을 잘 하도록 모델을 학습시키는 것입니다.\n",
    "- 이는 `expected generalization error`에 포함하는 `bias`와 `variance`를 줄이도록 학습하는 것과 같습니다..\n",
    "- 그러나 학습과정에서 `bias`와 `variance`는 서로간에 상충합니다. \n",
    "- 풀어쓰자면 `bias`가 작아지면 `variance`는 커지고 `variance`가 작아지면 `bias`가 커지는 `bias variance tradeoff` 현상이 나타납니다.\n",
    "- bias와 variance를 조금 구체적으로 살펴보면 다음과 같습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bias**\n",
    "\n",
    "- `bias`는 학습알고리즘에서의 잘못된 가정으로 인해 발생하는 `오류`입니다.<br> \n",
    "- `High bias`는 학습알고리즘이 **feature와 target간의 `regularities` 를 놓치게 합니다.**(`underfitting의 원인`)<br>\n",
    "- 이는 **`unknown data`에 대해서 `generalization error`가 나오게** 합니다.\n",
    "\n",
    "**vairance**\n",
    "\n",
    "- `variance`는 훈련데이터에서의 작은 변동에 학습알고리즘이 민감하게 반응하여 발생하는 `오류`입니다.<br>\n",
    "- `High variance`는 학습알고리즘이 **feature와 target간의 `regularities` 를 너무 과하게 학습해서 발생합니다.**(`overfitting의 결과`)\n",
    "- 마찬가지로 이는 **`unknown data`에 대해서 `generalization error`가 나오게** 합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./bias%20variance%20tdoff%20.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1번그림\n",
    "\n",
    "- bias가 작아서 알고리즘이 어떤 방향으로 편향되지 않습니다.\n",
    "- variance또한 작아서 데이터의 변화에 의한 학습된 알고리즘의 변동,편차는 거의 없습니다.\n",
    "- 전체적으로 bias,variance가 작기 때문에 학습된 알고리즘은 True값에 가깝습니다.\n",
    "\n",
    "2번그림\n",
    "\n",
    "- bias가 크기 때문에 오른쪽 방향으로 편향되어 있습니다.<br>\n",
    "- variance는 작아서 데이터의 변화에 의한 학습된 알고리즘의 변동,편차는 거의 없습니다.<br>\n",
    "\n",
    "3번그림\n",
    "\n",
    "- bias가 작아서 어떤 방향으로 편향되지 않습니다. \n",
    "- variance는 크기때문에 작은 데이터의 변화에 의한 학습된 알고리즘의 성능변화가 매우 심합니다.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\"> **Derivation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:black\"> **Background**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 통계학에서 데이터는 다음과 같은 `additive error model`로부터 sampling됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C ����̺��� �������� �̸��� �����ϴ�.\n",
      " ���� �Ϸ� ��ȣ: 00AF-E1BD\n",
      "\n",
      " c:\\Users\\22668\\Desktop\\github\\sin-hoyeon\\posts\\DL\\Bias Variance tradeoff ���͸�\n",
      "\n",
      "2023-03-23  ���� 04:21    <DIR>          .\n",
      "2023-03-22  ���� 10:00    <DIR>          ..\n",
      "2023-03-19  ���� 09:39           411,691 bias variance tdoff .png\n",
      "2023-03-23  ���� 04:21             6,023 bias variance trade off.ipynb\n",
      "2023-03-20  ���� 05:05             2,074 Untitled-1.py\n",
      "               3�� ����             419,788 ����Ʈ\n",
      "               2�� ���͸�  134,020,882,432 ����Ʈ ����\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m .\n",
    "!git push\n",
    "!quarto publish --no-prompt --no-browser "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&y = f(x) + \\epsilon ,\\,\\, \\epsilon \\overset{\\text{i.i.d}}{\\sim} \\mathcal{N}(0,\\sigma^2)\\\\\n",
    "&\\text{where} \\\\\n",
    "&f(x) : \\text{target function that we are trying to learn,but do not really know} \\\\\n",
    "&\\epsilon : \\text{statistical error}\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $f(x)$는 모집단에서 두 변수 $x,y$사이의 관계를 대표하는 곡선이며 우리가 학습 알고리즘을 통해 찾고자 하는 target function입니다.\n",
    "- target function을 찾게되면 우리는 unknown data에 대해서도 좋은 결과를 얻을 수 있습니다.(good generalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\"> **Derivation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `bias-variance decomposition`은 `bias`,`variance`,`irreducible error`로 구성되는 학습알고리즘의 `expected generalization error`를 살펴봄으로서 학습알고리즘을 분석하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
