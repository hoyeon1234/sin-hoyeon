{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "author: 신호연\n",
    "date: 2023-02-08\n",
    "title: \"[Linear Algebra] 6-3.EVD of symmetric matrix\"\n",
    "format: html\n",
    "categories: [Linear Algebra]\n",
    "image: ./Linear_subspaces_with_shading.svg\n",
    "---\n",
    "수튜브님의 직교대각화가능(orthogonal diagonalizability)을 보고 정리한 내용입니다.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전지식"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthonormal matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear algebra, an orthogonal matrix, or orthonormal matrix, is a real square matrix whose columns and rows are orthonormal vectors. (from wikipedia)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행벡터들과 열벡터들이 orthogonal(직교) + normal(크기가 1)인 정사각행렬을 orthonormal matrix라 한다.\n",
    "- orthogonal matrix 또는 orthonormal matrix는 같은 표현이다.\n",
    "- 그러나 직교 + 크기가 1인 벡터가 열벡터이기에 orthogonal + normal = orthonormal이 더 의미를 살리는 듯하여 여기서는 `orthonormal matrix`용어를 사용한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expression 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orthonormal matrix $Q$을 나타내는 첫 번째 표현은 아래와 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&Q^TQ = QQ^T = I \\\\\n",
    "&\\text{where } I \\text{ is the identity matrix}\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 왜 저런 표현식이 나올까? \n",
    "- 이는 정의를 함축하고 아주 잘 함축하고 있는 표현이다.\n",
    "- 임의의 $Q \\in \\mathbb{R}^{n \\times n}$가 다음과 같다고 해보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&Q = \n",
    "\\begin{bmatrix}\n",
    "q_1 & q_2 & \\dots q_n\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서 $q_i \\in \\mathbb{R}^{n \\times 1}(i=1,2,\\dots,n)$은 $Q$의 column vector이다. \n",
    "- 먼저 $Q^TQ = I$를 확인해보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "Q^TQ =\n",
    "\\begin{bmatrix}\n",
    "q_1^T \\\\ q_2^T \\\\ \\vdots \\\\ q_n^T\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "q_1 & q_2 & \\dots & q_n\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "q_1^T,q_1 & q_1^Tq_2 & \\dots & q_1^Tq_n \\\\\n",
    "q_2^T,q_1 & q_2^Tq_2 & \\dots & q_2^Tq_n \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "q_n^T,q_1 & q_n^Tq_2 & \\dots & q_n^Tq_n\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & \\dots & 0\\\\\n",
    "0 & 1 & \\dots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\dots & 1\\\\\n",
    "\n",
    "\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 좌우변이 같기때문에 아래가 유도된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "q_i^Tq_j = \n",
    "\\begin{cases}\n",
    "1 \\quad (i = j)\\\\\n",
    "0 \\quad (\\text{otherwise})\n",
    "\\end{cases}\n",
    "\\text{for all }i \\in (1,\\dots,n),\\,j \\in (1,\\dots,n)\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이는 같은 벡터끼리 내적을 하면 1이고  다른벡터끼리 내적하면 0임을 의미한다.\n",
    "- 즉, 임의의 벡터$q_i$의 크기는 1인 unit vector이며 열벡터들은 orthogornal 하다는 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&\\text{for all }i \\in (1,...,n), j \\in (1,...,n) \\\\\n",
    "&|q_i| = \\sqrt{q_i} = \\sqrt{dot(q_i,q_i)} = 1 \\\\\n",
    "&dot(q_i,q_j)=0 \\longleftrightarrow q_i\\perp q_j\n",
    "\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 동일한 과정을 행벡터에 대해서도 수행하면 행벡터들도 orthonormal하다는 것을 보일 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expression 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- expression1으로부터 orthonormal matrix에 관한 다음의 식도 끌어낼 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&Q^T = Q^{-1} \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 즉,어떤 행렬의 transpose가 그것의 inverse와 같으면 orthonormal matrix라는 것이며 이것또한 orthonormal matrix의 다른 표현이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 왜 그런가 하면 expression1에서 $Q^TQ = QQ^T = I$였다. 그러므로 $Q$의 역행렬$Q^{-1}$는 $Q^T$와 같다.<br>\n",
    "(Q의 역행렬은 $Q^{-1}Q = QQ{-1} = I$를 만족하는 행렬이다.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## orthogonally similar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음과 같은 식을 만족하면 C는 A와 orthogonally similar(직교닮음)이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&C = Q^{-1}AQ \\\\\n",
    "&\\text{where } Q^{-1} = Q^T\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서 $Q^{-1} = Q^T$는 orthonomal matrix의 정의이다.\n",
    "- 윗 식에 의해서 A도 C와 orthogonally similar임을 이끌어낼 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&A = QCQ^{-1} \\\\\n",
    "&\\text{where } Q^{-1} = Q^T\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## orthogonally diagonalize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임의의 정사각행렬 $A,D$에 대해서 다음이 만족한다고 해보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&\n",
    "\\begin{aligned}\n",
    "D &= Q^{-1}AQ \\\\\n",
    "&= Q^TAQ \\\\\n",
    "\\end{aligned}\n",
    "\\\\\n",
    "&\\text{where } D = diag(d_1,d_2,\\dots,d_n) , Q^{-1} = Q^T\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이와 같이 $A$와 직교닮음인 대각행렬 $D$가 존재할때 행렬$A$가 직교대각화 되었다 라고 한다.\n",
    "- 또한 이때 정사각행렬 $A$는 $P^{-1}AP$가 대각행렬$D$가 되게하는 가역행렬이자 orthornomal matrix인 $P$가 존재하기때문에 \"행렬$A$는 orthogonally diagonalizable하다\"라고 말한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $Q^T$와 $Q$의 자리를 바꿔서 써도 된다. 즉 $Q^{-1}$를 새로운 Q로 본다면 다음과 같이 적을 수도 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "D &= QAQ^{-1}\\\\\n",
    "&= QAQ^T\\\\\n",
    "&\\text{where } D = \\text{diag}(d_1,d_2,\\dots,d_n),Q^{-1} = Q^T\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단지 notation의 차이일 뿐이다. 역행렬의 관계이기 때문이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 매우 중요한 정리<br>$A$가 대칭행렬이다 $\\Longleftrightarrow A$가 orthogonally diagonalizable하다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 두 명제가 동치임을 보이기 위해 다음 두 정리를 증명한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 명제1 : $A$가 orthogonally diagonalizable $\\rightarrow A = A^T$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬$A$가 orthogonally diagonalizable하다고 하자. 즉 $D = P^TAP$를 만족하는 직교행렬 $P$가 존재한다. 이때 $A^T$를 전개하면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&A = PDP^{-1} = PDP^T\\\\\n",
    "&A^T = (PDP^T)^T = PD^TP^T = PDP^T = A\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 명제2 : $A = A^T \\rightarrow$ $A$는 orthogonally diagonalizable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수학적 귀납법으로 아래의 두 가지를 증명하면 된다.\n",
    "    - $A \\in \\mathbb{R}^{1 \\times 1}$ 일때 직교대각화가 가능하다.(1)\n",
    "    - $A \\in \\mathbb{R}^{(n-1)\\times (n-1)}$때 직교대각화가 가능하다고 가정하고 $A \\in \\mathbb{R}^{n \\times n}$때 직교대각화가 가능함을 보인다.(2)\n",
    "    - 임의의 $n$ 그리고 $n-1$에 대해서 성립함을 증명했고 1에대해서 증명했기 때문에 ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&\\mathbb{R}^{1 \\times 1} \\rightarrow \\mathbb{R}^{2 \\times 2}\\\\\n",
    "&\\mathbb{R}^{2 \\times 2} \\rightarrow \\mathbb{R}^{3 \\times 3}\\\\\n",
    "&\\mathbb{R}^{3 \\times 3} \\rightarrow \\mathbb{R}^{4 \\times 4}\\\\\n",
    "&\\quad\\quad\\quad\\vdots\\\\\n",
    "&\\mathbb{R}^{n-1 \\times n-1} \\rightarrow \\mathbb{R}^{n \\times n}\\\\\n",
    "&\\quad\\quad\\quad\\vdots\\\\\n",
    "\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이렇게 증명하면 모든 $n$ 결국은 모든 대각행렬에 대해서 직교대각화가 가능함을 보일 수 있다.\n",
    "- 느낌\n",
    "    - 하나의 증명을 위해서 모든 자연수에 대해 딸려있는 증명들을 해야되네?! $\\rightarrow$ 작은 것부터 차례차례 쓰러뜨려보자! $\\rightarrow$ 작은거 하나하나 다하기 힘드니까 임의의 n에 대해서 해보자.!\n",
    "    - (1)을 증명하고 (2)만 증명하면 모든 n에 대해서 증명할 수 있어서 (2)를 증명해서 뚫는 느낌.\n",
    "    - 도미노 : 하나를 쓰러뜨리면 그 다음이 쓰러지는 것을 알고있어(증명했어). 증명해야 될 문제는 맨 처음부터 맨 마지막까지 전부 쓰러뜨리면 되는문제야. 맨 처음이 무너진다면 다음에 오는 모든 것들이 무너질꺼야. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 $A \\in \\mathbb{R}^{1 \\times 1}$ 일때 직교대각화가 가능함을 보인다. 먼저 $A$와 $P$행렬을 잡는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&A = \\begin{bmatrix}a\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{1 \\times 1} \\\\\n",
    "&P = \\begin{bmatrix}1\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{1 \\times 1}\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $A=A^T$인 대칭행렬이며 $P$의 경우 $P^{-1} = P^T$가 성립하는 orthonomal matrix이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "D = P^{-1}AP = \\begin{bmatrix}a\\end{bmatrix}\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D는 대각행렬이다. 따라서 $D = P^{-1}AP$를 만족하는 가역행렬이자 직교행렬인$P$와 대각행렬$D$가 존재하므로 행렬$A \\in \\mathbb{R}^{1 \\times 1}$는 orthogonally diagonalizable하다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- D는 대각행렬이다. 따라서 $D = P^-1AP$를 만족하는 가역행렬이자 직교행렬인$P$와 대각행렬$D$가 존재하므로 행렬$A \\in \\mathbb{R}^{1 \\times 1}$는 orthogonally diagonalizable하다.\n",
    "- 정리2 자세한 증명 생략...\n",
    "- **따라서 어떤 행렬이 대칭행렬 $\\Longleftrightarrow$직교대각화가 가능하다.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVD of symmetric matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Symmetric matrix $A = A^T \\in \\mathbb{R}^{n \\times n}$의 경우의 EVD는 조금 특별하다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&A = V\\Lambda V^{-1}\\\\\n",
    "&A^T = V^{-T}\\Lambda^T V^{T} = V^{-T}\\Lambda V^{T}\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위와 같이 전개가 된다.\n",
    "- 여기서 $A = A^T$임을 사용하면..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&A = A^T\\\\\n",
    "&\\Longrightarrow V\\Lambda V^{-1} = V^{-T}\\Lambda V^{T}\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 윗 식을 만족하는 $V$는 $V^{-1} = V^T$인 orthonormal matrix이다.\n",
    "    - 엄밀하게는 $V$는 $V^{-1} = V^T$ orthonormal matrix가 될 수 있다가 맞는 것 같다.\n",
    "    - 느낌상 맨위의 표현으로 기억하고 익숙하다면 좀 더 세부적으로 기억해보자.\n",
    "    - 예시 : [반드시 직교대각화만 되는 건 아니다?!링크넣기](dsad),orthogonally diagonolizable 참고\n",
    "- 이는 무엇을 의미할까? $\\to V^{-1}$를 찾는 번거로움이 줄어든다.\n",
    "    - 원래의 EVD라면 $V$를 구하고 $V^{-1}$를 따로 구해줘야 한다.(역행렬 구하는 것이 쉽지많은 않을 것이다.특히 차원이 커질수록!)\n",
    "    - Symmetric하다면 $V$를 구하고 transpose만 취해주면 된다.\n",
    "- 즉 Symmetric하다면 고윳값분해는 다음과 같다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = V\\Lambda V^{-1} = V \\Lambda V^T$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orthonormal matrix를 보통 Q로 많이 적으므로 여기서부터는 $V$를 $Q$로 적겠다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric matrix의 EVD와 orthogonally diagonalizable의 연관성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 잠깐 넘어가기 전에 중요한 중요한 사실 하나를 짚고 넘어가자.\n",
    "- 우리는 정리를 통해서 Symmetric matrix는 직교대각화가 가능하다는 사실을 알고 있다.\n",
    "- 하지만 이러한 사실만 알고있을뿐 실제로 어떻게 $P$와 $D$를 구하는지는 알지 못했다.\n",
    "- 대칭행렬의 경우 직교대각화는 EVD를 통해 구현할 수 있다. 이는 정방행렬의 경우와 유사하다.(정방행렬의 EVD와 orthogonally diagonalizable 참고)\n",
    "    - 정방행렬의 경우 대각화는 EVD를 통해서 구현할 수 있었다.\n",
    "    - 대칭행렬의 경우 직교대각화는 EVD에서 $V^{-1} = V^T$인 V가 구해지기에 구현할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신기하고 중요한 사실들"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신기한 사실1 : 대칭행렬 A는 rank1 매트릭스들의 가중합으로 표현할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- EVD를 계속해서 전개해보면 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "A &= V\\Lambda V^T = \n",
    "\\begin{bmatrix}\n",
    "q_1 & q_2 & q_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\lambda_1 & 0 & 0 \\\\\n",
    "0 & \\lambda_2 & 0 \\\\\n",
    "0 &  0 & \\lambda_3\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "q_1^T \\\\ q_2^T \\\\ q_3^T\n",
    "\\end{bmatrix}\n",
    "=\n",
    "&\\begin{bmatrix}\n",
    "\\lambda_1q_1 & \\lambda_2q_2 & \\lambda_3q_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "q_1^T \\\\ q_2^T \\\\ q_3^T\n",
    "\\end{bmatrix}\\\\\n",
    "&= \\lambda_1q_1q_1^T + \\lambda_2q_2q_2^T + \\lambda_3q_3q_3^T = \n",
    "\\sum_{i=1}^3 \\lambda_iq_iq_i^T\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서부터 재미난 사실을 알 수 있다.\n",
    "- $q_iq_i^T$는 rank가 1인 matrix이다.\n",
    "- 마지막 수식은 이러한 rank-1 matrix들을 적절하게 상수배하고 더하여 합을 취하면 $A$가 나온다는 것이다. 상수가 각각에 대응하는 rank-1 matrix $q_iq_i^T$의 중요도,기여도를 고려한 가중치라고 생각한다면?\n",
    "- 다음과 같은 해석을 할 수 있다.\n",
    "    - 어떤 정방행렬$A$는 여러개의 rank-1 matrix들이 섞인거야.\n",
    "    - 그런데 그냥 섞인건 아니고 중요한건 많이 안중요한건 적게 섞은 것이 정방행렬이야!\n",
    "    - 그때의 중요도는 $\\lambda_i$가 알려줘."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그림으로 보면 이런느낌이다.!\n",
    "그림"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 만약에 데이터의 크기가 너무 커서 압축을 해야하는 상황이라면 이를 응용할 수 있다.\n",
    "    - 이미지의 크기가 너무크다. 조금 사이즈를 줄이고 싶다.\n",
    "    - 중요도 $\\lambda_i$가 상대적으로 작은 matrix들은 조금 제외를 해도 괜찮겠지? \n",
    "    - 실제로 된다. 조금 줄여도 여전히 인식할 수 있는 정도이다.(조금 화질이 안좋아지긴 한다.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신기한 사실2 : 선형변환이 대칭행렬이라면 입력벡터는 직교하는 고유벡터로 분해하고 적절하게 줄이고 늘려서 재조합한 된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./eigenvalue%20eigenvector/symmetric%20transform.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그림과 같이 선형변환이 Symmetric matrix $A = A^T$인 경우를 고려해보자.\n",
    "- $A$를 EVD하고 rank-1 matrix의 가중합으로 표현했을때 $x$에 대한 선형변환 $Ax$는 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Ax = \\lambda_1q_1q_1^Tx + \\lambda_2q_2q_2^Tx + \\lambda_3q_3q_3^Tx$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x \\in \\mathbb{R}^3$에 대하여 $q_i^Tx$는 각각의 직교하는 3차원 공간의 또다른 정규직교기저에 대한 $x$의 성분을 의미한다.\n",
    "- $q_i(i=1,2,3)$로 표현된 $x$는 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "x = (q_1^Tx)q_1 + (q_2^Tx)q_2 + (q_3^Tx)q_3 = \\begin{bmatrix}q_1^Tx \\\\ q_2^Tx \\\\ q_3^Tx\\end{bmatrix}\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 간단하게 말해서 $q_1,q_2,q_3$를 포함하도록 $x$를 분해했다고 보면된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./eigenvalue%20eigenvector/symmetric%20component.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그럼 $Ax$는?? $\\to Ax$는 직교기저로 $x$를 분해하고 각 성분에 대해 적절한 스칼라배를 취해서 다시 조합하여 섞은 것으로 이해할 수 있다.\n",
    "    - 첫번째 성분인 $(q_1^Tx)q_1$은 $\\lambda_1$만큼 곱한다. $\\to \\lambda_1q_1q_1^Tx$\n",
    "    - 두번째 성분인 $(q_2^Tx)q_2$은 $\\lambda_2$만큼 곱한다. $\\to \\lambda_2q_2q_2^Tx$\n",
    "    - 세번째 성분인 $(q_3^Tx)q_3$은 $\\lambda_3$만큼 곱한다. $\\to \\lambda_3q_3q_3^Tx$\n",
    "    - 곱한것들을 +해서 섞으면 $x$를 대칭행렬로 선형변환한 $Ax$이다.\n",
    "- 즉, $Ax = \\lambda_1q_1q_1^Tx + \\lambda_2q_2q_2^Tx + \\lambda_3q_3q_3^Tx$이다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정리\n",
    "- Symmetric matrix의 경우 EVD가 조금 더 간단하다.\n",
    "    - 이는 $V^{-1} = V^T$로 구해지기 때문이다.\n",
    "- 또한 재밌는 사실도 두 가지 나왔다.\n",
    "    - Symmetric matrix는 rank-1 matrix의 가중합이다. $\\to$ 데이터 압축,축소,PCA 응용(1)\n",
    "    - Symmetric matrix가 선형변환이라면 그러한 선형변환은 Input을 직교기저로 분해하고 적절히 스칼라배하여 재조합 한 것이다.(2)\n",
    "- 특히(1)의 경우는 유용할 것 같지만 여기서는 Symmetric matrix로 하는 방법만 배웠다.\n",
    "- SVD의 경우 일반적인 행렬에 대해서 할 수 있다.(만능)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[수튜브](https://www.youtube.com/watch?v=_nmuOZujc-E&ab_channel=%EC%88%98%ED%95%99%EC%B1%84%EB%84%90%EC%91%A4%ED%8A%9C%EB%B8%8C)<br>\n",
    "[공돌이의 수학정리노트](https://angeloyeo.github.io/2020/11/19/eigen_decomposition.html)<br>\n",
    "[혁펜하임 선형대수학 5-2강. 고윳값 분해 (Eigendecomposition) 의 모든 것!](https://www.youtube.com/watch?v=PP9VQXKvSCY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0478b8cb1c47bafb71305148a49d30528a4d9c22ca2de336c01aa5a8230a459a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
