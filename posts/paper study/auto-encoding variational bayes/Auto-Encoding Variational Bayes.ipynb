{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Auto-Encoding Variational Bayes\"\n",
    "format: html\n",
    "date : 2023-02-22\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"color:black\">**Problem Setting**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같은 data set 주어져 있다고 해보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&{\\bf{X}} = \\{{\\bf{x}^{(i)}}\\}_{n=1}^N\\\\\n",
    "&\\,\\text{consisiting of N i.i.d samples of discrete(or) random variable {\\bf{x}}} \\in \\mathbb{R}^K\\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set은 다음과 같은 random process에 의해서 생성된다고 가정한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ${\\bf{z}}^{i} \\in \\mathbb{R}^P$는 $p_{{\\boldsymbol{\\theta}}^*}({\\bf{z}})$에서 먼저 생성되었다. (generated) (단, $K>P$)\n",
    "2. ${\\bf{x^{(i)}}}$가 ${\\bf{z^{(i)}}}$를 condition으로 하는 distribution $p_{{\\boldsymbol{\\theta}}^*}({\\bf{x}}|{\\bf{z}} = {\\bf{z^{(i)}}})$에서 생성되었다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 계산의 간단함을 위해서 prior $p_{{\\boldsymbol{\\theta}}^*}(\\bf{z})$와 likelyhood $p_{{\\boldsymbol{\\theta}}^*}\\bf{(x|z)}$는 동일한 파라미터를 가지는 분포 $p_{{\\boldsymbol{\\theta}}}(\\bf{z})$와 $p_{{\\boldsymbol{\\theta}}}(\\bf{x|z})$이며 ${\\boldsymbol{\\theta}},z$에 대하여 거의 모든 곳에서 미분가능하다고 가정한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ${\\bf{z}^{(i)}}$는 i-번째 생성된 latent variable이다. 이 randomvariable은 우리는 알려지지 않았다.\n",
    "- ${\\bf{x}^{(i)}}$는 i-번째 latent variable을 condition으로 하는 conditional distribution으로부터 sampling된 값(벡터)이다.\n",
    "- $p_{{\\boldsymbol{\\theta}}}$는 parameter가 ${\\boldsymbol{\\theta}}$인 확률분포함수이다. 예를들어 정규분포라면 ${\\boldsymbol{\\theta}} = \\{\\boldsymbol{\\mu},\\boldsymbol{\\sigma^2}\\}$이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성모델을 만들고자 할때 나타나는 일반적인 상황은 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적으로 생성모델은 $p_{\\boldsymbol{\\theta}}{\\bf{({\\bf{x}})}} = \\int_z p_{\\boldsymbol{\\theta}}({\\bf{z}})p_{\\boldsymbol{\\theta}}({\\bf{x|z}})d{\\bf{z}}$가 $\\bf{z}$의 차원이 너무커서 적분을 할 수 없음.  따라서 posterior를 구할 수 없는 Intractability가 존재.(Note : likelyhood와 prior를 쉬운 분포로 가정해놔도 계산할 수 없음!)\n",
    "- large dataset이 주어져서 batch단위로 optimization을 하기에는 너무 큰 computational cost가 예상됨."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에서 위와 같은 문제점을 극복하여 다음의 것들을 문제를 풀고자 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. True Parameter인 ${\\boldsymbol{\\theta}^*}$를 추정하여 random process 모방. 즉, True $p_{{\\boldsymbol{\\theta}}}{\\bf{(x|z)}}$를 학습하여 latent variable에서 input space로의 mapping 학습. ($\\boldsymbol{\\theta} \\rightarrow \\boldsymbol{\\theta}^*$)\n",
    "2. True Posterior $p_{{\\boldsymbol{\\theta}^*}}{\\bf{({\\bf{z|x}})}}$를 구하여 representation,coding task에서의 사용.($\\boldsymbol{\\theta}^*$를 알고있어도 구하는 것이 불가능했던 확률분포)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국에 보면 encooder,decoder를 학습하는 문제이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"color:black\">**Method**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\">**posterior inference via Variational Inference**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번째 문제인 True posterior를 구하기 위해서는 어떻게 해야할까? 먼저 $\\boldsymbol{\\theta} \\rightarrow \\boldsymbol{\\theta}^*$가 되도록 학습(1번째 목적)해야하며 또한 True parameter $\\boldsymbol{\\theta^*}$를 찾았다고 해도 intractability를 해결하여 Posterior를 구해야 한다. True parameter를 찾는 방법은 일단 재껴두고 여기서는 **임의의 $\\boldsymbol{\\theta}$으로 parameterize된 posterior $p_{\\boldsymbol{\\theta}}(\\bf{{\\bf{z|x}}})$를 구하는 것에만 집중**한다. 또한 먼저 논의를 간단히 하기 위해서 single observation ${\\bf{x}}$에 대해서만 고려한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior $p_{\\boldsymbol{\\theta}}(\\bf{{\\bf{z|x}}})$는 어떻게 구할 수 있을까? 논문에서는 **variational inference의 방법** 즉, **$\\bf{z}$에 관한 또다른 확률분포 $q_{\\boldsymbol{\\phi}}\\bf{({\\bf{z|x}})}$를 가정한 후 이를 점점 실제 posterior인 $p_{{\\boldsymbol{\\theta}}}\\bf{({\\bf{z|x}})}$에 다가가도록 하는 것**이다. **$q_{{\\boldsymbol{\\phi}}}$가 충분히 $p_{\\boldsymbol{\\theta}}$에 다가가면 이를 posterior 대신 사용**한다. 단,여기서 $q_{\\boldsymbol{\\phi}}$는 계속해서 ${\\boldsymbol{\\phi}}$를 수정해 나가야하므로 우리가 알고있는 계산이 편리한 함수로 가정한다.(예를 들면 정규분포)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 방법을 사용하기 위해서는 두 분포사이의 \"차이\"를 좁혀나가야 하며 이를 알려주는 값인 KL-divergence를 사용한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\text{D}_{KL}[q_{\\boldsymbol{\\phi}}({\\bf{z|x}})||p_{{\\boldsymbol{\\theta}}}({\\bf{z|x}})] &:= \\int_zq_{\\boldsymbol{\\phi}}({\\bf{z|x}})\\text{log}\\frac{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})}{p_{{\\boldsymbol{\\theta}}}({\\bf{z|x}})}dz \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 2번째 목적은 다음과 같이 KL-divergence를 가장 줄이는 $\\hat{q_{\\boldsymbol{\\phi}}}$를 찾는 것과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\hat{q_{\\boldsymbol{\\phi}}}} = \\underset{q_{\\boldsymbol{\\phi}}}{\\text{argmin}}\\,\\text{D}_{KL}[q_{\\boldsymbol{\\phi}}({\\bf{z|x}})||p_{{\\boldsymbol{\\theta}}}({\\bf{z|x}})] $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 RHS term인 KL-divergence는 ELBO와 evidence(marginal log likelyhood)의 차이로 전개할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&\n",
    "\\begin{aligned}\n",
    "\\text{D}_{KL}[q_{\\boldsymbol{\\phi}}({\\bf{z|x}})||p_{{\\boldsymbol{\\theta}}}({\\bf{z|x}})] &:= \\int_zq_{\\boldsymbol{\\phi}|}({\\bf{z|x}})\\text{log}\\frac{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})}{p_{{\\boldsymbol{\\theta}}}({\\bf{z|x}})}dz \\\\\n",
    "&= -\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}}) + \\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x}})\\\\\n",
    "\\end{aligned}\n",
    "\\\\\n",
    "&\\text{where } \\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}}) := \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,\\frac{p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})}{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})} \\right] = \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}}) \\right]\n",
    "\\end{aligned}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}})$는 evidence = $\\text{log}p_{\\boldsymbol{\\theta}}(\\bf{x})$의 lowerbound(하한)이다. i.e. $\\text{log}\\,p_{\\boldsymbol{\\theta}}(\\bf{x}) \\geq \\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}})$ 줄여서 ELBO라고 한다. \n",
    "- ELBO를 $\\boldsymbol{\\phi},{\\boldsymbol{\\theta}}$의 함수로 notation한 이유는 optimization과정에서 parameter를 변수이기.(MLE에서 parameter는 하나의 고정된 상수이지만 일단은 변수로 보고 likelyhood의 max값을 찾는 과정과 비슷한 느낌인 것 같다.)\n",
    "- ${\\bf{x}}$는 single observation으로 고정된 관측값이다. 우리의 목적은 관측된 값 ${\\bf{x}}$가 있을 때의 latent variable ${\\bf{z}}$의 posterior를 구하는 것임을 기억하자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $p_{{\\boldsymbol{\\theta}}}({\\bf{x}})$는 $q_{\\boldsymbol{\\phi}}$와 독립적이므로 $q_{\\boldsymbol{\\phi}}$를 maximization하는 과정에서는 상수취급 할 수 있으므로 이는 ELBO를 maximization하는 문제로 바뀌게 된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\hat{q_{\\boldsymbol{\\phi}}} &= \\underset{q_{\\boldsymbol{\\phi}}}{\\text{argmax}}\\,\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}}) \\\\\n",
    "&= \\underset{q_{\\boldsymbol{\\phi}}}{\\text{argmax}}\\,\\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}}) \\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 ${\\bf{z}}$는 integral후에 사라지는 적분변수이며 ${\\bf{x}}$는 관측값이다. 결국 $q_{\\boldsymbol{\\phi}}$를 control하여 KL-divergence를 maximize하는 것은 $\\boldsymbol{\\phi}$를 control하여 KL-divergence를 maximize하는 $\\hat{\\boldsymbol{\\phi}}$를 찾는 것과 같은 문제이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\hat{\\boldsymbol{\\phi}} = \\underset{\\boldsymbol{\\phi}}{\\text{argmax}}\\,\\mathcal{L}(\\boldsymbol{\\phi};{\\boldsymbol{\\theta}},x)\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- maximization 과정에서는 $\\boldsymbol{\\phi}$만 움직이는 변수 취급하므로 ${\\boldsymbol{\\theta}}$는 일단 고정된 값으로 취급하였다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리하자면 문제는 원래 우리가 임의로 설정한 posterior인 $q_{\\boldsymbol{\\phi}}$를 posterior인 $p_{\\boldsymbol{\\theta}}$와 비슷하게 만드는 문제였다. 이는 KL-divergence를 minimize하는 $q_{\\boldsymbol{\\phi}}$를 찾는 것이었으며 수식전개를 통해서 결국에는 ELBO를 maximize하는 $\\boldsymbol{\\phi}$를 찾는 문제와 같음을 알 수 있다. 문제를 끝까지 푸는 건 잠시 뒤로 미루고 1번째 문제를 푸는 방법에 대해서 생각해보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\">**estimate $\\boldsymbol{\\theta}^*$ via MLE**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 2번 문제를 푸는 방법을 알았기에 이제 해결해야 할 것은 1번문제인 true parameter인 $\\theta^*$를 구하는 것이다. 이 문제도 풀게되면 True posterior,True likelyhood,True prior을 근사적으로 구하며 randomprocess(encoder,decoder)를 묘사할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 true parameter인 $\\theta^*$에 가장 근접하도록 $\\theta$를 구해야 하기 때문에 먼저 $\\theta^*$에 대해 생각해보자. $\\theta^*$은 과연 어떤 값일까? 아마도 $\\theta^*$는 관측된 데이터 ${\\bf{x}}$에 대해서 가장 높은 확률을 부여하는 값일 것이다. 따라서 우리는 관측된 데이터에 대해서 가장 높은 확률을 부여하는 $\\theta$를 찾아야 한다. 이는 전체적으로 MLE의 방법과 동일하다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\hat{\\theta} = \\underset{{\\bf{\\theta}}}{\\text{argmax}}\\,\\text{log}\\,p_{\\boldsymbol{\\theta}}(\\bf{x})\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제는 $p_{\\boldsymbol{\\theta}}{\\bf{({\\bf{x}})}} = \\int_z p_{\\boldsymbol{\\theta}}({\\bf{z}})p_{\\boldsymbol{\\theta}}({\\bf{x|z}})d{\\bf{z}}$이다. problem setting에서 언급했듯이 구할 수 없는 값이다. 여기서 문제를 약간 우회하여 $\\text{log}\\,p_{\\boldsymbol{\\theta}}(\\bf{x})$의 lowerbound인 ELBO를 maximize하는 문제로 바꾼다. 즉 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&\\hat{\\theta} = \\underset{{\\bf{\\theta}}}{\\text{argmax}}\\,\\text{log}\\,p_{\\boldsymbol{\\theta}}(\\bf{x}) \\approx \\underset{{\\bf{\\theta}}}{\\text{argmax}}\\,\\mathcal{L}({\\boldsymbol{\\theta}};\\boldsymbol{\\phi},{\\bf{x}}) \\\\\n",
    "&\\text{where }\\\\\n",
    "&\\text{evidence} := \\text{log}p_{\\boldsymbol{\\theta}}({\\bf{x}})\\\\\n",
    "&\\text{log}\\,p_{\\boldsymbol{\\theta}}({\\bf{x}}) \\geq \\text{ELBO} := \\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}})=\\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}}) \\right] \n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\theta$만 바꿔가며 위의 문제를 풀게되므로 $\\boldsymbol{\\phi}$는 fixed된 값이며 ;뒤에 위치시켰다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론 ELBO도 $z$에 대한 적분이기 때문에 풀 수 없음을 알 수 있다. 하지만 이제 문제가 ELBO를 optimization문제로 바뀌었음을 알 수 있으며 우리는 ELBO 하나의 값에 대해서 집중적으로 풀어낼 수 있는 방법을 사용할 것이다.(쉽게말하면 ELBO 하나만 샘플링해서 풀기위해서 이렇게 바꾼 것이다.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&\\boldsymbol{\\theta,\\phi}=\\underset{{\\boldsymbol{\\theta,\\phi}}}{\\text{argmax}}\\,\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};\\bf{x})\\\\\n",
    "&\\text{where }\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}},{\\bf{x}}) = \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}}) \\right] \n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\boldsymbol{\\theta,\\phi}$ : parameters of function $q$ and $p$\n",
    "- ${\\bf{x}}$ : single observation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:black\">**Solving Optimization Problem**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제는 전적으로 이제 ELBO를 Optimization하는 문제로 바뀌었다. 우리는 ELBO에 Gradient ascent를 사용하여 optimal한 $\\hat{\\boldsymbol{\\phi}},\\hat{\\boldsymbol{\\theta}}$를 구할것이다. 그러기전에 먼저 ELBO를 살펴보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}},{\\bf{x}}) &= \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}}) \\right] \\\\\n",
    "&= \\int_z\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}})\\right]q({\\bf{z|x}})d{\\bf{z}}\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에도 계속 문제였던 $d\\bf{{z}}$가 또 등장한다. 그러므로 우리는 expectation을 구할 수 없다. 따라서 samping을 통해 expectation을 근사적으로 구하는 Monte carlo method를 사용한다. 이는 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}}) &= \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}}) \\right] \\\\\n",
    "&= \\int_z\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}})\\right]q({\\bf{z|x}})d{\\bf{z}} \\\\\n",
    "&\\approx \\frac{1}{L}\\sum_{l=1}^L[\\text{log}\\,p_{\\boldsymbol{\\theta}}({\\bf{x,z}}^{(l)}) - \\text{log}\\,q_{\\boldsymbol{{\\phi}}}({\\bf{z}}|{\\bf{x}}^{(l)})]\n",
    "\\end{aligned}\n",
    "$$\\text{where } {\\bf{z}}^{(l)} \\sim q_{\\boldsymbol{\\phi}}({\\bf{z}})$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELBO를 근사적으로 구했으므로 최적화를 위해 gradient를 구해야 한다. 먼저 $\\theta$에 대한 gradient를 구해보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\nabla_{\\theta}\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}}) &= \\mathbb{E}_{Z\\sim q}\\left[\\nabla_\\theta\\text{log}\\,p_{\\boldsymbol{\\theta}}({\\bf{x,z}})\\right]\\\\\n",
    "&\\approx \\frac{1}{L}\\sum_{l=1}^L\\nabla_\\theta\\text{log}\\,p_{\\boldsymbol{\\theta}}({\\bf{x,z}}^{(l)})\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 뒷항은 $\\theta$에 대해 parameterize되어있지 않으므로 미분과정에서 제거됨."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta$에 대한 gradient는 전혀 문제없이 잘 구해짐을 알 수 있다. 하지만 문제는 $\\phi$에 대한 gradient를 구할 때 발생한다. $f({\\bf{z}}) = \\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}})$라 할 때 gradient는 다음과 같이 구해진다.(증명생략)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\nabla_{\\phi}\\mathbb{E}_{q_{\\boldsymbol{\\phi}}({\\bf{z})}}[f({\\bf{z}})] &= \\mathbb{E}_{q_{\\boldsymbol{\\phi}(\\bf{z})}} \\nabla_{q_{\\boldsymbol{\\phi}(\\bf{z})}}\\text{log}\\,q_{\\phi}({\\bf{z}}) \\\\&\\approx \\frac{1}{L}\\sum_{l=1}^L f({\\bf{z}})\\nabla_{q_{\\boldsymbol{\\phi}({\\bf{z}})}}\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z}}^{(l)})\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "갑자기 로그가 들어간 형태로 gradient가 구해진다. 이러한 gradient에 대한 추정량은 unbiased estimator이지만 high variance를 가진다고 한다. 그러므로 샘플링을 아주많이(거의무한하게)취하는 것이 아니면 이 값은 수렴하지 않는 값이므로 적당한 샘플링을 통해서 문제를 풀어야 하는 우리의 방식에는 맞지않는다. 그러므로 샘플을 대체적으로 취하는 방식인 reparameterization을 사용한다. 이를 사용하면 unbiased estimator를 얻을뿐만 아니라 low variance를 가진다. (더 자세한 논의는 [링크](https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important)에서 확인 가능)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(reparameterization trick)**<br>\n",
    "${\\bf{z}}$가 conditional distribution인 $q_{\\phi}(\\bf{z|x})$를 따르는 continuous 또는 discrete random-variable일때 ${\\bf{z}} = g_{\\phi}(\\boldsymbol{\\epsilon},\\bf{x})$인 g에 대해 deterministic한 random variable로 나타낼 수 있다는 것이다.(where, ${\\bf{\\epsilon}}\\sim p(\\boldsymbol{\\epsilon})$)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러므로 우리는 reparameterization trick을 사용해서 ELBO를 Monte carlo method를 통해 다르게 생각할 수 있다. 이렇게 ELBO를 구하면 Gradient estimator는 unbiased일 뿐만 아니라 low variance를 가진다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\tilde{\\mathcal{L}}^A(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}}) &= \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}}) \\right] \\\\\n",
    "&= \\int_z\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}})\\right]q({\\bf{z|x}})d{\\bf{z}} \\\\\n",
    "&\\approx \\frac{1}{L}\\sum_{l=1}^L[\\text{log}\\,p_{\\boldsymbol{\\theta}}({\\bf{x,z}}^{(l)}) - \\text{log}\\,q_{\\boldsymbol{{\\phi}}}({\\bf{z}}|{\\bf{x}}^{(l)})]\n",
    "\\end{aligned}\n",
    "$$\\text{where } {\\bf{z}}^{(l)} =  q_{\\boldsymbol{\\phi}}({\\boldsymbol{\\epsilon}}^{(l)},{\\bf{x}}),{\\boldsymbol{\\epsilon}}\\sim p(\\boldsymbol{\\epsilon})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A는 type A를 의미함."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에는 이러한 estimator말고도 다른 방법으로 구한 것도 있다. 이는 다음과 같다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\tilde{\\mathcal{L}}^B(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}}) = -D_{KL}(q_{\\boldsymbol{\\phi}}({\\bf{z|x}})||p_\\theta({\\bf{z}})) + \\frac{1}{L}\\sum_{l=1}^L(\\text{log}\\,p_\\theta({\\bf{x}}|{\\bf{z}}^{(l)})\n",
    "\\end{aligned}\n",
    "$$\\text{where } {\\bf{z}}^{(l)} =  q_{\\boldsymbol{\\phi}}({\\boldsymbol{\\epsilon}}^{(l)},{\\bf{x}}),{\\boldsymbol{\\epsilon}}\\sim p(\\boldsymbol{\\epsilon})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두번째 estimator를 통해서 ELBO를 maximization하는 최적화 문제를 푸는것이 왜 auto-encoder와 연결되는지 알 수 있다. ELBO를 maximize하려면 첫번째 term을 가능한 작게 해야 하는데 이는 observation을 보고 latent variable가 따르는 예측한 값이 얼마나 차이가 나느냐이다.(encoder의 성능?인 것 같다.)두번째 텀은 decoder가 얼마나 latenr variable에서 input space로 mapping을 잘 하느냐를 의미한다.(decoder의 성능?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 단 한개의 관측치에 대해서 모든 과정을 수행해봤다. 사실은 한 개의 관측치가 아니라 data set의 크기가 m인 mini-batch에 대하여 위의 과정을 수행해줘야 하므로 이것을 고려한 ELBO는 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{X}}) \\approx \n",
    "\\tilde{L}^M(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{X}})=\\frac{N}{M}\\sum_{i=1}^M\\tilde{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};{\\bf{x}}^{(i)})\n",
    "\\end{aligned}\n",
    "$$\\text{where } {\\bf{z}}^{(l)} \\sim q_{\\boldsymbol{\\phi}}({\\bf{z}})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"color:black\">**Appendix**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"color:black\">**evidence lower bound(ELBO)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 evidence는 다음과 같이 marginzalization된 loglikelyhood로 정의한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{evidence} := \\text{log}\\,p(x;{\\boldsymbol{\\theta}}) = \\int_z p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})dz$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evidence를 쭉 전개하면 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\text{log}\\,p(x;{\\boldsymbol{\\theta}}) &= \\int_z p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})dz \\\\\n",
    "&=\\text{log}\\,\\int_z \\frac{p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})}{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})}q_{\\boldsymbol{\\phi}}({\\bf{z|x}})dz \\\\\n",
    "&=\\text{log}\\,\\mathbb{E}_{Z\\sim q}\\left[\\frac{p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})}{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})} \\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jenson's inequality](https://ko.wikipedia.org/wiki/%EC%98%8C%EC%84%BC_%EB%B6%80%EB%93%B1%EC%8B%9D) $f(E[X])\\leq E[f({\\bf{x}})]$에 의하여 evidence의 lowerbound를 찾을 수 있다. 이를 evidence lower bound(ELBO)라 정의한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&\\text{log}\\,p(x;{\\boldsymbol{\\theta}}) \\geq \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,\\frac{p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})}{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})} \\right]\\\\\n",
    "&\\mathcal{L(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}})} := \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,\\frac{p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})}{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})} \\right] = \\mathbb{E}_{Z\\sim q}\\left[\\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})-\\text{log}\\,q_{\\boldsymbol{\\phi}}({\\bf{z|x}}) \\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- evidence를 $\\boldsymbol{\\phi},{\\boldsymbol{\\theta}}$의 함수로 notation한 이유는 optimization 과정에서 변수로 보고 사용하기 때문이다.(MLE에서 parameter는 하나의 고정된 상수이지만 일단은 변수로 보고 likelyhood의 max값을 찾는 과정과 비슷한 느낌인 것 같다.)\n",
    "- 관측값${\\bf{x}}$는 고정이므로 ;뒤에 놓았다.(이것도 MLE에서 관측한 값은 고정인 느낌과 같다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"color:black\">**KL-divergence 전개**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\text{D}_{KL}[q_{\\boldsymbol{\\phi}}({\\bf{z|x}})||p_{\\boldsymbol{\\theta}}({\\bf{z|x}})] &:= \\int_zq_{\\boldsymbol{\\phi}}\n",
    "({\\bf{z|x}})\\text{log}\\frac{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})}{p_{{\\boldsymbol{\\theta}}}({\\bf{z|x}})}dz \\\\\n",
    "&= \\int_zq_{\\boldsymbol{\\phi}}({\\bf{z|x}})\\text{log}\\frac{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})p_{{\\boldsymbol{\\theta}}}({\\bf{x}})}{p_{\\boldsymbol{\\theta}}({\\bf{x,z}})}dz \\\\\n",
    "&= \\int_zq_{\\boldsymbol{\\phi}}({\\bf{z|x}})\\text{log}\\frac{q_{\\boldsymbol{\\phi}}({\\bf{z|x}})}{p_{{\\boldsymbol{\\theta}}}({\\bf{x,z}})}dz  + \\int_z q_{\\boldsymbol{\\phi}}({\\bf{z|x}})\\text{log}\\,p_{\\boldsymbol{\\theta}}({\\bf{x}})dz\\\\\n",
    "&= -\\mathcal{L}(\\boldsymbol{\\phi},{\\boldsymbol{\\theta}};{\\bf{x}}) + \\text{log}\\,p_{{\\boldsymbol{\\theta}}}({\\bf{x}})\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0478b8cb1c47bafb71305148a49d30528a4d9c22ca2de336c01aa5a8230a459a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
