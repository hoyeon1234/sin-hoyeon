<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="신호연">
<meta name="dcterms.date" content="2022-12-26">

<title>HIHO - Logistic Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-JE4129QJZV"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-JE4129QJZV', { 'anonymize_ip': true});
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">HIHO</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/hoyeon1234/sin-hoyeon/tree/main/posts"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Logistic Regression</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Deep learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>신호연 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 26, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link active" data-scroll-target="#logistic-regression">Logistic Regression</a></li>
  <li><a href="#가정" id="toc-가정" class="nav-link" data-scroll-target="#가정">가정</a>
  <ul class="collapse">
  <li><a href="#기댓값에-대한-고찰" id="toc-기댓값에-대한-고찰" class="nav-link" data-scroll-target="#기댓값에-대한-고찰">기댓값에 대한 고찰</a></li>
  </ul></li>
  <li><a href="#로지스틱회귀-수식-유도" id="toc-로지스틱회귀-수식-유도" class="nav-link" data-scroll-target="#로지스틱회귀-수식-유도">로지스틱회귀 수식 유도</a>
  <ul class="collapse">
  <li><a href="#concept" id="toc-concept" class="nav-link" data-scroll-target="#concept">concept</a></li>
  <li><a href="#본격적인-유도" id="toc-본격적인-유도" class="nav-link" data-scroll-target="#본격적인-유도">본격적인 유도</a>
  <ul class="collapse">
  <li><a href="#모수를-로지스틱함수로-바꾸기" id="toc-모수를-로지스틱함수로-바꾸기" class="nav-link" data-scroll-target="#모수를-로지스틱함수로-바꾸기">모수를 로지스틱함수로 바꾸기</a></li>
  <li><a href="#베르누이-분포의-pmf-정리" id="toc-베르누이-분포의-pmf-정리" class="nav-link" data-scroll-target="#베르누이-분포의-pmf-정리">베르누이 분포의 pmf 정리</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#mle" id="toc-mle" class="nav-link" data-scroll-target="#mle">MLE</a></li>
  <li><a href="#gradient-descent" id="toc-gradient-descent" class="nav-link" data-scroll-target="#gradient-descent">Gradient descent</a></li>
  <li><a href="#구현" id="toc-구현" class="nav-link" data-scroll-target="#구현">구현</a>
  <ul class="collapse">
  <li><a href="#setting" id="toc-setting" class="nav-link" data-scroll-target="#setting">setting</a></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">data</a></li>
  <li><a href="#gradient-descent-1" id="toc-gradient-descent-1" class="nav-link" data-scroll-target="#gradient-descent-1">Gradient Descent</a></li>
  </ul></li>
  <li><a href="#정리" id="toc-정리" class="nav-link" data-scroll-target="#정리">정리</a></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix">Appendix</a>
  <ul class="collapse">
  <li><a href="#베르누이-분포-전개" id="toc-베르누이-분포-전개" class="nav-link" data-scroll-target="#베르누이-분포-전개">1.베르누이 분포 전개</a></li>
  <li><a href="#nll전개with-parameter-w" id="toc-nll전개with-parameter-w" class="nav-link" data-scroll-target="#nll전개with-parameter-w">2.NLL전개(with parameter <span class="math inline">\(W\)</span>)</a></li>
  <li><a href="#nll전개cross-entropy-유도하기" id="toc-nll전개cross-entropy-유도하기" class="nav-link" data-scroll-target="#nll전개cross-entropy-유도하기">3.NLL전개(Cross Entropy 유도하기)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>로지스틱회귀에 대해서 정리한 글입니다.</p>
<section id="logistic-regression" class="level1">
<h1>Logistic Regression</h1>
<p>로지스틱회귀는 이진분류문제를 풀기위한 모형이며 종속변수 Y는 범주형 변수로 2가지 값 0또는 1만을 가질 수 있습니다. 파라미터를 사용하여 종속변수 y값을 설명한다는 점에서 선형회귀와 비슷하지만 y가 범주형변수라는 점과 분류문제에 사용되는 모델이라는 차이점이 있습니다.</p>
</section>
<section id="가정" class="level1">
<h1>가정</h1>
<p>로지스틱회귀의 기본 가정은 다음과 같습니다.</p>
<p><code>-</code> 각각의 데이터요소(샘플)는 여러개의 독립변수와 0또는1만 가질수 있는 종속변수로 이루어져 있습니다. <br> <code>-</code> 임의의 m개의 독립변수와 이진 종속변수를 가지는 i번째 샘플을 나타나면 다음과 같습니다.<span class="math inline">\(x_{m,i}\)</span>는 임의의 i번째 관측치의 m번째 변수를 의미합니다<br></p>
<p><span class="math display">\[(x_{1,i},x_{2,i},\dots,x_{m,i}),Y_{i} \]</span></p>
<p><code>-</code> <span class="math inline">\(x_{1,i},x_{2,i},\dots,x_{m,i}\)</span>가 주어질 때, 종속변수 <span class="math inline">\(Y_{i}\)</span>는 베르누이 분포를 따르는 확률변수입니다.<br></p>
<span class="math display">\[\begin{aligned}
&amp; Y_i|x_{1,i},x_{2,i},\dots,x_{m,i} \sim \text{Bernouli}(p_{i}) \nonumber \\
&amp; \text{where},p_{i} = P(Y|X=1)
\end{aligned}\]</span>
<p><code>-</code> 확률변수<span class="math inline">\(Y_{i}\)</span>가 따르는 확률함수를 구체적으로 표현한 식입니다.<br> <span class="math display">\[Pr\,(Y_{i} = y|x_{1,i},x_{2,i},\dots,x_{m,i}\,) =
\begin{cases}
p_i   &amp; \text{if }y=1, \\
1-p_i &amp; \text{if }y=0
\end{cases} = p_i^y(1-p_i)^{1-y}\]</span> <br></p>
<p><code>-</code> 기댓값은 실험 또는 시행을 무한히 반복했을때 확률변수가 취하는 값의 평균으로 기대되는(expected) 값(value)입니다. 베르누이분포를 따르는 확률변수 <span class="math inline">\(Y_{i}\)</span>의 기댓값을 구하면 다음과 같습니다.<br></p>
<p><span class="math display">\[E\,[Y|x_{1,i},x_{2,i},\dots,x_{m,i}]\, = \sum_{i=0}^{i=1}p_iy = 1 \times p_{i} + 0 \times (1-p_{i}) = p_{i}\]</span></p>
<div class="cell" data-execution_count="75">
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>&lt;matplotlib.legend.Legend at 0x1f25fe4e730&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Logistic Regression_files/figure-html/cell-2-output-2.png" class="img-fluid"></p>
</div>
</div>
<section id="기댓값에-대한-고찰" class="level2">
<h2 class="anchored" data-anchor-id="기댓값에-대한-고찰">기댓값에 대한 고찰</h2>
<p>기댓값은 실험 또는 시행을 무한히 반복했을때 확률변수가 취하는 값의 평균으로(또는 샘플링된 값의 평균) 기대되는 값입니다. 확률변수가 베르누이 분포를 따르는 경우 확률변수에 대한 기댓값(<span class="math inline">\(E\,[y|x_{1,i},x_{2,i}\.,\dots,x_{m,i}]\)</span>)과 모수<span class="math inline">\((p_i)\)</span>가 같은 값을 가집니다. 그러므로,만약에 주어진 샘플데이터로부터 베르누이분포의 모수를 적절히 추정할 수 있다면 주어진 조건하에서 실험 또는 시행을 무한히 반복할 경우 확률변수가 1인사건과 0인사건중 어떤 사건이 더 많이 발생할지 알 수 있고 이를 바탕으로 종속변수 Y의 값을 결정하는 것은 타당합니다.<br> <code>-</code> e.g.<br></p>
<ul>
<li><span class="math inline">\(E\,[y]\, = \hat{p_i}&lt;0.5\)</span> =&gt; 무한히 실행했을때 0인 경우가 더 많을 것임 =&gt; 관측치를 0으로 예측 <br></li>
<li><span class="math inline">\(E\,[y]\, = \hat{p_i}\geq0.5\)</span>=&gt;무한히 실행했을때 1인 경우가 더 많을 것임 =&gt; 관측치를 1로 예측</li>
</ul>
</section>
</section>
<section id="로지스틱회귀-수식-유도" class="level1">
<h1>로지스틱회귀 수식 유도</h1>
<section id="concept" class="level2">
<h2 class="anchored" data-anchor-id="concept">concept</h2>
<p>선형회귀에서 추정하고자하는 변수<span class="math inline">\(y\)</span>는 <span class="math inline">\(x_0,x_1,...,x_m\)</span>과 <span class="math inline">\(w_0,w_1,...,w_m\)</span>과의 linear combination이였습니다.위에서 언급했듯이 특정샘플에 대한 모수를 적절하게 추정할 수 있다면 관측치가 어떤 클래스에 속할지 합리적으로 알 수 있으므로,로지스틱회귀에서도 선형회귀에서의 아이디어를 핵심아이디어를 가지고와서 추정하고자 하는 모수<span class="math inline">\(p_i\)</span>를 <span class="math inline">\(x_0,x_1,...,x_m\)</span>과 <span class="math inline">\(w_0,w_1,...,w_m\)</span>의 linear combination로 표현하고자 합니다.<br></p>
<p><code>선형회귀의 아이디어(linear combination)</code> + <code>모수에 대한 표현</code>이라는 조건을 만족하기 위해서 최종적인 식은 다음과 조건을 만족해야 것입니다.<br> <code>-</code> <span class="math inline">\((x_0,x_1,...,x_m)\,,(w_0,w_1,..,w_m)\)</span>의 linear combination 식에 있어야 함.<br> <code>-</code> linearcombination = 모수(추정하고자하는값)여야 함.</p>
<p>why linear combination?</p>
</section>
<section id="본격적인-유도" class="level2">
<h2 class="anchored" data-anchor-id="본격적인-유도">본격적인 유도</h2>
<section id="모수를-로지스틱함수로-바꾸기" class="level3">
<h3 class="anchored" data-anchor-id="모수를-로지스틱함수로-바꾸기">모수를 로지스틱함수로 바꾸기</h3>
<ol type="1">
<li><span class="math inline">\((x_0,x_1,...,x_m)\,,(w_0,w_1,..,w_m)\)</span>의 linear combination이 식에 존재해야 합니다. 그러므로 선형방정식을 하나 만듭니다.<br> <span class="math display">\[\begin{align}
f(i) = x_{1,i}w_0 + x_{2,i}w_1 + x_2w_2 + ... + x_{m,i}w_m = X_iW \nonumber \\
where,X_i = \,[x_{1,i},x_{2,i},\dots,x_{m,i}]\, ,W = \,[w_0,w_1,\dots,w_m]^\text{T} \nonumber \\
\end{align}\]</span></li>
<li>좌변은 예측하고자 하는 값인 모수여야 합니다. 좌변을 바꿔봅니다. <span class="math display">\[p_i = WX_i\]</span></li>
<li>좌변의 베르누이 분포의 모수 <span class="math inline">\(p_i\)</span>는 확률변수 <span class="math inline">\(y = 1\)</span>인 사건이 일어날 확률입니다. 그러므로 <span class="math inline">\([0,1]\)</span>이라는 범위를 가지는 반면 우변의 값<span class="math inline">\(WX_i\)</span>은 <span class="math inline">\(\,[-\infty,\infty]\,\)</span>에 범위를 가집니다. 여기서 Odss Ratio를 써서 모수 <span class="math inline">\(p_i\)</span>를 포함하며 더 넓은 range를 갖도록 좌변을 수정합니다. <span class="math display">\[\text{Odds Ratio} = \frac{p_i}{1-p_i} = WX_i\]</span></li>
<li>좌변을 Odds Ratio로 수정했지만 여전히 좌변의 범위는<span class="math inline">\(\,[0,\infty]\,\)</span>으로 우변에 비해 좁습니다. 따라서 Odds Ratio에 로짓변환을 취하여 좌변의 범위를 <span class="math inline">\(\,[-\infty,\infty]\)</span>로 넓혀줍니다. <span class="math display">\[\text{logit}(p) = \text{ln}\frac{p_i}{1-p_i} = WX_i\]</span></li>
</ol>
<p>위 식을 해석하기 위해 <span class="math inline">\(X\)</span>의 첫번째 요소인 <span class="math inline">\(x_1\)</span>에 대응하는 회귀계수 <span class="math inline">\(w_1\)</span>이 학습결과 3으로 정해졌다고 가정해봅시다.만약 <span class="math inline">\(x_1\)</span>의 값이 1증가한다면 로그오즈비가 3증가합니다.<br></p>
<ol start="5" type="1">
<li>이제 양변의 범위는 맞춰졌으므로 추정하고자 하는 변수 <span class="math inline">\(p_i\)</span>가 좌변에 오도록 정리해봅시다. <span class="math display">\[p_i = \frac{1}{\,(1 + e^{-WX_i})\, }\]</span> (전개)<br> <span class="math inline">\(\frac{p_i}{1-p_i} = e^{WX_i}\)</span><br> <span class="math inline">\(\Longleftrightarrow p_i = \,(1-p_i)\,e^{WX_i}\)</span><br> <span class="math inline">\(\Longleftrightarrow p_i = \,e^{WX_i}-p_ie^{WX_i}\)</span><br> <span class="math inline">\(\Longleftrightarrow p_i + p_ie^{WX_i} = \,e^{WX_i}\)</span><br> <span class="math inline">\(\Longleftrightarrow p_i\,(1 + e^{WX_i})\, = \,e^{WX_i}\)</span><br> <span class="math inline">\(\Longleftrightarrow p_i = \frac{\,e^{WX_i}}{\,(1 + e^{WX_i})\, }\)</span><br> <span class="math inline">\(\Longleftrightarrow p_i = \frac{1}{\,(1 + e^{-WX_i})\, }\)</span><br></li>
</ol>
<p>최종적으로, 앞서 목적이었던 X와 W의 선형조합이 수식내부에 존재하도록 새롭게 표현한 모수는 다음과 같습니다. <span class="math display">\[p_i(y) = Pr\,(y = 1|X_i;W)\, = \frac{1}{\,1 + e^{-WX_i}\,}\]</span></p>
</section>
<section id="베르누이-분포의-pmf-정리" class="level3">
<h3 class="anchored" data-anchor-id="베르누이-분포의-pmf-정리">베르누이 분포의 pmf 정리</h3>
<p>베르누이분포의 모수 <span class="math inline">\(p_i\)</span>가 새롭게 표현되었으므로 확률질량함수도 새롭게 표현할 수 있습니다. 마지막 수식은 베르누이 분포의 확률질량함수가 모수<span class="math inline">\(W\)</span>에 관한 식으로 바뀌었음을 표현합니다.</p>
<p><span class="math display">\[\begin{align}
Bern(y;p_i) = Pr\,(Y_{i} = y|x_{1,i},x_{2,i},\dots,x_{m,i};p_i) &amp;=
\begin{cases}
p_i &amp; \text{if}\,y=1 \\
1-p_i &amp; \text{if}\,y=0
\end{cases} \\
&amp;= p_i^{y}(1-p_i)^{1-y} \\
&amp;= \frac{e^{yWX_i}}{1+e^{WX_i}}
\end{align}\]</span> <br></p>
</section>
</section>
</section>
<section id="mle" class="level1">
<h1>MLE</h1>
<p>베르누이 분포의 모수 <span class="math inline">\(W\)</span>만 적절하게 추정할 수 있다면 임의의 데이터에 대해서 독립변수 <span class="math inline">\(X_i = (x_{0,i},x_{1,i},\dots,x_{m,i})\)</span>가 들어왔을때 <span class="math inline">\(p_i = Pr(Y=1|X_i;w)\)</span>를 구하고 샘플이 속하는 적절한 클래스(0 또는 1)을 예측할 수 있습니다. 베르누이 분포의 모수는 어떻게 추정할 수 있을까요?<br></p>
<p>주어진 상황은 다음과 같습니다.<br></p>
<ol type="1">
<li>주어진 데이터
<span class="math display">\[\begin{aligned}
&amp;\text{Given}\, ,D={(X_i,y)}_{i=1}^{i=n} \\
&amp; \text{where}\, ,X_i = ({x_{0,i},x_{1,i},\dots,x_{m,i})}
\end{aligned}\]</span>
<br></li>
<li>로지스틱 회귀의 가정
<span class="math display">\[\begin{aligned}
&amp;\text{Suppose that data(or sample) } y_1,y_2,\dots,y_n \text{ are realization of a random variables } \\
&amp;Y_1,Y_2,Y_3,\dots,Y_n \\
&amp;\text{where,}\, Y_1 \sim Bern(Y|X_1;W),Y_2 \sim Bern(Y|X_2;W),\dots,Y_N \sim Bern(Y|X_n;W)\\
\end{aligned}\]</span>
<br></li>
</ol>
<p>MLE를 통해 모수를 추정합니다.(참고:<a href="https://hoyeon1234.github.io/sin-hoyeon/posts/probabilty,statistics/MLE.html">MLE</a>)<br> 가능도는 다음과 같습니다.<br> <span class="math display">\[L(W;y_1,y_2,\dots,y_n) = p_{Y_1,Y_2,\dots,Y_n}(y_1,y_2,\dots,y_n;W) = \underset{i=1}{\overset{i=n}{\large{\prod}}}\frac{e^{y_iWX_i}}{1+e^{WX_i}}\]</span> <br></p>
우리가 구하고자 하는 추정값은 다음과 같습니다.<br>
<span class="math display">\[\begin{aligned}
\hat{W}_{MLE} &amp;= \underset{W}{\text{argmax}}\,\underset{i=1}{\overset{i=n}{\large{\prod}}}\frac{e^{y_iWX_i}}{1+e^{WX_i}} \\
&amp;= \underset{W}{\text{argmin}}-\overset{n}{\underset{i=1}{\large{\sum}}}y_iWX_i + \overset{n}{\underset{i=1}{\large{\sum}}}ln(1+e^{WX_i})
\end{aligned}\]</span>
<p>목적함수가 최솟값을 가지려면 <span class="math inline">\(\large{\frac{\partial J}{\partial w_0}=\frac{\partial J}{\partial w_1}=\frac{\partial J}{\partial w_2}=\dots\ = \frac{\partial J}{\partial w_m}} = 0\)</span> <br> 즉,<span class="math inline">\(\nabla_wJ(W) = [\large{\frac{\partial J}{\partial w_0},\frac{\partial J}{\partial w_1},\frac{\partial J}{\partial w_2}=\dots\,\frac{\partial J}{\partial w_m}}]^\text{T} = \overrightarrow{\bf{0}}\)</span> 이어야 합니다. 목적함수를 임의의 <span class="math inline">\(w_k\)</span>편미분하여 0이 되는 방정식은 다음과 같습니다<br></p>
<span class="math display">\[\begin{aligned}
\frac{\partial J}{\partial w_k} = -\overset{n}{\underset{i=1}{\large{\sum}}}y_ix_{k,i} + \sum_{i=1}^{n}\frac{x_{k,i}e^{WX_i}}{1+e^{WX_i}} = 0
\end{aligned}\]</span>
<p><br></p>
<p>위와 같이 m개의 변수에 대해서 미분하면 m개의 방정식이 존재합니다. 그러나 정리하여 풀어낼 수 없는형태이므로 닫힌형태(closed-form)로 해가 존재하지 않습니다.</p>
</section>
<section id="gradient-descent" class="level1">
<h1>Gradient descent</h1>
<p>위에서 해석적으로 logstic regression의 해를 구할 수 없기때문에 다른 방법들을 써야합니다. 여기서는 경사하강법으로 해를 구합니다. 경사하강법을 사용하기 위해서 NLL을 베르누이분포의 2번식을 활용하여 전개하면 다음과 같습니다. 이번에는 베르누이 분포의 모수를 <span class="math inline">\(p_i\)</span>로 놓고 진행했습니다.<br> <span class="math display">\[NLL = -\sum_{i=1}^{n}y_i\text{ln}\,p_i(1-y_i)\text{ln}\,(1-p_i)\]</span> <br></p>
<p>우리의 목적은 다음과 같습니다.이번에는 모수가 <span class="math inline">\(p_i\)</span>인 베르누이 분포였으므로 추정량도<span class="math inline">\(\hat{p_i}\)</span>입니다.<br></p>
<p><span class="math display">\[\hat{p_i} = \underset{p_i}{\text{argmin}}-\sum_{i=1}^{n}y_i\text{ln}\,p_i(1-y_i)\text{ln}\,(1-p_i)\]</span></p>
<p>위식에 대해서 직접 계산은 해보지 않았지만, 해석적으로 해를 구할 수 없음을 알았습니다. 그러므로 경사하강법을 이용해서 해를 구합니다. 최솟값을 찾고자 하는 Loss function은 다음과 같이 쓸 수 있습니다.Binary Cross Entropy와 같은 수식입니다.<br> <span class="math display">\[L(\hat{y_i}) = -\sum_{i=1}^{n}y_i\text{ln}\,\hat{y_i}+(1-y_i)\text{ln}\,(1-\hat{y_i})\]</span></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>약간의 notation 변경이 있습니다.로지스틱회귀의 likelyhood를 최대화(또는 최소화)하여 나온 estimated value(추정치)는 <span class="math inline">\(\hat{p_i}\)</span> = <span class="math inline">\(\hat{y_i}\)</span>입니다. 경사하강법은 NLL에서 모수 <span class="math inline">\(p_i\)</span>에 대한 추정치<span class="math inline">\(\hat{p_i}\)</span>를 계속해서 대입해보고 틀린지 파악하고 반복적으로 추정치를 업데이트 합니다. 그러므로, <span class="math inline">\(p_i\)</span> 대신 <span class="math inline">\(\hat{p_i}\)</span>를 쓰는 것으로 보입니다.</p>
</div>
</div>
</section>
<section id="구현" class="level1">
<h1>구현</h1>
<p>로지스틱회귀의 적합을 pytorch를 사용하여 구현. Gradient Descent 활용</p>
<section id="setting" class="level2">
<h2 class="anchored" data-anchor-id="setting">setting</h2>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3"></a>plt.style.use(<span class="st">'ggplot'</span>)</span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co">#sig = lambda z:torch.exp(z)/(1+torch.exp(z))</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>sig <span class="op">=</span> torch.nn.Sigmoid()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">data</h2>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>torch.manual_seed(<span class="dv">2022</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a>n<span class="op">=</span><span class="dv">400</span></span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co">#1 모수 W가정</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>W <span class="op">=</span> torch.tensor(</span>
<span id="cb3-6"><a href="#cb3-6"></a>    [[<span class="op">-</span><span class="fl">0.8467</span>],</span>
<span id="cb3-7"><a href="#cb3-7"></a>    [<span class="fl">0.041</span>]]).<span class="bu">float</span>()</span>
<span id="cb3-8"><a href="#cb3-8"></a></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co">#2 각각의 관측치(데이터요소)에서의 모수 p_i시각화(시그모이드 함수 시각화)</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>_x <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">150</span>,<span class="dv">150</span>,n).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb3-11"><a href="#cb3-11"></a>_one <span class="op">=</span> torch.ones((n,<span class="dv">1</span>))</span>
<span id="cb3-12"><a href="#cb3-12"></a>X <span class="op">=</span> torch.concat((_one,_x),axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-13"><a href="#cb3-13"></a>p_i <span class="op">=</span> sig(X<span class="op">@</span>W)</span>
<span id="cb3-14"><a href="#cb3-14"></a>y <span class="op">=</span> torch.bernoulli(p_i)</span>
<span id="cb3-15"><a href="#cb3-15"></a>plt.xlim([<span class="op">-</span><span class="dv">150</span>,<span class="dv">150</span>])</span>
<span id="cb3-16"><a href="#cb3-16"></a>plt.plot(X[:,<span class="dv">1</span>],y,<span class="st">"bo"</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb3-17"><a href="#cb3-17"></a>plt.plot(X[:,<span class="dv">1</span>],p_i,<span class="st">"r--"</span>)</span>
<span id="cb3-18"><a href="#cb3-18"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb3-19"><a href="#cb3-19"></a>plt.ylabel(<span class="st">"y,$p_i$"</span>)</span>
<span id="cb3-20"><a href="#cb3-20"></a>plt.title(<span class="st">"realizations $y_1,\dots,y_</span><span class="sc">{300}</span><span class="st">$ from $Bern(p_1),\dots,Bern(p_</span><span class="sc">{300}</span><span class="st">)$"</span>)</span>
<span id="cb3-21"><a href="#cb3-21"></a>plt.legend([<span class="st">"y"</span>,<span class="st">"p"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>&lt;matplotlib.legend.Legend at 0x1f2684bfe20&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Logistic Regression_files/figure-html/cell-4-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="gradient-descent-1" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent-1">Gradient Descent</h2>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">import</span> torch</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-3"><a href="#cb5-3"></a>plt.style.use(<span class="st">'ggplot'</span>)</span>
<span id="cb5-4"><a href="#cb5-4"></a></span>
<span id="cb5-5"><a href="#cb5-5"></a></span>
<span id="cb5-6"><a href="#cb5-6"></a>torch.manual_seed(<span class="dv">2022</span>)</span>
<span id="cb5-7"><a href="#cb5-7"></a>n<span class="op">=</span><span class="dv">400</span></span>
<span id="cb5-8"><a href="#cb5-8"></a></span>
<span id="cb5-9"><a href="#cb5-9"></a><span class="co">#2 임의의 W에 대한 estimated value(추정치) What 초기화</span></span>
<span id="cb5-10"><a href="#cb5-10"></a>What <span class="op">=</span> torch.tensor(</span>
<span id="cb5-11"><a href="#cb5-11"></a>    [[<span class="fl">0.</span>],</span>
<span id="cb5-12"><a href="#cb5-12"></a>    [<span class="op">-</span><span class="fl">0.03</span>]],requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-13"><a href="#cb5-13"></a></span>
<span id="cb5-14"><a href="#cb5-14"></a>_x <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">150</span>,<span class="dv">150</span>,n).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb5-15"><a href="#cb5-15"></a>_one <span class="op">=</span> torch.ones((n,<span class="dv">1</span>))</span>
<span id="cb5-16"><a href="#cb5-16"></a>X <span class="op">=</span> torch.concat((_one,_x),axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-17"><a href="#cb5-17"></a>yhat <span class="op">=</span> sig(X<span class="op">@</span>What)</span>
<span id="cb5-18"><a href="#cb5-18"></a></span>
<span id="cb5-19"><a href="#cb5-19"></a>plt.plot(X[:,<span class="dv">1</span>].data,y,<span class="st">"bo"</span>,alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb5-20"><a href="#cb5-20"></a>plt.plot(X[:,<span class="dv">1</span>].data,p_i,<span class="st">"r"</span>)</span>
<span id="cb5-21"><a href="#cb5-21"></a>plt.plot(X[:,<span class="dv">1</span>].data,yhat.data,<span class="st">"g"</span>)</span>
<span id="cb5-22"><a href="#cb5-22"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb5-23"><a href="#cb5-23"></a>plt.ylabel(<span class="st">"y"</span>)</span>
<span id="cb5-24"><a href="#cb5-24"></a>plt.title(<span class="st">"realizations $y_1,\dots,y_</span><span class="sc">{60}</span><span class="st">$ from $Bern(p_1),\dots,Bern(p_</span><span class="sc">{60}</span><span class="st">)$"</span>)</span>
<span id="cb5-25"><a href="#cb5-25"></a>plt.legend([<span class="st">"y"</span>,<span class="st">"$p_i$"</span>,<span class="st">"$\hat</span><span class="sc">{y}</span><span class="st">(\hat</span><span class="sc">{p_i}</span><span class="st">)$"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>&lt;matplotlib.legend.Legend at 0x1f268e11e50&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Logistic Regression_files/figure-html/cell-5-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>loss_fn <span class="op">=</span> torch.nn.BCELoss()</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="co">"""</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="co">def BCE_Loss(yhat,y):</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="co">    return torch.mean(y * torch.log(yhat) + (1-y) * torch.log(1-yhat))</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="co">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>'\ndef BCE_Loss(yhat,y):\n    return torch.mean(y * torch.log(yhat) + (1-y) * torch.log(1-yhat))\n'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co">#custom sigmoid + torch.BCELoss 쓰면 오류 발생. 0과 1사이의 범위 아님</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="co">#torch.nn.Sigmoid + custom BCE Loss 써도 오류발생 =&gt; nan</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>plt.subplots(<span class="dv">2</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">8</span>))</span>
<span id="cb9-4"><a href="#cb9-4"></a>plt.subplots_adjust(hspace<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb9-5"><a href="#cb9-5"></a>i<span class="op">=</span><span class="dv">1</span></span>
<span id="cb9-6"><a href="#cb9-6"></a></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb9-8"><a href="#cb9-8"></a>    <span class="co">#1 yhat </span></span>
<span id="cb9-9"><a href="#cb9-9"></a>    yhat <span class="op">=</span> sig(X<span class="op">@</span>What)</span>
<span id="cb9-10"><a href="#cb9-10"></a>    <span class="co">#2 loss</span></span>
<span id="cb9-11"><a href="#cb9-11"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb9-12"><a href="#cb9-12"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">20</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb9-13"><a href="#cb9-13"></a>        plt.subplot(<span class="dv">2</span>,<span class="dv">5</span>,i)</span>
<span id="cb9-14"><a href="#cb9-14"></a>        <span class="co">#plt.plot(X[:,1].data,y,"bo",alpha=0.3)</span></span>
<span id="cb9-15"><a href="#cb9-15"></a>        plt.plot(X[:,<span class="dv">1</span>].data,p_i,<span class="st">"r"</span>)</span>
<span id="cb9-16"><a href="#cb9-16"></a>        plt.plot(X[:,<span class="dv">1</span>].data,yhat.data,<span class="st">"g"</span>)</span>
<span id="cb9-17"><a href="#cb9-17"></a>        plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb9-18"><a href="#cb9-18"></a>        plt.ylabel(<span class="st">"y"</span>)</span>
<span id="cb9-19"><a href="#cb9-19"></a>        <span class="co">#plt.title("realizations $y_1,\dots,y_{60}$ from $Bern(p_1),\dots,Bern(p_{60})$")</span></span>
<span id="cb9-20"><a href="#cb9-20"></a>        plt.legend([<span class="st">"p"</span>,<span class="st">"yhat"</span>])</span>
<span id="cb9-21"><a href="#cb9-21"></a>        title <span class="op">=</span> <span class="st">"loss : </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(<span class="bu">round</span>(loss.tolist(),<span class="dv">5</span>))</span>
<span id="cb9-22"><a href="#cb9-22"></a>        plt.title(title)</span>
<span id="cb9-23"><a href="#cb9-23"></a>        i<span class="op">+=</span><span class="dv">1</span></span>
<span id="cb9-24"><a href="#cb9-24"></a>    <span class="co">#3 derivative</span></span>
<span id="cb9-25"><a href="#cb9-25"></a>    loss.backward()</span>
<span id="cb9-26"><a href="#cb9-26"></a>    <span class="co">#4 update &amp; clean</span></span>
<span id="cb9-27"><a href="#cb9-27"></a>    What.data <span class="op">=</span> What.data <span class="op">-</span> <span class="fl">0.00005</span> <span class="op">*</span> What.grad</span>
<span id="cb9-28"><a href="#cb9-28"></a>    What.grad <span class="op">=</span> <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Logistic Regression_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="bu">round</span>(loss.tolist(),<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>0.3109</code></pre>
</div>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>plt.plot(X[:,<span class="dv">1</span>].data,y,<span class="st">"bo"</span>,alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb12-2"><a href="#cb12-2"></a>plt.plot(X[:,<span class="dv">1</span>].data,p_i,<span class="st">"r"</span>)</span>
<span id="cb12-3"><a href="#cb12-3"></a>plt.plot(X[:,<span class="dv">1</span>].data,yhat.data,<span class="st">"g"</span>)</span>
<span id="cb12-4"><a href="#cb12-4"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb12-5"><a href="#cb12-5"></a>plt.ylabel(<span class="st">"y"</span>)</span>
<span id="cb12-6"><a href="#cb12-6"></a>plt.title(<span class="st">"Logistic Regression"</span>)</span>
<span id="cb12-7"><a href="#cb12-7"></a>plt.legend([<span class="st">"y"</span>,<span class="st">"$p_i$"</span>,<span class="st">"$\hat</span><span class="sc">{y}</span><span class="st">(\hat</span><span class="sc">{p_i}</span><span class="st">)$"</span>])</span>
<span id="cb12-8"><a href="#cb12-8"></a>plt.gca().axes.xaxis.set_visible(<span class="va">False</span>)</span>
<span id="cb12-9"><a href="#cb12-9"></a>plt.gca().axes.yaxis.set_visible(<span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Logistic Regression_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="정리" class="level1">
<h1>정리</h1>
<ul>
<li>로지스틱회귀는 종속변수 Y가 1과0을 가지는 이진분류 문제일때 사용하는 모형입니다.</li>
<li>각각의 관측치에서 y의 값은 <span class="math inline">\(X_i\)</span>가 조건이며 모수가 <span class="math inline">\(p_i = \frac{1}{1+e^{-WX_i}}\)</span>인 베르누이분포를 따르는 확률변수 <span class="math inline">\(Y_i\)</span>의 realization이라고 가정합니다.</li>
<li>가정에 의해서 베르누이 분포의 모수<span class="math inline">\(p_i\)</span> 더 전개하여 또다른 모수 <span class="math inline">\(W\)</span>만 적절하게 추정하면 임의의 데이터가 어떤 클래스에 속하는지 분류할 수 있습니다. 로지스틱회귀는 모수 <span class="math inline">\(W\)</span>를 적절하게 추정치 <span class="math inline">\(\hat{p_i}\)</span>을 출력하는 것을 목적으로 합니다.</li>
<li>MLE로 모수 W를 추정할 수 있습니다. 이때 가능도(또는 로그가능도) 함수의 최댓값에 대한 닫힌형태의 해가 존재하지 않습니다.따라서 경사하강법을 통하여 해를 구합니다.</li>
<li>경사하강법의 Loss function은 NLL이며 이진분류의 CrossEntropy와 같습니다.</li>
</ul>
</section>
<section id="appendix" class="level1">
<h1>Appendix</h1>
<section id="베르누이-분포-전개" class="level2">
<h2 class="anchored" data-anchor-id="베르누이-분포-전개">1.베르누이 분포 전개</h2>
<span class="math display">\[\begin{aligned}
p_i^y(1-p_i)^{1-y} &amp;= \ (\frac{1}{\,1 + e^{-WX_i}\,})^y\,\,(1-\frac{1}{\,1 + e^{-WX_i}\,})^{1-y} \\
&amp;= (\frac{1}{1+e^{-WX_i}})^{y}(\frac{e^{-WX_i}}{1+e^{-WXi}})^{1-y} \\
&amp;= (\frac{1}{1+e^{-WX_i}})^{y}(\frac{1}{1+e^{WXi}})^{1-y} \\
&amp;= (\frac{1+e^{WX_i}}{1+e^{-WX_i}})^{y}(\frac{1}{1+e^{WX_i}}) \\
&amp;= (\frac{e^{WX_i}+e^{2WX_i}}{1+e^{WX_i}})^{y}(\frac{1}{1+e^{WX_i}}) \\
&amp;= (\frac{e^{WX_i}(1+e^{WX_i})}{1+e^{WX_i}})^{y}(\frac{1}{1+e^{WX_i}}) \\
&amp;= e^{yWX_i}\frac{1}{1+e^{WX_i}} \\
&amp;= \frac{e^{yWX_i}}{1+e^{WX_i}}
\end{aligned}\]</span>
</section>
<section id="nll전개with-parameter-w" class="level2">
<h2 class="anchored" data-anchor-id="nll전개with-parameter-w">2.NLL전개(with parameter <span class="math inline">\(W\)</span>)</h2>
<span class="math display">\[\begin{aligned}
LL &amp;= \text{ln}(\underset{i=1}{\overset{n}{\large{\prod}}}\,\frac{e^{y_iWX_i}}{1+e^{WX_i}}) \\
&amp;=\overset{n}{\underset{i=1}{\large{\sum}}}(\text{ln}\frac{e^{y_iWX_i}}{1+e^{WX_i}}) \\
&amp;= \overset{n}{\underset{i=1}{\large{\sum}}}\,[\text{ln}e^{y_iWX_i} - \text{ln}(1+e^{WX_i})]\, \\
&amp;= \overset{n}{\underset{i=1}{\large{\sum}}}\,[y_iWX_i - \text{ln}(1+e^{WX_i})], \\
&amp;= \overset{n}{\underset{i=1}{\large{\sum}}}y_iWX_i - \overset{n}{\underset{i=1}{\large{\sum}}}ln(1+e^{WX_i}) \\


NLL &amp;= -\overset{n}{\underset{i=1}{\large{\sum}}}y_iWX_i + \overset{n}{\underset{i=1}{\large{\sum}}}ln(1+e^{WX_i}) \\

\end{aligned}\]</span>
</section>
<section id="nll전개cross-entropy-유도하기" class="level2">
<h2 class="anchored" data-anchor-id="nll전개cross-entropy-유도하기">3.NLL전개(Cross Entropy 유도하기)</h2>
임의의 i번째 항에서의 확률변수 <span class="math inline">\(Y_i\)</span>가 따르는 베르누이 분포는 다음과 같습니다. <br>
<span class="math display">\[\begin{aligned}
Bern(y|X_i;p_i) = (p_i)^y(1-p_i)^{y-1}
\end{aligned}\]</span>
모수가 <span class="math inline">\(p_i\)</span>인 각각의 베르누이 분포를 따르는 확률변수 <span class="math inline">\(Y_1,Y_2\dots Y_n\)</span>으로부 n개의 realization(sample) <span class="math inline">\(y_1,y_2\dots y_n\)</span>에 대한 NLL는 다음과 같습니다. <br>
<span class="math display">\[\begin{aligned}
NLL &amp;= -\text{ln}\prod_{i=1}^{n}p_i^{y_i}(1-p_i)^{1-y_i} \\
&amp;= -\sum_{i=1}^{n}\text{ln}p_i^{y_i}(1-p_i)^{1-y_i} \\
&amp;= -\sum_{i=1}^{n}\text{ln}p_i^{y_i} + \text{ln}(1-p_i)^{1-y_i} \\
&amp;= -\sum_{i=1}^{n}y_i\text{ln}p_i + (1-y_i)\text{ln}(1-p_i)
\end{aligned}\]</span>
<p>참고링크<br> 1. <a href="https://www.analyticsvidhya.com/blog/2022/02/decoding-logistic-regression-using-mle/#h2_1">로지스틱 회귀 전개</a><br> 2. <a href="https://en.wikipedia.org/wiki/Logistic_regression">위키피디아 - 로지스틱 회귀</a><br> 3. <a href="https://ratsgo.github.io/machine%20learning/2017/07/02/logistic/">ratsgo’s blog</a></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="hoyeon1234/sin-hoyeon" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>