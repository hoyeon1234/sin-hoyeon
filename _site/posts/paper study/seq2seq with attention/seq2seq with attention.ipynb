{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"[Paper Study] NEURAL MACHINE TRANSLATION\n",
    "BY JOINTLY LEARNING TO ALIGN AND TRANSLATE\"\n",
    "format: \n",
    "  html:\n",
    "    linkcolor: blue\n",
    "categories: Paper study\n",
    "date: 2023-03-26\n",
    "author: hoyeon\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"color:black\"> **Introduction**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 당시 인공신경망을 활용한 기계번역에서는 대부분 `encoder`와 `decoder`를 포함한 모델을 사용했습니다\n",
    "- 이러한 모델은 `context vector`를 사용했으며 결과적으로 **길이가 긴 문장에서 성능저하**를 가져왔습니다.\n",
    "- 따라서 논문에서는 **각각의 `target world`에 대해 서로다른 `context vector`를 사용함으로서 길이가 긴 문장에 대한 성능저하를 개선**합니다.\n",
    "- 이러한 새로운 접근 방식을 통해 기존의 phrase-based system과 비슷한 번역 성능을 달성했습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"color:black\"> **Problem Setting**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./seq2seq%20with%20attention.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이러한 모델들은 먼저 `source sentence`가 먼저 `encoder`를 통과하여 고정된 크기의 `context vector`가 되고 이를 `decoder`의 초기 `hidden state`사용되어 `output sequence`를 출력하는 구조를 가졌었습니다.\n",
    "- 하지만 이는 input과 ouput사이에 **고정된 크기의 하나의 `context vector`를 거쳐야** 했기에 **길이가 긴 문장에 대해서는 성능저하**를 가져왔습니다.\n",
    "- 따라서 논문에서는 **각각의 `target word`를 예측할 때 마다 `source sentence`에서 연관성이 높은 부분을 자동으로 가져와주는 서로다른 `context vector`를 사용함**으로서 긴 문장에 대한 성능저하를 개선합니다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이러한 **고정된 길이의 `context vector`라는 구조적 한계 존재**했기 때문에 **길이가 긴 문장이 들어와도 정보를 과도하게 함축해야 했고** 이는 **길이가 긴 문장에 대한 성능저하로 이어졌습니다.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "당시 인공신경망을 encoder-dec \n",
    "이러한 모델은 encoder가 source setence에서 길이가 고정된 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
