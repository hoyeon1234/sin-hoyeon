<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-02-22">

<title>HIHO - Auto-Encoding Variational Bayes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-JE4129QJZV"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-JE4129QJZV', { 'anonymize_ip': true});
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">HIHO</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
 <span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/hoyeon1234/sin-hoyeon/tree/main/posts"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Auto-Encoding Variational Bayes</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 22, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span style="color:black"><strong>Introduction</strong></span></a></li>
  <li><a href="#background" id="toc-background" class="nav-link" data-scroll-target="#background"><span style="color:black"><strong>Background</strong></span></a>
  <ul class="collapse">
  <li><a href="#latent-variable-model" id="toc-latent-variable-model" class="nav-link" data-scroll-target="#latent-variable-model"><span style="color:black"><strong>Latent Variable Model</strong></span></a></li>
  <li><a href="#generative-model" id="toc-generative-model" class="nav-link" data-scroll-target="#generative-model"><span style="color:black"><strong>Generative Model</strong></span></a></li>
  </ul></li>
  <li><a href="#method" id="toc-method" class="nav-link" data-scroll-target="#method"><span style="color:black"><strong>Method</strong></span></a></li>
  <li><a href="#method-1" id="toc-method-1" class="nav-link" data-scroll-target="#method-1"><span style="color:black"><strong>Method</strong></span></a>
  <ul class="collapse">
  <li><a href="#posterior-inference-via-variational-inference" id="toc-posterior-inference-via-variational-inference" class="nav-link" data-scroll-target="#posterior-inference-via-variational-inference"><span style="color:black"><strong>posterior inference via Variational Inference</strong></span></a></li>
  <li><a href="#estimate-boldsymboltheta-via-mle" id="toc-estimate-boldsymboltheta-via-mle" class="nav-link" data-scroll-target="#estimate-boldsymboltheta-via-mle"><span style="color:black"><strong>estimate <span class="math inline">\(\boldsymbol{\theta}^*\)</span> via MLE</strong></span></a></li>
  <li><a href="#solving-optimization-problem" id="toc-solving-optimization-problem" class="nav-link" data-scroll-target="#solving-optimization-problem"><span style="color:black"><strong>Solving Optimization Problem</strong></span></a></li>
  </ul></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix"><span style="color:black"><strong>Appendix</strong></span></a></li>
  <li><a href="#evidence-lower-boundelbo" id="toc-evidence-lower-boundelbo" class="nav-link" data-scroll-target="#evidence-lower-boundelbo"><span style="color:black"><strong>evidence lower bound(ELBO)</strong></span></a></li>
  <li><a href="#kl-divergence-전개" id="toc-kl-divergence-전개" class="nav-link" data-scroll-target="#kl-divergence-전개"><span style="color:black"><strong>KL-divergence 전개</strong></span></a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level1">
<h1><span style="color:black"><strong>Introduction</strong></span></h1>
<p>variational auto-encoder는 <strong>generative model</strong>로서 intractable한 posterior를 포함하는 latent variable이 있고 large dataset에도 잘 동작한다. <strong>이는 1)variational lower bound를 reparamet-<br>erization을 통해 샘플링</strong>하고 SGD를 사용하며 <strong>2)posterior를 variational inference로 구한 뒤 encoder(inference model)로 학습</strong>시키기에 가능하다. 이번 포스트에서는 논문에서 사용된 방법들에 대해서 자세하게 수식적으로 설명한다.</p>
</section>
<section id="background" class="level1">
<h1><span style="color:black"><strong>Background</strong></span></h1>
<section id="latent-variable-model" class="level2">
<h2 class="anchored" data-anchor-id="latent-variable-model"><span style="color:black"><strong>Latent Variable Model</strong></span></h2>
<p>latent variable model은 <strong>관측가능한 데이터를 변수와 관련짓는 통계학적 모델</strong>이다. 이때의 <strong>변수를 latent variable이라고 하며 데이터가 어떻게 생성되는지에 영향</strong>을 미친다. latent variable model에서 데이터가 만들어지는 과정은 다음과 같다.</p>
<p><strong>(Data Generation Process)</strong><br> <strong>1.</strong> latent variable <span class="math inline">\(\bf{z}\)</span>가 <span class="math inline">\(p(\bf{z})\)</span>에서 먼저 sampling된다. <br> <strong>2.</strong> observed data <span class="math inline">\(\bf{x}\)</span>가 그 후 <span class="math inline">\(p({\bf{x}}|{\bf{z}}) = p({\bf{x}}|f_{\theta}({\bf{z}}))\)</span>에서 sampling된다. <br></p>
<ul>
<li><span class="math inline">\(\bf{z}\)</span>의 dimension은 일반적으로 <span class="math inline">\(\bf{x}\)</span>의 dimension보다 작다고 가정한다.</li>
<li>여기서 <span class="math inline">\(f_\theta(\bf{z})\)</span>는 <span class="math inline">\(\theta\)</span>를 parameter로 갖는 vector function으로 여러개(또는 하나의)의 output을 가집니다.</li>
</ul>
<p>예를 들어 학교에 “고양이”를 주제로 하여 과제를 제출해야 한다고 가정해보자. latent variable은 교수님이 지정한 글자크기,글자간격,글자수,주제(고양이)로 비유할 수 있으며 제출할 과제는 이러한 잠재변수들이 결과를 미쳤을 것이라 볼 수 있다. 특히 주목할 점은 latent variable <span class="math inline">\(\bf{z}\)</span>가 그대로 영향을 미칠 수도 있고 적절한 transform(function)을 거친 <span class="math inline">\(f_{\theta}(\bf{z})\)</span>가 영향을 미칠 수도 있다는 것이다. 이는 주제가 “고양이”로 선정되었어도 누군가는 “고양이에게 줘야하는 음식”으로 다른 누군가는 “고양이의 행동분석”으로 과제를 제출하는 것에 비유할 수 있다.</p>
</section>
<section id="generative-model" class="level2">
<h2 class="anchored" data-anchor-id="generative-model"><span style="color:black"><strong>Generative Model</strong></span></h2>
<p>Generative Model(생성모델)은 observed data와 유사하면서도 다른 new samples을 생성해내는 것이 목적이다. 이를 다시말하면 <strong>Generative model의 목적은 <span class="math inline">\(p_{data}(x)\)</span>를 구하는 것</strong>이라고 할 수 있다. 관측된 데이터를 생성하는 확률분포 <span class="math inline">\(p_{data}(\bf{x})\)</span>를 알면 sampling을 통해서 생성해낼 수 있기 때문이다.</p>
</section>
</section>
<section id="method" class="level1">
<h1><span style="color:black"><strong>Method</strong></span></h1>
<p><span class="math inline">\(p_{data}(\bf{x})\)</span>는 어떻게 구할 수 있을까? VAE에서는 Maximum likelyhood estimation으로 확률분포를 구하고자 한다. 구체적인 단계는 다음과 같다.</p>
<p>(<strong>Probability density estimation</strong>)<br> <strong>1.</strong> <span class="math inline">\(p_{data}(\bf{x})\)</span>를 근사할 likelyhood <span class="math inline">\(p(\bf{x})\)</span>를 가정<br> <strong>2.</strong> likelyhood가 어떤 확률분포를 따를지 결정(ex 정규분포,베르누이분포 …)<br> <strong>3.</strong> likelyhood를 가장 크게하는 parameter를 <span class="math inline">\(p(\bf{x})\)</span>의 parameter로 설정 <br> <strong>4.</strong> <span class="math inline">\(p({\bf{x}}) \approx p_{data}({\bf{x}}) \rightarrow p(\bf{x})\)</span>를 <span class="math inline">\(p_{data}(\bf{x})\)</span>대신 사용!!</p>
<ol type="1">
<li>먼저 <span class="math inline">\(p(\bf{x})\)</span>를 구해보자. Generation process가 latent variable model이라고 하면 다음과 같은 explicit form으로 적어줄 수 있다.</li>
</ol>
<p><span class="math display">\[p({\bf{x}}) = \int_z p({\bf{x}}|{\bf{z}})p({\bf{z}})d{\bf{z}} = \int_z p({\bf{x}}|{f_{\theta}(\bf{z})})p({\bf{z}})d{\bf{z}}\]</span></p>
<ol start="2" type="1">
<li><span class="math inline">\(p(\bf{x})\)</span>를 결정하는 것은 적분안의 함수를 모두 결정하는 것과 같다. VAE에서 <span class="math inline">\(p({\bf{x}}|f_{\theta}({\bf{z}}))\)</span>는 <span class="math inline">\(\bf{x}\)</span>가 실수전체에서 연속적일 경우 정규분포로 0과1사이에서 연속적일 경우 베르누이분포로 가정한다. <span class="math inline">\(p({\bf{x}}|f_{\theta}{(\bf{z})}) = \mathcal{N}({\bf{x}}|f_{\theta}(\bf{z}),\sigma^2 * \bf{I})\)</span>로 가정하고 전개해보자.</li>
</ol>
<span class="math display">\[\begin{aligned}
p({\bf{x}}) &amp;= \int_z p({\bf{x}}|{f_{\theta}(\bf{z})})p({\bf{z}})d{\bf{z}}\\
&amp;= \int_z \mathcal{N}({\bf{x}}|f_{\theta}({\bf{z}}),\sigma^2 * {\bf{I}})p({\bf{z}})d{\bf{z}}
\end{aligned}\]</span>
<ul>
<li><span class="math inline">\(f_{\theta}(z)\)</span>가 정규분포의 parameter(평균)이므로 명시적으로 <span class="math inline">\(\boldsymbol{\theta}\)</span>표시. $ p({}) p(\bf{x}|)$</li>
</ul>
<p>여기서 latent variable의 distribution인 <span class="math inline">\(p(\bf{z})\)</span>만 잘 결정해주면 우리는 monte carlo method를 사용하여 likelyhood를 근사하고 Gradient Ascent를 사용하면 될 것이다. 그러나 이는 쉽지않은 조심스러운 문제이다.</p>
<p>예를 들어서 숫자이미지를 생성하는 latent variable을 생각해보자. 단순하게 생각하면 어떤 숫자를 적어야 하는지에 관한 변수가 있지만 이 외에도 굵기,각도,스타일등의 <strong>여러가지 우리가 알지못하는 변수들이 데이터의 생성에 영향</strong>을 미칠 수 있다. 또한 각도가 휘어있는 숫자는 누군가가 빨리 쓰다가 그랬다고 생각할 수 있으며 이는 상당히 얇은 굵기를 만들어 낼 수도 있으므로 <strong>변수들간에 상관관계도 존재</strong>할 수 있다. 요약하자면 <strong>latent variable의 distribution은 매우 복잡하다는 것</strong>이다.</p>
<p>그렇다면 VAE에서는 어떻게 <span class="math inline">\(p(\bf{z})\)</span>를 가정할까? 그냥 <strong>단순히 평균이 0이며 상관관계가 존재하지 않는(공분산이 존재하지 않는) 가장 단순한 정규분포로 가정</strong>해버린다.</p>
<p><span class="math display">\[{\bf{z}} \sim p({\bf{z}}) = \mathcal{N}({\bf{z}}|0,\bf{I})\]</span></p>
<p>당연하게도 이렇게 <strong>단순하게 분포를 가정해버린다면 복잡한 latent variable의 분포를 전혀 대표하지 못할 것 같다?</strong>라는 생각이 든다. 왜냐하면 <strong>너무 쉬운 latent variable의 distribution을</strong>가정했기 때문이다. 여기서 <strong>복잡한 함수로서 역할을 하는 Deep Neural Network</strong>가 이 문제를 해결해줄 수 있다.</p>
<p>다음과 같은 data set 주어져 있다고 해보자.</p>
<span class="math display">\[\begin{aligned}
&amp;{\bf{X}} = \{{\bf{x}^{(i)}}\}_{n=1}^N\\
&amp;\,\text{consisiting of N i.i.d samples of discrete(or) random variable {\bf{x}}} \in \mathbb{R}^K\\
\end{aligned}\]</span>
<p>Data set은 다음과 같은 random process에 의해서 생성된다고 가정한다.</p>
<ol type="1">
<li><span class="math inline">\({\bf{z}}^{i} \in \mathbb{R}^P\)</span>는 <span class="math inline">\(p_{{\boldsymbol{\theta}}^*}({\bf{z}})\)</span>에서 먼저 생성되었다. (generated) (단, <span class="math inline">\(K&gt;P\)</span>)</li>
<li><span class="math inline">\({\bf{x^{(i)}}}\)</span>가 <span class="math inline">\({\bf{z^{(i)}}}\)</span>를 condition으로 하는 distribution <span class="math inline">\(p_{{\boldsymbol{\theta}}^*}({\bf{x}}|{\bf{z}} = {\bf{z^{(i)}}})\)</span>에서 생성되었다.</li>
</ol>
<p>또한 계산의 간단함을 위해서 prior <span class="math inline">\(p_{{\boldsymbol{\theta}}^*}(\bf{z})\)</span>와 likelyhood <span class="math inline">\(p_{{\boldsymbol{\theta}}^*}\bf{(x|z)}\)</span>는 동일한 파라미터를 가지는 분포 <span class="math inline">\(p_{{\boldsymbol{\theta}}}(\bf{z})\)</span>와 <span class="math inline">\(p_{{\boldsymbol{\theta}}}(\bf{x|z})\)</span>이며 <span class="math inline">\({\boldsymbol{\theta}},z\)</span>에 대하여 거의 모든 곳에서 미분가능하다고 가정한다.</p>
<ul>
<li><span class="math inline">\({\bf{z}^{(i)}}\)</span>는 i-번째 생성된 latent variable이다. 이 randomvariable은 우리는 알려지지 않았다.</li>
<li><span class="math inline">\({\bf{x}^{(i)}}\)</span>는 i-번째 latent variable을 condition으로 하는 conditional distribution으로부터 sampling된 값(벡터)이다.</li>
<li><span class="math inline">\(p_{{\boldsymbol{\theta}}}\)</span>는 parameter가 <span class="math inline">\({\boldsymbol{\theta}}\)</span>인 확률분포함수이다. 예를들어 정규분포라면 <span class="math inline">\({\boldsymbol{\theta}} = \{\boldsymbol{\mu},\boldsymbol{\sigma^2}\}\)</span>이다.</li>
</ul>
<p>생성모델을 만들고자 할때 나타나는 일반적인 상황은 다음과 같다.</p>
<ul>
<li>일반적으로 생성모델은 <span class="math inline">\(p_{\boldsymbol{\theta}}{\bf{({\bf{x}})}} = \int_z p_{\boldsymbol{\theta}}({\bf{z}})p_{\boldsymbol{\theta}}({\bf{x|z}})d{\bf{z}}\)</span>가 <span class="math inline">\(\bf{z}\)</span>의 차원이 너무커서 적분을 할 수 없음. 따라서 posterior를 구할 수 없는 Intractability가 존재.(Note : likelyhood와 prior를 쉬운 분포로 가정해놔도 계산할 수 없음!)</li>
<li>large dataset이 주어져서 batch단위로 optimization을 하기에는 너무 큰 computational cost가 예상됨.</li>
</ul>
<p>논문에서 위와 같은 문제점을 극복하여 다음의 것들을 문제를 풀고자 한다.</p>
<ol type="1">
<li>True Parameter인 <span class="math inline">\({\boldsymbol{\theta}^*}\)</span>를 추정하여 random process 모방. 즉, True <span class="math inline">\(p_{{\boldsymbol{\theta}}}{\bf{(x|z)}}\)</span>를 학습하여 latent variable에서 input space로의 mapping 학습. (<span class="math inline">\(\boldsymbol{\theta} \rightarrow \boldsymbol{\theta}^*\)</span>)</li>
<li>True Posterior <span class="math inline">\(p_{{\boldsymbol{\theta}^*}}{\bf{({\bf{z|x}})}}\)</span>를 구하여 representation,coding task에서의 사용.(<span class="math inline">\(\boldsymbol{\theta}^*\)</span>를 알고있어도 구하는 것이 불가능했던 확률분포)</li>
</ol>
<p>결국에 보면 encooder,decoder를 학습하는 문제이다.</p>
</section>
<section id="method-1" class="level1">
<h1><span style="color:black"><strong>Method</strong></span></h1>
<section id="posterior-inference-via-variational-inference" class="level2">
<h2 class="anchored" data-anchor-id="posterior-inference-via-variational-inference"><span style="color:black"><strong>posterior inference via Variational Inference</strong></span></h2>
<p>2번째 문제인 True posterior를 구하기 위해서는 어떻게 해야할까? 먼저 <span class="math inline">\(\boldsymbol{\theta} \rightarrow \boldsymbol{\theta}^*\)</span>가 되도록 학습(1번째 목적)해야하며 또한 True parameter <span class="math inline">\(\boldsymbol{\theta^*}\)</span>를 찾았다고 해도 intractability를 해결하여 Posterior를 구해야 한다. True parameter를 찾는 방법은 일단 재껴두고 여기서는 <strong>임의의 <span class="math inline">\(\boldsymbol{\theta}\)</span>으로 parameterize된 posterior <span class="math inline">\(p_{\boldsymbol{\theta}}(\bf{{\bf{z|x}}})\)</span>를 구하는 것에만 집중</strong>한다. 또한 먼저 논의를 간단히 하기 위해서 single observation <span class="math inline">\({\bf{x}}\)</span>에 대해서만 고려한다.</p>
<p>Posterior <span class="math inline">\(p_{\boldsymbol{\theta}}(\bf{{\bf{z|x}}})\)</span>는 어떻게 구할 수 있을까? 논문에서는 <strong>variational inference의 방법</strong> 즉, <strong><span class="math inline">\(\bf{z}\)</span>에 관한 또다른 확률분포 <span class="math inline">\(q_{\boldsymbol{\phi}}\bf{({\bf{z|x}})}\)</span>를 가정한 후 이를 점점 실제 posterior인 <span class="math inline">\(p_{{\boldsymbol{\theta}}}\bf{({\bf{z|x}})}\)</span>에 다가가도록 하는 것</strong>이다. <strong><span class="math inline">\(q_{{\boldsymbol{\phi}}}\)</span>가 충분히 <span class="math inline">\(p_{\boldsymbol{\theta}}\)</span>에 다가가면 이를 posterior 대신 사용</strong>한다. 단,여기서 <span class="math inline">\(q_{\boldsymbol{\phi}}\)</span>는 계속해서 <span class="math inline">\({\boldsymbol{\phi}}\)</span>를 수정해 나가야하므로 우리가 알고있는 계산이 편리한 함수로 가정한다.(예를 들면 정규분포)</p>
<p>위와 같은 방법을 사용하기 위해서는 두 분포사이의 “차이”를 좁혀나가야 하며 이를 알려주는 값인 KL-divergence를 사용한다.</p>
<span class="math display">\[\begin{aligned}
\text{D}_{KL}[q_{\boldsymbol{\phi}}({\bf{z|x}})||p_{{\boldsymbol{\theta}}}({\bf{z|x}})] &amp;:= \int_zq_{\boldsymbol{\phi}}({\bf{z|x}})\text{log}\frac{q_{\boldsymbol{\phi}}({\bf{z|x}})}{p_{{\boldsymbol{\theta}}}({\bf{z|x}})}dz \\
\end{aligned}\]</span>
<p>그렇다면 2번째 목적은 다음과 같이 KL-divergence를 가장 줄이는 <span class="math inline">\(\hat{q_{\boldsymbol{\phi}}}\)</span>를 찾는 것과 같다.</p>
<p><span class="math display">\[{\hat{q_{\boldsymbol{\phi}}}} = \underset{q_{\boldsymbol{\phi}}}{\text{argmin}}\,\text{D}_{KL}[q_{\boldsymbol{\phi}}({\bf{z|x}})||p_{{\boldsymbol{\theta}}}({\bf{z|x}})] \]</span></p>
<p>여기서 RHS term인 KL-divergence는 ELBO와 evidence(marginal log likelyhood)의 차이로 전개할 수 있다.</p>
<span class="math display">\[\begin{aligned}
&amp;
\begin{aligned}
\text{D}_{KL}[q_{\boldsymbol{\phi}}({\bf{z|x}})||p_{{\boldsymbol{\theta}}}({\bf{z|x}})] &amp;:= \int_zq_{\boldsymbol{\phi}|}({\bf{z|x}})\text{log}\frac{q_{\boldsymbol{\phi}}({\bf{z|x}})}{p_{{\boldsymbol{\theta}}}({\bf{z|x}})}dz \\
&amp;= -\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}}) + \text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x}})\\
\end{aligned}
\\
&amp;\text{where } \mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}}) := \mathbb{E}_{Z\sim q}\left[\text{log}\,\frac{p_{{\boldsymbol{\theta}}}({\bf{x,z}})}{q_{\boldsymbol{\phi}}({\bf{z|x}})} \right] = \mathbb{E}_{Z\sim q}\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}}) \right]
\end{aligned}\]</span>
<ul>
<li><span class="math inline">\(\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}})\)</span>는 evidence = <span class="math inline">\(\text{log}p_{\boldsymbol{\theta}}(\bf{x})\)</span>의 lowerbound(하한)이다. i.e.&nbsp;<span class="math inline">\(\text{log}\,p_{\boldsymbol{\theta}}(\bf{x}) \geq \mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}})\)</span> 줄여서 ELBO라고 한다.</li>
<li>ELBO를 <span class="math inline">\(\boldsymbol{\phi},{\boldsymbol{\theta}}\)</span>의 함수로 notation한 이유는 optimization과정에서 parameter를 변수이기.(MLE에서 parameter는 하나의 고정된 상수이지만 일단은 변수로 보고 likelyhood의 max값을 찾는 과정과 비슷한 느낌인 것 같다.)</li>
<li><span class="math inline">\({\bf{x}}\)</span>는 single observation으로 고정된 관측값이다. 우리의 목적은 관측된 값 <span class="math inline">\({\bf{x}}\)</span>가 있을 때의 latent variable <span class="math inline">\({\bf{z}}\)</span>의 posterior를 구하는 것임을 기억하자.</li>
</ul>
<p>여기서 <span class="math inline">\(p_{{\boldsymbol{\theta}}}({\bf{x}})\)</span>는 <span class="math inline">\(q_{\boldsymbol{\phi}}\)</span>와 독립적이므로 <span class="math inline">\(q_{\boldsymbol{\phi}}\)</span>를 maximization하는 과정에서는 상수취급 할 수 있으므로 이는 ELBO를 maximization하는 문제로 바뀌게 된다.</p>
<span class="math display">\[\begin{aligned}
\hat{q_{\boldsymbol{\phi}}} &amp;= \underset{q_{\boldsymbol{\phi}}}{\text{argmax}}\,\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}}) \\
&amp;= \underset{q_{\boldsymbol{\phi}}}{\text{argmax}}\,\mathbb{E}_{Z\sim q}\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}}) \right]
\end{aligned}\]</span>
<p>또한 <span class="math inline">\({\bf{z}}\)</span>는 integral후에 사라지는 적분변수이며 <span class="math inline">\({\bf{x}}\)</span>는 관측값이다. 결국 <span class="math inline">\(q_{\boldsymbol{\phi}}\)</span>를 control하여 KL-divergence를 maximize하는 것은 <span class="math inline">\(\boldsymbol{\phi}\)</span>를 control하여 KL-divergence를 maximize하는 <span class="math inline">\(\hat{\boldsymbol{\phi}}\)</span>를 찾는 것과 같은 문제이다.</p>
<span class="math display">\[\begin{aligned}
\hat{\boldsymbol{\phi}} = \underset{\boldsymbol{\phi}}{\text{argmax}}\,\mathcal{L}(\boldsymbol{\phi};{\boldsymbol{\theta}},x)
\end{aligned}\]</span>
<ul>
<li>maximization 과정에서는 <span class="math inline">\(\boldsymbol{\phi}\)</span>만 움직이는 변수 취급하므로 <span class="math inline">\({\boldsymbol{\theta}}\)</span>는 일단 고정된 값으로 취급하였다.</li>
</ul>
<p>정리하자면 문제는 원래 우리가 임의로 설정한 posterior인 <span class="math inline">\(q_{\boldsymbol{\phi}}\)</span>를 posterior인 <span class="math inline">\(p_{\boldsymbol{\theta}}\)</span>와 비슷하게 만드는 문제였다. 이는 KL-divergence를 minimize하는 <span class="math inline">\(q_{\boldsymbol{\phi}}\)</span>를 찾는 것이었으며 수식전개를 통해서 결국에는 ELBO를 maximize하는 <span class="math inline">\(\boldsymbol{\phi}\)</span>를 찾는 문제와 같음을 알 수 있다. 문제를 끝까지 푸는 건 잠시 뒤로 미루고 1번째 문제를 푸는 방법에 대해서 생각해보자.</p>
</section>
<section id="estimate-boldsymboltheta-via-mle" class="level2">
<h2 class="anchored" data-anchor-id="estimate-boldsymboltheta-via-mle"><span style="color:black"><strong>estimate <span class="math inline">\(\boldsymbol{\theta}^*\)</span> via MLE</strong></span></h2>
<p>위에서 2번 문제를 푸는 방법을 알았기에 이제 해결해야 할 것은 1번문제인 true parameter인 <span class="math inline">\(\theta^*\)</span>를 구하는 것이다. 이 문제도 풀게되면 True posterior,True likelyhood,True prior을 근사적으로 구하며 randomprocess(encoder,decoder)를 묘사할 수 있다.</p>
<p>우리는 true parameter인 <span class="math inline">\(\theta^*\)</span>에 가장 근접하도록 <span class="math inline">\(\theta\)</span>를 구해야 하기 때문에 먼저 <span class="math inline">\(\theta^*\)</span>에 대해 생각해보자. <span class="math inline">\(\theta^*\)</span>은 과연 어떤 값일까? 아마도 <span class="math inline">\(\theta^*\)</span>는 관측된 데이터 <span class="math inline">\({\bf{x}}\)</span>에 대해서 가장 높은 확률을 부여하는 값일 것이다. 따라서 우리는 관측된 데이터에 대해서 가장 높은 확률을 부여하는 <span class="math inline">\(\theta\)</span>를 찾아야 한다. 이는 전체적으로 MLE의 방법과 동일하다.</p>
<span class="math display">\[\begin{aligned}
\hat{\theta} = \underset{{\bf{\theta}}}{\text{argmax}}\,\text{log}\,p_{\boldsymbol{\theta}}(\bf{x})
\end{aligned}\]</span>
<p>문제는 <span class="math inline">\(p_{\boldsymbol{\theta}}{\bf{({\bf{x}})}} = \int_z p_{\boldsymbol{\theta}}({\bf{z}})p_{\boldsymbol{\theta}}({\bf{x|z}})d{\bf{z}}\)</span>이다. problem setting에서 언급했듯이 구할 수 없는 값이다. 여기서 문제를 약간 우회하여 <span class="math inline">\(\text{log}\,p_{\boldsymbol{\theta}}(\bf{x})\)</span>의 lowerbound인 ELBO를 maximize하는 문제로 바꾼다. 즉 다음과 같다.</p>
<span class="math display">\[\begin{aligned}
&amp;\hat{\theta} = \underset{{\bf{\theta}}}{\text{argmax}}\,\text{log}\,p_{\boldsymbol{\theta}}(\bf{x}) \approx \underset{{\bf{\theta}}}{\text{argmax}}\,\mathcal{L}({\boldsymbol{\theta}};\boldsymbol{\phi},{\bf{x}}) \\
&amp;\text{where }\\
&amp;\text{evidence} := \text{log}p_{\boldsymbol{\theta}}({\bf{x}})\\
&amp;\text{log}\,p_{\boldsymbol{\theta}}({\bf{x}}) \geq \text{ELBO} := \mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}})=\mathbb{E}_{Z\sim q}\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}}) \right]
\end{aligned}\]</span>
<ul>
<li><span class="math inline">\(\theta\)</span>만 바꿔가며 위의 문제를 풀게되므로 <span class="math inline">\(\boldsymbol{\phi}\)</span>는 fixed된 값이며 ;뒤에 위치시켰다.</li>
</ul>
<p>물론 ELBO도 <span class="math inline">\(z\)</span>에 대한 적분이기 때문에 풀 수 없음을 알 수 있다. 하지만 이제 문제가 ELBO를 optimization문제로 바뀌었음을 알 수 있으며 우리는 ELBO 하나의 값에 대해서 집중적으로 풀어낼 수 있는 방법을 사용할 것이다.(쉽게말하면 ELBO 하나만 샘플링해서 풀기위해서 이렇게 바꾼 것이다.)</p>
<span class="math display">\[\begin{aligned}
&amp;\boldsymbol{\theta,\phi}=\underset{{\boldsymbol{\theta,\phi}}}{\text{argmax}}\,\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};\bf{x})\\
&amp;\text{where }\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}},{\bf{x}}) = \mathbb{E}_{Z\sim q}\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}}) \right]
\end{aligned}\]</span>
<ul>
<li><span class="math inline">\(\boldsymbol{\theta,\phi}\)</span> : parameters of function <span class="math inline">\(q\)</span> and <span class="math inline">\(p\)</span></li>
<li><span class="math inline">\({\bf{x}}\)</span> : single observation</li>
</ul>
</section>
<section id="solving-optimization-problem" class="level2">
<h2 class="anchored" data-anchor-id="solving-optimization-problem"><span style="color:black"><strong>Solving Optimization Problem</strong></span></h2>
<p>문제는 전적으로 이제 ELBO를 Optimization하는 문제로 바뀌었다. 우리는 ELBO에 Gradient ascent를 사용하여 optimal한 <span class="math inline">\(\hat{\boldsymbol{\phi}},\hat{\boldsymbol{\theta}}\)</span>를 구할것이다. 그러기전에 먼저 ELBO를 살펴보자.</p>
<span class="math display">\[\begin{aligned}
\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}},{\bf{x}}) &amp;= \mathbb{E}_{Z\sim q}\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}}) \right] \\
&amp;= \int_z\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}})\right]q({\bf{z|x}})d{\bf{z}}
\end{aligned}\]</span>
<p>이전에도 계속 문제였던 <span class="math inline">\(d\bf{{z}}\)</span>가 또 등장한다. 그러므로 우리는 expectation을 구할 수 없다. 따라서 samping을 통해 expectation을 근사적으로 구하는 Monte carlo method를 사용한다. 이는 다음과 같다.</p>
<span class="math display">\[\begin{aligned}
\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}}) &amp;= \mathbb{E}_{Z\sim q}\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}}) \right] \\
&amp;= \int_z\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}})\right]q({\bf{z|x}})d{\bf{z}} \\
&amp;\approx \frac{1}{L}\sum_{l=1}^L[\text{log}\,p_{\boldsymbol{\theta}}({\bf{x,z}}^{(l)}) - \text{log}\,q_{\boldsymbol{{\phi}}}({\bf{z}}|{\bf{x}}^{(l)})]
\end{aligned}\]</span>
<p><span class="math display">\[\text{where } {\bf{z}}^{(l)} \sim q_{\boldsymbol{\phi}}({\bf{z}})\]</span></p>
<p>ELBO를 근사적으로 구했으므로 최적화를 위해 gradient를 구해야 한다. 먼저 <span class="math inline">\(\theta\)</span>에 대한 gradient를 구해보자.</p>
<span class="math display">\[\begin{aligned}
\nabla_{\theta}\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}}) &amp;= \mathbb{E}_{Z\sim q}\left[\nabla_\theta\text{log}\,p_{\boldsymbol{\theta}}({\bf{x,z}})\right]\\
&amp;\approx \frac{1}{L}\sum_{l=1}^L\nabla_\theta\text{log}\,p_{\boldsymbol{\theta}}({\bf{x,z}}^{(l)})
\end{aligned}\]</span>
<ul>
<li>뒷항은 <span class="math inline">\(\theta\)</span>에 대해 parameterize되어있지 않으므로 미분과정에서 제거됨.</li>
</ul>
<p><span class="math inline">\(\theta\)</span>에 대한 gradient는 전혀 문제없이 잘 구해짐을 알 수 있다. 하지만 문제는 <span class="math inline">\(\phi\)</span>에 대한 gradient를 구할 때 발생한다. <span class="math inline">\(f({\bf{z}}) = \text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}})\)</span>라 할 때 gradient는 다음과 같이 구해진다.(증명생략)</p>
<span class="math display">\[\begin{aligned}
\nabla_{\phi}\mathbb{E}_{q_{\boldsymbol{\phi}}({\bf{z})}}[f({\bf{z}})] &amp;= \mathbb{E}_{q_{\boldsymbol{\phi}(\bf{z})}} \nabla_{q_{\boldsymbol{\phi}(\bf{z})}}\text{log}\,q_{\phi}({\bf{z}}) \\&amp;\approx \frac{1}{L}\sum_{l=1}^L f({\bf{z}})\nabla_{q_{\boldsymbol{\phi}({\bf{z}})}}\text{log}\,q_{\boldsymbol{\phi}}({\bf{z}}^{(l)})
\end{aligned}\]</span>
<p>갑자기 로그가 들어간 형태로 gradient가 구해진다. 이러한 gradient에 대한 추정량은 unbiased estimator이지만 high variance를 가진다고 한다. 그러므로 샘플링을 아주많이(거의무한하게)취하는 것이 아니면 이 값은 수렴하지 않는 값이므로 적당한 샘플링을 통해서 문제를 풀어야 하는 우리의 방식에는 맞지않는다. 그러므로 샘플을 대체적으로 취하는 방식인 reparameterization을 사용한다. 이를 사용하면 unbiased estimator를 얻을뿐만 아니라 low variance를 가진다. (더 자세한 논의는 <a href="https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important">링크</a>에서 확인 가능)</p>
<p><strong>(reparameterization trick)</strong><br> <span class="math inline">\({\bf{z}}\)</span>가 conditional distribution인 <span class="math inline">\(q_{\phi}(\bf{z|x})\)</span>를 따르는 continuous 또는 discrete random-variable일때 <span class="math inline">\({\bf{z}} = g_{\phi}(\boldsymbol{\epsilon},\bf{x})\)</span>인 g에 대해 deterministic한 random variable로 나타낼 수 있다는 것이다.(where, <span class="math inline">\({\bf{\epsilon}}\sim p(\boldsymbol{\epsilon})\)</span>)</p>
<p>그러므로 우리는 reparameterization trick을 사용해서 ELBO를 Monte carlo method를 통해 다르게 생각할 수 있다. 이렇게 ELBO를 구하면 Gradient estimator는 unbiased일 뿐만 아니라 low variance를 가진다.</p>
<span class="math display">\[\begin{aligned}
\tilde{\mathcal{L}}^A(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}}) &amp;= \mathbb{E}_{Z\sim q}\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}}) \right] \\
&amp;= \int_z\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}})\right]q({\bf{z|x}})d{\bf{z}} \\
&amp;\approx \frac{1}{L}\sum_{l=1}^L[\text{log}\,p_{\boldsymbol{\theta}}({\bf{x,z}}^{(l)}) - \text{log}\,q_{\boldsymbol{{\phi}}}({\bf{z}}|{\bf{x}}^{(l)})]
\end{aligned}\]</span>
<p>$$ {}^{(l)} = q_{}({}^{(l)},{}),{}p()</p>
<ul>
<li>A는 type A를 의미함.</li>
</ul>
<p>논문에는 이러한 estimator말고도 다른 방법으로 구한 것도 있다. 이는 다음과 같다.</p>
<span class="math display">\[\begin{aligned}
\tilde{\mathcal{L}}^B(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}}) = -D_{KL}(q_{\boldsymbol{\phi}}({\bf{z|x}})||p_\theta({\bf{z}})) + \frac{1}{L}\sum_{l=1}^L(\text{log}\,p_\theta({\bf{x}}|{\bf{z}}^{(l)})
\end{aligned}\]</span>
<p>$$ {}^{(l)} = q_{}({}^{(l)},{}),{}p()</p>
<p>두번째 estimator를 통해서 ELBO를 maximization하는 최적화 문제를 푸는것이 왜 auto-encoder와 연결되는지 알 수 있다. ELBO를 maximize하려면 첫번째 term을 가능한 작게 해야 하는데 이는 observation을 보고 latent variable가 따르는 예측한 값이 얼마나 차이가 나느냐이다.(encoder의 성능?인 것 같다.)두번째 텀은 decoder가 얼마나 latenr variable에서 input space로 mapping을 잘 하느냐를 의미한다.(decoder의 성능?)</p>
<p>여기까지 단 한개의 관측치에 대해서 모든 과정을 수행해봤다. 사실은 한 개의 관측치가 아니라 data set의 크기가 m인 mini-batch에 대하여 위의 과정을 수행해줘야 하므로 이것을 고려한 ELBO는 다음과 같다.</p>
<span class="math display">\[\begin{aligned}
\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{X}}) \approx
\tilde{L}^M(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{X}})=\frac{N}{M}\sum_{i=1}^M\tilde{L}(\boldsymbol{\theta},\boldsymbol{\phi};{\bf{x}}^{(i)})
\end{aligned}\]</span>
<p><span class="math display">\[\text{where } {\bf{z}}^{(l)} \sim q_{\boldsymbol{\phi}}({\bf{z}})\]</span></p>
</section>
</section>
<section id="appendix" class="level1">
<h1><span style="color:black"><strong>Appendix</strong></span></h1>
</section>
<section id="evidence-lower-boundelbo" class="level1">
<h1><span style="color:black"><strong>evidence lower bound(ELBO)</strong></span></h1>
<p>먼저 evidence는 다음과 같이 marginzalization된 loglikelyhood로 정의한다.</p>
<p><span class="math display">\[\text{evidence} := \text{log}\,p(x;{\boldsymbol{\theta}}) = \int_z p_{{\boldsymbol{\theta}}}({\bf{x,z}})dz\]</span></p>
<p>evidence를 쭉 전개하면 다음과 같다.</p>
<span class="math display">\[\begin{aligned}
\text{log}\,p(x;{\boldsymbol{\theta}}) &amp;= \int_z p_{{\boldsymbol{\theta}}}({\bf{x,z}})dz \\
&amp;=\text{log}\,\int_z \frac{p_{{\boldsymbol{\theta}}}({\bf{x,z}})}{q_{\boldsymbol{\phi}}({\bf{z|x}})}q_{\boldsymbol{\phi}}({\bf{z|x}})dz \\
&amp;=\text{log}\,\mathbb{E}_{Z\sim q}\left[\frac{p_{{\boldsymbol{\theta}}}({\bf{x,z}})}{q_{\boldsymbol{\phi}}({\bf{z|x}})} \right]
\end{aligned}\]</span>
<p><a href="https://ko.wikipedia.org/wiki/%EC%98%8C%EC%84%BC_%EB%B6%80%EB%93%B1%EC%8B%9D">Jenson’s inequality</a> <span class="math inline">\(f(E[X])\leq E[f({\bf{x}})]\)</span>에 의하여 evidence의 lowerbound를 찾을 수 있다. 이를 evidence lower bound(ELBO)라 정의한다.</p>
<span class="math display">\[\begin{aligned}
&amp;\text{log}\,p(x;{\boldsymbol{\theta}}) \geq \mathbb{E}_{Z\sim q}\left[\text{log}\,\frac{p_{{\boldsymbol{\theta}}}({\bf{x,z}})}{q_{\boldsymbol{\phi}}({\bf{z|x}})} \right]\\
&amp;\mathcal{L(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}})} := \mathbb{E}_{Z\sim q}\left[\text{log}\,\frac{p_{{\boldsymbol{\theta}}}({\bf{x,z}})}{q_{\boldsymbol{\phi}}({\bf{z|x}})} \right] = \mathbb{E}_{Z\sim q}\left[\text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x,z}})-\text{log}\,q_{\boldsymbol{\phi}}({\bf{z|x}}) \right]
\end{aligned}\]</span>
<ul>
<li>evidence를 <span class="math inline">\(\boldsymbol{\phi},{\boldsymbol{\theta}}\)</span>의 함수로 notation한 이유는 optimization 과정에서 변수로 보고 사용하기 때문이다.(MLE에서 parameter는 하나의 고정된 상수이지만 일단은 변수로 보고 likelyhood의 max값을 찾는 과정과 비슷한 느낌인 것 같다.)</li>
<li>관측값<span class="math inline">\({\bf{x}}\)</span>는 고정이므로 ;뒤에 놓았다.(이것도 MLE에서 관측한 값은 고정인 느낌과 같다.)</li>
</ul>
</section>
<section id="kl-divergence-전개" class="level1">
<h1><span style="color:black"><strong>KL-divergence 전개</strong></span></h1>
<span class="math display">\[\begin{aligned}
\text{D}_{KL}[q_{\boldsymbol{\phi}}({\bf{z|x}})||p_{\boldsymbol{\theta}}({\bf{z|x}})] &amp;:= \int_zq_{\boldsymbol{\phi}}
({\bf{z|x}})\text{log}\frac{q_{\boldsymbol{\phi}}({\bf{z|x}})}{p_{{\boldsymbol{\theta}}}({\bf{z|x}})}dz \\
&amp;= \int_zq_{\boldsymbol{\phi}}({\bf{z|x}})\text{log}\frac{q_{\boldsymbol{\phi}}({\bf{z|x}})p_{{\boldsymbol{\theta}}}({\bf{x}})}{p_{\boldsymbol{\theta}}({\bf{x,z}})}dz \\
&amp;= \int_zq_{\boldsymbol{\phi}}({\bf{z|x}})\text{log}\frac{q_{\boldsymbol{\phi}}({\bf{z|x}})}{p_{{\boldsymbol{\theta}}}({\bf{x,z}})}dz  + \int_z q_{\boldsymbol{\phi}}({\bf{z|x}})\text{log}\,p_{\boldsymbol{\theta}}({\bf{x}})dz\\
&amp;= -\mathcal{L}(\boldsymbol{\phi},{\boldsymbol{\theta}};{\bf{x}}) + \text{log}\,p_{{\boldsymbol{\theta}}}({\bf{x}})
\end{aligned}\]</span>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="hoyeon1234/sin-hoyeon" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>