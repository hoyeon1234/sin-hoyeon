[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "전북대학교 IT응용시스템 공학과 신호연 sinhoyeon0514@gmail.com"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HIHO",
    "section": "",
    "text": "Untitled\n\n\n\n\n\n\n\n\n\n \n\n\n\nUntitled\n\n\n\n\n\n\n\n\n\n \n\n\n\nUntitled\n\n\n\n\n\n\n\n\n\n\n\n\n\nBatch Normalization(작성중)\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\nBellman Equation\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nAuto-Encoding Variational Bayes\n\n\n\n2/22/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nEigendecomposition & Property\n\n\n\n2/10/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuadratic Form(작성중)\n\n\n\n2/10/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nDiagonalization of symmetric matrix(정리중)\n\n\n\n2/8/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDQN\n\n\n\n2/3/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\neigenvalue & eigenvector\n\n\n\n1/31/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[강화학습] 2-1 Markov Decision process and property\n\n\nMDP와 중요한 property 정리\n\n\n\n1/22/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n[강화학습] 1 - 강화학습 용어정리\n\n\n강화학습 공부하면서 용어정리\n\n\n\n1/21/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[강화학습] 2-2 Reward & Return & State Value f & Action Value f\n\n\n\n1/21/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDQN review\n\n\n\n1/20/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[PRML 읽기] 1 - 확률론 개요\n\n\nSum rule, Product rule, Baye’s rule,random variable independence\n\n\n\n1/15/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n[PRML 읽기] 2 - 확률론 개요(작성중 …)\n\n\nprobability density, expectation and covariance, Bayesian probabilities,Gausian distribution\n\n\n\n1/15/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimension Reduction using Auto Encoder with pytorch\n\n\n\n1/12/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nimport\n\n\n\n1/12/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[프로그래머스]Lv.1시저암호\n\n\n\n1/9/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[프로그래머스]Lv1.이상한 문자 만들기\n\n\n\n1/9/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[프로그래머스]Lv1.크기가 작은 부분 문자열\n\n\n\n1/9/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeast Squares\n\n\n열공간(column space)과 정사영(projection)으로 접근한 최소제곱법(least squares)\n\n\n\n1/8/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnp.meshgrid\n\n\n\n1/8/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n확률론 용어정리\n\n\nrandom variable,event,sample space,probability distribution,randomsample,realization\n\n\n\n1/8/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinite Difference Method with np.gradient\n\n\n\n1/7/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplotly 시각화 모음\n\n\n\n1/6/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAx=b의 해의 갯수 알아내기\n\n\n\n1/5/23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrank & null space(kernel)\n\n\n\n1/5/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nLinear Combination & Span\n\n\n\n1/3/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n행렬곱에 대한 여러가지 관점\n\n\n\n1/2/23\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nMultinomial Logistic Regression & Softmax Regression\n\n\n\n12/30/22\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n카테고리 분포\n\n\n\n12/30/22\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMLE & MAP (작성중)\n\n\n\n12/29/22\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n확률분포에서 ;와|의 사용\n\n\n\n12/27/22\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression\n\n\n\n12/26/22\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n파이썬 - 변수,할당문,인터닝\n\n\n\n12/25/22\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Regression\n\n\n\n12/24/22\n\n\n\n\n\n\n\n\n\n\n \n\n\n\npytorch로 Rnn구현하기\n\n\n\n12/24/22\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nDiagonalization of symmetric matrix(정리중)\n\n\n\n2/9/22\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/coading test/programmers시저암호.html",
    "href": "posts/coading test/programmers시저암호.html",
    "title": "[프로그래머스]Lv.1시저암호",
    "section": "",
    "text": "문제\n\n\n\n나의 풀이\n\ndef solution(s, n):\n    upper_ch = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n    answer = \"\"\n    for el_s in s:\n        #1.맨 마지막 리턴을 위해 원래 문자가 소문자인지 대문자인지 기억 and 대문자에서 검색할것이기 때문에 대문자로 변환\n        #대문자로 변환된 문자열 s의 각각의 문자,대소문자 여부\n        if el_s == \" \":\n            answer += \" \"\n        elif el_s.isupper() == True:\n            was_upper = True\n        else:\n            was_upper = False\n            el_s = el_s.upper()\n        #2.인덱스 숫자가 upper_ch에서 벗어날때 아닐때 처리\n        for idx,up_ch in enumerate(upper_ch):\n            if el_s == up_ch and idx + n <= len(upper_ch)-1:\n                find_idx = idx+n\n                if was_upper == True:\n                    answer += upper_ch[find_idx]\n                else:\n                    answer += upper_ch[find_idx].lower()        \n            elif el_s == up_ch and idx + n > len(upper_ch)-1:\n                find_idx = n-len(upper_ch[idx:])\n                if was_upper == True:\n                    answer += upper_ch[find_idx]\n                else:\n                    answer += upper_ch[find_idx].lower()  \n    return answer\n\n\n\n다른 풀이\n\ndef caesar(s, n):\n    lower_list = \"abcdefghijklmnopqrstuvwxyz\"  \n    #소문자도 리스트로 만듦 \n    #좋은점->대소문자 여부를 기억하는 코드 불필요(조건문)\n    #안좋은점->소문자로 이뤄진 리스트를 만드는데 그만큼의 메모리 필요\n    upper_list = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" \n    \n    \n    \n    result = [] \n    #문자열들을 저장할 list를 만듦\n    #mutable로 붙이는 것과 immutable로 붙이는 것 차이\n    #속도 -> \n    #mutable이 더 빠름,\n    #그러나 garbage collector도 고려시 스캔범위가 너무커서 느려질수도?\n    #메모리 -> immutable이 더 적게들을 듯(리스트는 이중포인터같은 구조라서 이렇게 예상됨)\n    for i in s:\n        if i == \" \":\n            result.append(\" \")\n        elif i.islower() is True:\n            new_ = lower_list.find(i) + n\n            result.append(lower_list[new_ % 26]) \n            #나머지로 계산하는 방식,이게 더 간단하고 좋은듯\n            #반복문이 문자열에 대해서 돌다보니 문자열과 문자열의 인덱스 위주로 너무 생각함\n            #어떤 숫자(여기서는 인덱스)보다 크거나 같을때에 다시 0부터 줘야하는 상황? -> 나머지 활용\n        else:\n            new_ = upper_list.find(i) + n\n            result.append(upper_list[new_ % 26])\n    return \"\".join(result)\n\n나중에 볼 링크 링크1 링크2 링크3"
  },
  {
    "objectID": "posts/coading test/programmers이상한문자만들기.html",
    "href": "posts/coading test/programmers이상한문자만들기.html",
    "title": "[프로그래머스]Lv1.이상한 문자 만들기",
    "section": "",
    "text": "문제\n\n\n\n나의 풀이\n\ndef solution(s):\n    words = s.split(\" \") #스플릿 함수 헷갈리는 부분이 있었음 - 정리\n    answer = \"\"\n    for wd in words:\n        for idx,chr in enumerate(wd):\n            print(idx,chr)\n            if idx % 2 == 0:\n                chr = chr.upper()\n            else:\n                chr = chr.lower()\n            answer += chr\n        answer+= \" \"\n    return answer[:-1]\n\n\n\nsplit 메서드(함수)\n\nt=\"sdsa  sd\"\nhelp(t.split)\n\nHelp on built-in function split:\n\nsplit(sep=None, maxsplit=-1) method of builtins.str instance\n    Return a list of the words in the string, using sep as the delimiter string.\n    \n    sep\n      The delimiter according which to split the string.\n      None (the default value) means split according to any whitespace,\n      and discard empty strings from the result.\n    maxsplit\n      Maximum number of splits to do.\n      -1 (the default value) means no limit.\n\n\n\nstring객체의 인스턴스 즉,문자열에 대해서만 사용할 수 있는 메서드 sep파라미터에 전달한 인수를 구분자로 사용하여 문자열안에 있는 단어들을 가져옴. 가져온 단어들은 리스트의 원소가 되어 반환됨 Parameter - sep - …\nReturn - list[word1,word2,…] (구분자를 통하여 구분된 단어들,기본값은 공백(space))\n\n\n예시\n\n#문자열 내에 구분기준이 없는 경우?\n#sep = \" \"으로 기본값으로 설정되어 있음. 공백이 없으므로 그냥 문자열을 리스트에 넣어서 반환\n_t = \"abcde\"\nanswer = _t.split()\nprint(answer)\n\n['abcde']\n\n\n\n#문자열 내에 구분기준이 있는 경우?\n_t = \"ab cd esda dg\"\nanswer = _t.split()\nprint(answer)\n\n['ab', 'cd', 'esda', 'dg']\n\n\n\n_t = \"abtcdtesdatdg\"\nanswer = _t.split(\"t\")\nprint(answer)\n\n['ab', 'cd', 'esda', 'dg']\n\n\n\n_t = \"ab;;cd;;esd;;atdg\"\nanswer = _t.split(\";;\")\nprint(answer)\n\n['ab', 'cd', 'esd', 'atdg']"
  },
  {
    "objectID": "posts/coading test/programmers크기가작은부분문자열.html",
    "href": "posts/coading test/programmers크기가작은부분문자열.html",
    "title": "[프로그래머스]Lv1.크기가 작은 부분 문자열",
    "section": "",
    "text": "문제\n\n\n\n나의 풀이\n\ndef solution(t, p):\n    t_len = len(t);p_len = len(p)\n    answer = 0\n    p = int(p)\n    for idx in range(t_len-p_len+1):\n        num = int(t[idx:idx+p_len])\n        if num <= p:\n            answer+=1\n        else:\n            pass\n    return answer"
  },
  {
    "objectID": "posts/DL/Auto Encoder Dimension Reduction.html",
    "href": "posts/DL/Auto Encoder Dimension Reduction.html",
    "title": "Dimension Reduction using Auto Encoder with pytorch",
    "section": "",
    "text": "import torch.nn as nn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nimport os\nimport numpy as np\nimport torch\ntest_path = \"./test.csv\"\ntrain_path = \"./train.csv\"\n\n\n# %pip install plotly (jupyter notebook)\nfrom plotly.offline import iplot\nimport plotly.graph_objs as go\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n#pio.renderers.default = 'iframe_connected'\n#pio.renderers.default = \"vscode\"\npio.renderers.default = \"plotly_mimetype+notebook\""
  },
  {
    "objectID": "posts/DL/Auto Encoder Dimension Reduction.html#encoding-dimension3",
    "href": "posts/DL/Auto Encoder Dimension Reduction.html#encoding-dimension3",
    "title": "Dimension Reduction using Auto Encoder with pytorch",
    "section": "encoding dimension=3",
    "text": "encoding dimension=3\n\ntraining autoencoder\n\ntorch.manual_seed(201711375)\nautoencoder_3 = AutoEncoder(47,3)\nloss_fn = torch.nn.MSELoss()\nrelu = torch.nn.LeakyReLU()\noptimizer = torch.optim.Adam(autoencoder_3.parameters(),lr=0.001)\n\n\nfor epoch in range(20000):\n    #1.yhat\n    out = autoencoder_3(X_train_ohe)\n    #2\n    loss = loss_fn(out,X_train_ohe)\n    #3\n    loss.backward()\n    if epoch % 10000 == 0:\n        print(f\"epoch:{epoch} loss:{loss.tolist()}\")\n    #4\n    optimizer.step()\n    optimizer.zero_grad()\n\nepoch:0 loss:0.5274774432182312\nepoch:10000 loss:0.11526338756084442\n\n\n\n\nvisualization\n\nclass_map_inv = {}\nfor key,value in class_map.items():\n    class_map_inv[value] = key\nclass_map_inv\n\n{0: 'A', 1: 'B', 2: 'C'}\n\n\n\ndt_dim3 = pd.DataFrame({\"class\":Y_train_ohe})\ndt_dim3 = pd.concat([pd.DataFrame(np.array(autoencoder_3.encoder(X_train_ohe).tolist())),dt_dim3],axis=1)\ndt_dim3 = dt_dim3.rename(columns = {0:\"x\",1:\"y\",2:\"z\"})\n\n\ncount = 0\ndata = []\nfor cl in dt_dim3[\"class\"].unique():\n    cond = dt_dim3[\"class\"] == cl\n    _data = dt_dim3.loc[cond,:]\n    x = _data.x.tolist()\n    y = _data.y.tolist()\n    z = _data.z.tolist()\n    if count == 0:\n        color = \"red\"\n    elif count == 1:\n        color = \"blue\"\n    else:\n        color = \"black\"\n    trace=go.Scatter3d(\n        x=x,\n        y=y,\n        z=z,\n        mode=\"markers\",\n        marker = dict(color = color,size=2),\n        name = str(class_map_inv[cl])\n        )\n    data.append(trace)\n    count+=1\n\nlayout = go.Layout(title=dict(text = \"3-dimension \"))\n\n#4. figure\nfig = go.Figure(data=data,layout=layout)\nfig.show()"
  },
  {
    "objectID": "posts/DL/Auto Encoder Dimension Reduction.html#encoding-dimension10",
    "href": "posts/DL/Auto Encoder Dimension Reduction.html#encoding-dimension10",
    "title": "Dimension Reduction using Auto Encoder with pytorch",
    "section": "encoding dimension=10",
    "text": "encoding dimension=10\n\ntorch.manual_seed(201711375)\nautoencoder_3 = AutoEncoder(47,10)\nloss_fn = torch.nn.MSELoss()\nrelu = torch.nn.LeakyReLU()\noptimizer = torch.optim.Adam(autoencoder_3.parameters(),lr=0.001)\n\n\nfor epoch in range(40000):\n    #1.yhat\n    out = autoencoder_3(X_train_ohe)\n    #2\n    loss = loss_fn(out,X_train_ohe)\n    #3\n    loss.backward()\n    if epoch % 10000 == 0:\n        print(f\"epoch:{epoch} loss:{loss.tolist()}\")\n    #4\n    optimizer.step()\n    optimizer.zero_grad()\n\nepoch:0 loss:0.3828417658805847\nepoch:10000 loss:0.060432590544223785\nepoch:20000 loss:0.06043253839015961\nepoch:30000 loss:0.060432031750679016"
  },
  {
    "objectID": "posts/DL/Linear Regression.html",
    "href": "posts/DL/Linear Regression.html",
    "title": "Linear Regression",
    "section": "",
    "text": "선형회귀에 대해서 정리한 글입니다."
  },
  {
    "objectID": "posts/DL/Linear Regression.html#assumption-modeling",
    "href": "posts/DL/Linear Regression.html#assumption-modeling",
    "title": "Linear Regression",
    "section": " Assumption & modeling",
    "text": "Assumption & modeling\n\n\nText(0.5, 1.0, 'n=200')\n\n\n\n\n\n우리가 가진 데이터를 관찰해봅시다. 가장크게 눈에 띄는 사실은 x와 y사이의 관계가 선형적이라는 점입니다. 따라서 간단한 선형모형으로 독립변수와 종속변수사이의 관계를 모델링할 수 있을 것 같습니다. 조금 더 세부적으로 들어가서 각각의 x값에 대해서 y값을 관찰해 봅시다. 첫번째로 알 수 있는 점은 동일한 x값에 대해서도 서로다른 y값을 가지는 점들 데이터가 많이 있다는 것입니다. 이로부터 \\(y\\)가 \\(x\\)뿐만아니라 또다른 확률변수 \\(\\epsilon\\)의 값에 의해 결정된다는 것을 알 수 있습니다. 두번째로 x값에 의해서 찍히는 점의 위치(y)의 양상이 다르다는 점을 알 수 있습니다. x가 작으면 일반적으로 y는 낮은위치에서 점이 찍히고 x가 크면클수록 일반적으로 높은 위치에서 점이 찍히는 것을 알 수 있습니다.\n데이터를 관찰하면서 얻은 사실로부터 \\(x\\)와 \\(y\\)사이의 관계를 수학적으로 모델링 해보겠습니다. 첫번째 사실로부터 우리는 동일한 \\(x\\)라도 각각의 데이터에 대해서 어떤 또다른 값이 더해짐을 알 수 있습니다. 이렇게 뽑힐때마다 그 값이 다른 변수는 확률변수 \\(\\epsilon_i\\)를 더해줌으로서 표현할 수 있습니다. 여기서 오차가 따르는 분포에 대해서 가정을 합니다. 오차는 평균이 0이고 분산이 \\(\\sigma^2\\)인 정규분포를 따르는 확률변수라고 가정합니다.\n또한 두번째 사실로부터 우리는 \\(x\\)와 \\(y\\)는 커지면 커지고 작아지면 작아지는 관계임을 알 수 있습니다. 이러한 관계를 표현할 수 있는 방법은 여러가지가 있지만 선형회귀에서는 선형으로 이 관계를 표현합니다.\n\\[\\begin{aligned}\n&Y_i = w_0 + w_1x_1 + \\dots + w_Mx_M + \\epsilon_i={\\bf{x_i}^\\intercal}w + \\epsilon_i\\\\\n&\\text{where , }{\\bf{{\\bf{x_i}^\\intercal}}} = \\begin {bmatrix}0,x_{i,1},\\dots,x_{i,M} \\end {bmatrix} \\in \\mathbb{R^{1 \\times (M+1)},{\\bf{w}} = \\begin {bmatrix} w_0,w_1,\\dots,w_M\\end{bmatrix}}^\\intercal \\in \\mathbb{R^{(M+1)\\times 1}}\\\\\n\\quad\\quad\\quad &\\epsilon_i \\overset{i.i.d}{\\sim} \\mathcal{N}(0,\\sigma^2)\\,\\,(\\text{for } i=1,2,\\dots,N)\n\\end{aligned}\\]\n이렇게 \\({\\bf{x_i}^\\intercal}\\)와 \\(Y_i\\)사이의 관계를 정할 경우 각각의 \\(Y_i\\)안에 확률변수 \\(\\epsilon_i\\)가 \\(Y_i\\)도 마찬가지로 정규분로를 따르는 확률변수로 그 값이 \\(\\epsilon\\)에 의해 독립변수의 값이 동일하더라도 추출할때마다 다를 수 있습니다. \\(Y_i\\)도 확률변수이므로 정규분포를 따르는 확률변수이므로 중심위치와 변동을 확인하기 위해 기댓값과 분산을 구해볼 수 있습니다. 이때 \\(x\\)는 주어져 있으므로 그때의 확률분포에 대해서 계산하면 다음과 같습니다.\n\\[\\begin{aligned}\n&\\mathbb{E}[Y_i] = \\mathbb{E}[w_0 + \\dots + w_Mx_M+\\epsilon_i] = w_0 + w_1x_1 + \\dots + w_Mx_M={\\bf{x_i}^\\intercal}w \\\\\n&\\text{var}[Y_i] = \\text{var}[w_0 + \\dots + w_Mx_M+\\epsilon_i] = \\text{var}[\\epsilon_i] = \\sigma^2\n\\end{aligned}\\]\n위수식으로부터 각각의 \\(Y_i\\)에 대한 확률분포는 정규분포이며(\\(\\epsilon_i\\)에 의해) 기댓값은 \\(x\\)와 \\(w\\)에 의해 정해지지만 분산은 \\(\\sigma^2\\)으로 항상 동일하다는 점을 알 수 있습니다. 모두 정규분포를 따르지만 기댓값만 \\(x\\)에 의하여 달라집니다. 즉 다음과 같습니다.\n\\[\\begin{aligned}\n&Y_i|w;{\\bf{x_i}^\\intercal} \\sim \\mathcal{N}({\\bf{x_i}^\\intercal}{\\bf{w}},\\sigma^2)\\, \\text{ for } i = 1,2,\\dots,N\\\\\n&p(y_i|{\\bf{w}};{\\bf{x_i}^\\intercal}) = 정규분포식\n\\end{aligned}\\]\n이미지\n여기까지 우리가 가진 데이터를 기반으로 독립변수와 종속변사이의 관계를 선형모형을 만들어봤습니다. 그렇다면 궁극적인 목적인 unseen data에 적절하게 종속변수의 값을 예측하려면 어떻게 해야할까요?만약 학습데이터로부터 적절히 가중치인 \\(w\\)를 구할수만 있다면 독립변수가 입력되었때 대하여 종속변수가 따르는 확률분포(정규분포)를 알 수 있고 그 분포에서 가장 확률이 높은 곳의 종속변수의 값(정규분포에서는 xw)을 예측값으로 하면 됩니다. 또 다르게 생각하면 가중치를 구한다는 것은 데이터를 가장 잘 표현하는 직선(평면,초평면)을 얻은것이므로 입력x에 대하여 직선의 값을 읽어서 예측값으로 하면 됩니다. 어찌됐건 두 경우 모두 가중치를 구해야**하므로 우리의 목적은 이제 가중치를 구하는 것입니다."
  },
  {
    "objectID": "posts/DL/Linear Regression.html#point-estimation---mle",
    "href": "posts/DL/Linear Regression.html#point-estimation---mle",
    "title": "Linear Regression",
    "section": " Point Estimation - MLE",
    "text": "Point Estimation - MLE\n그렇다면 가장 적절한 가중치는 무엇일까요? 데이터가 주어질때 가중치에 확률이 다음과 같다고 해봅시다.\n\\[\\begin{aligned}\n&p({\\bf{w}}|D) = p_{{\\bf{w}}|Y_1,Y_2,\\dots,Y_N}(w|y_1,y_2,\\dots,y_N;{\\bf{X}})\\\\\n&\\text{where, } {\\bf{X}} =\n\\begin{bmatrix}\n--{\\bf{x_1^\\intercal}}--\\\\\n--{\\bf{x_2^\\intercal}}--\\\\\n\\vdots\\\\\n--{\\bf{x_N^\\intercal}}--\n\\end{bmatrix}\n\\end{aligned}\\]\n오른쪽식은 왼쪽식에서의 데이터\\(D\\)를 좀더 풀어적은 수식입니다. 만약 위와 같은 확률을 계산했을때 그 값이 작은 가중치는 가능성이 낮은 가중치이므로 우리가 찾는 적절한 가중치는 아닐것입니다. 반대로 확률이 높은 가중치는 가능성이 높은 가중치이기때문에 우리가 찾는 가중치라고 할 수 있겠습니다. 그러면 그냥 “저 확률을 가장 크게 하는 가중치를 찾으면 되겠다”라고 생각이 들지만 안타까운 점은 우리는 위와같은 (조건부)확률(분포)을 바로 알기가 어렵습니다.. 따라서 베이즈정리의 도움을 받습니다. 베이즈 정리는 다음과 같습니다.\n\\[\\begin{aligned}\n&p({\\bf{w}}|D) = \\frac{p(D|{\\bf{w}})p({\\bf{w}})}{p(D)} \\propto (D|{\\bf{w}})p({\\bf{w}})\n\\end{aligned}\\]\n수식에서 분모\\(p(D)\\)는 normalization constant라 하는 상수입니다. 그러므로 분자를 최대화하는 가중치를 구하면 되지만 MLE(maximum likelyhood estimation) 에서는 likelyhood인 \\(L = p(D|w)\\)만을 최대화 하는 것을 목적으로 합니다.\n\\[\\begin{aligned}\nL = p_{Y_1,Y_2,\\dots,Y_N|{\\bf{w}}}(y_1,y_2,\\dots,y_N|w;X)  &= p_{Y_1,Y_2,\\dots,Y_N|{\\bf{w}}}(y_1,y_2,\\dots,y_N|w;X)\\\\\n&= p_{Y_1,{\\bf{w}}}(y_1|{w},{\\bf{X}})\\dots p_{Y_N,{\\bf{w}}}(y_N|{w},{\\bf{X}}) \\\\\n&= \\prod_{n = 1}^{N}p_{Y_n|{\\bf{W}}}(y_n|w;{\\bf{X}}) = \\prod_{n = 1}^{N}\\mathcal{N}(y_n|{\\bf{x_n}^\\intercal}{\\bf{w}},\\sigma^2) \\\\\n&= \\prod_{i=1}^N \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{(y_n-{\\bf{x_n}}^\\intercal{\\bf{w}})^2}{2\\sigma^2} \\right\\}  \\\\\n\\end{aligned}\\]\nlog likelyhood를 구하면 다음과 같습니다. 로그를 취하는 이유는 최댓값을 가지는 \\({\\bf{w}}\\)가 변하지 않고 곱셈을 덧셈을 바꿔서 계산하기 더 편하기 때문입니다.\n\\[\\begin{aligned}\n\\text{lnL} &= \\text{ln}\\prod_{n=1}^N \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{(y_n-{\\bf{x_n}}^\\intercal{\\bf{w}})^2}{2\\sigma^2} \\right\\}  \\\\\n&= \\sum_{n=1}^N\\text{ln} \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\text{exp}\\left\\{-\\frac{(y_n-{\\bf{x_n}}^\\intercal{\\bf{w}})^2}{2\\sigma^2} \\right\\} \\\\\n&= \\sum_{n=1}^N \\text{ln}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} - \\frac{1}{2\\sigma^2} \\sum_{n=1}^{N}(y_n-{\\bf{x_n}}^\\intercal{\\bf{w}})^2 \\\\\n&= C_1 - C_2\\sum_{n=1}^{N}(y_n-{\\bf{x_n}}^\\intercal{\\bf{w}})^2\n\\end{aligned}\\]\n상수를 제외해도 최댓값의 위치는 변하지 않으므로 제외하고 loglikelyhood를 최대화 하는 가중치를 얻은것이 우리의 목표입니다. 이때의 가중치는 가중치에 대한 추정량이므로 \\(\\bf{\\hat{w}}\\)로 표기합니다.\n여기서 시그마에서부터 보면 흔히 경사하강법에서 쓰는 MSE가 보입니다. MSE는 선형회귀의 MLE에서 Negative log likelyhood를 구할때 나오는 항입니다.\npsuedo inverse에 의한 해를 구하면 다음과 같습니다.\n\\[\\begin{aligned}\n\\hat{{\\bf{w}}} = (\\bf{X^TX}^{-1})X^Ty\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/DL/Linear Regression.html#선형회귀의-loss-function",
    "href": "posts/DL/Linear Regression.html#선형회귀의-loss-function",
    "title": "Linear Regression",
    "section": " 선형회귀의 Loss function",
    "text": "선형회귀의 Loss function\n2번에서 구한 추정값 \\(\\hat{\\bf{W}}\\)이 얼마나 틀린지,부정확한지 알려주는 함수를 Loss function 또는 Cost function이라고 합니다. 선형회귀에서의 Loss function은 일반적으로 MSE를 사용하며 주어진 샘플에서 잔차(residual,\\(\\hat{y}_i-y\\))들을 전부 제곱하여 더한 값입니다.\n(Loss function) \\(MSE = \\Sigma_{i=1}^{i=n}(y_i - \\hat{y_i})^{2} = \\frac{1}{n}({\\bf{y} - \\bf{\\hat{y}}})^{T}({\\bf{y} - \\bf{\\hat{y}}}) = \\frac{1}{n}(\\bf{y}-X\\hat{\\bf{W}})^{T}(\\bf{y}-X\\hat{\\bf{W}})\\)\nMSE와 같은 Loss function은 우리의 추정이 얼마나 틀렸는지를 나타내는 \\(\\hat{\\bf{W}}\\)에 대한 함수입니다. 그러므로, loss function을 가장 최소화 하는 \\(\\bf{\\hat{W}}\\)을 찾아내면 확률변수사이의 선형관계인 \\(\\bf{W}\\)를 알아낼 수 있습니다.\n\n\nText(110, 15, 'residual')"
  },
  {
    "objectID": "posts/DL/Linear Regression.html#parameter-update",
    "href": "posts/DL/Linear Regression.html#parameter-update",
    "title": "Linear Regression",
    "section": " Parameter update",
    "text": "Parameter update\nn개의 독립변수를 가지는 다변수 스칼라 함수에 대한 Gradient는 수학적으로 다음과 같습니다.\n\\(\\nabla_{X}{f(x_1,x_2,...,x_n)} = (\\frac{\\partial f}{\\partial x_1},\\frac{\\partial f}{\\partial x_2},\\dots,\\frac{\\partial f}{\\partial x_n})\\) 다변수 스칼라 함수에 그레디언트를 취하면 벡터입니다.그러므로,그레디언트를 벡터(다변수)를 입력했을 때,벡터를 출력으로 하는 벡터함수라고 생각해도 무방합니다.중요한 사실은 임의의 공간상의 임의의 point \\(X\\)에서 스칼라함수에 대한 gradient of f = \\(-\\nabla_{X}{f}\\) 방향은 스칼라함수가 가장 급격하게 감소하는 방향이라는 사실입니다.(증명생략)\n위의 사실에 의하면,우리는 임의의 \\(\\hat{\\bf{W}}\\)에서 Loss function이 가장 급격하게 감소하는 방향을 찾을 수 있습니다. 그러므로 감소하는 방향을 찾고 이동하고 감소하는 방향을 찾고 이동하고 반복하다보면… 궁극적인 목적인 틀린정도를 최소화하는 즉,Loss function값이 가장 작은 \\(\\hat{\\bf{W}}\\)를 찾을 수 있습니다. \\(\\bf\\hat{W}\\)를 수정하는 구체적인 수식은 다음과 같습니다.\n(Gradient descent parameter update) \\(\\hat{\\bf{W}}_{t} = \\hat{\\bf{W}}_{t-1} - \\alpha\\times\\nabla_{W}{L}\\)\n\\(\\hat{\\bf{W}}_{t-1}\\)은 수정되기전의 가중치(벡터)이며 \\(\\hat{\\bf{W}_{t}}\\)는 파라미터를 한번 업데이트 한 후의 가중치(벡터)입니다. \\(t-1\\)의 \\(\\hat{\\bf{W_{t-1}}}\\)에 \\(-\\alpha\\times\\nabla_{W}{L}\\)를 더해줌으로서 \\(\\hat{\\bf{W}}_{t-1}\\)은 loss function이 가장 급격히(많이)감소하는 방향으로 이동하며 \\(\\hat{\\bf{W}}_{t}\\)가 됩니다. \\(\\alpha\\)는 학습률(learning rate)입니다. \\(\\hat{\\bf{W}}_{t-1}\\)과 곱해져서 얼마나 많이 또는 적게 움직일지를 결정합니다. 한번에 얼마나 이동할지에 비유한 “보폭”으로 생각할 수 있습니다.\n요약하자면, 경사하강법을 통하여 위와 같이 가중치\\(\\hat{\\bf{W}}\\)를 재귀적으로 업데이트 하면 loss function \\(L\\)이 가장 최소가 되는 지점의 \\(\\hat{\\bf{W}}\\)를 찾을 수 있습니다."
  },
  {
    "objectID": "posts/DL/Linear Regression.html#mse에-대한-더-상세한-전개",
    "href": "posts/DL/Linear Regression.html#mse에-대한-더-상세한-전개",
    "title": "Linear Regression",
    "section": " MSE에 대한 더 상세한 전개",
    "text": "MSE에 대한 더 상세한 전개\nMSE를 더 상세히 전개하면 다음과 같습니다. \\(MSE = \\Sigma_{i=1}^{i=n}(y_i - \\hat{y_i})^{2}\\) \\(= \\frac{1}{n}({\\bf{y} - \\bf{\\hat{y}}})^{T}({\\bf{y} - \\bf{\\hat{y}}})\\) \\(= \\frac{1}{n}(\\bf{y}-X\\hat{\\bf{W}})^{T}(\\bf{y}-X\\hat{\\bf{W}})\\) \\(= \\frac{1}{n}(\\bf{y^T - \\hat{\\bf{W}}^{T}\\bf{X}^{T})(\\bf{y} - \\bf{X}\\bf{\\hat{W}}})\\) \\(= \\frac{1}{n}(\\bf{y^Ty-y^TX\\hat{W}} - \\hat{W}X^Ty + \\hat{W}^TX^TX\\hat{W})\\)\n여기서 \\(\\bf{y^TX\\hat{W}} \\in \\bf{R}^{1 \\times 1}\\) 이므로 \\(\\bf{y^TX\\hat{W}} = (\\bf{y^TX\\hat{W}})^T = (\\bf{\\hat{W}X^Ty})\\)가 성립합니다. 그러므로 MSE를 정리하면 다음과 같습니다. (MSE) \\(MSE = \\frac{1}{n}(\\bf{y^Ty -2\\hat{W}X^Ty + \\hat{W}^TX^TX\\hat{W}})\\)"
  },
  {
    "objectID": "posts/DL/Linear Regression.html#gradient-descent에-대한-더-상세한-전개loss-mse일-경우",
    "href": "posts/DL/Linear Regression.html#gradient-descent에-대한-더-상세한-전개loss-mse일-경우",
    "title": "Linear Regression",
    "section": " Gradient Descent에 대한 더 상세한 전개(\\(Loss\\) = MSE일 경우)",
    "text": "Gradient Descent에 대한 더 상세한 전개(\\(Loss\\) = MSE일 경우)\n(Gradient of MSE) \\(\\nabla{L} = MSE\\) \\(= \\bf{\\frac{1}{n}\\frac{\\partial}{\\partial \\hat{W}}(\\bf{y^Ty - 2\\hat{W}^TX^T + \\hat{W}^TX^TX\\hat{W}})}\\) \\(= \\bf{\\frac{1}{n}}(\\bf{\\frac{\\partial}{\\partial \\hat{W}}}{y^{T}y} - \\frac{\\partial}{\\partial \\hat{W}}2\\hat{W}^{T}X^{T}y + \\frac{\\partial}{\\partial\\hat{W}}\\hat{W}^{T}X^{T}X\\hat{W})\\) \\(= \\bf{\\frac{1}{n}(\\frac{\\partial}{\\partial \\hat{W}}{y^{T}y} - \\frac{\\partial}{\\partial \\hat{W}}2y^TX\\hat{W} + \\frac{\\partial}{\\partial\\hat{W}}\\hat{W}^TX^TX\\hat{W})}\\) \\(= \\bf{\\frac{1}{n}[0 - 2X^Ty + (X^TX + X^TX)\\hat{W}]}\\) \\(= \\bf{\\frac{2}{n}X^T(X\\hat{W} - y)}\\)\n(parameter update) \\(\\bf{\\hat{W}_{t} = \\hat{W}_{t-1} - \\alpha \\times \\frac{2}{n}X^T(X\\hat{W} - y)}\\)"
  },
  {
    "objectID": "posts/DL/Linear Regression.html#결과해석",
    "href": "posts/DL/Linear Regression.html#결과해석",
    "title": "Linear Regression",
    "section": " 결과해석",
    "text": "결과해석\n200개의 샘플로부터 \\(\\bf{w}\\)를 추정하여 \\(\\hat{\\bf{w}}= (0.125,0.969)\\)를 얻었습니다. population regression model의 \\({\\bf{w}} = (w_0,w_1) = (0,1)\\)을 올바르게 추정했음을 알 수 있습니다. 아주 약간의 차이가 존재하는데 이 차이는 모집단에서 샘플을 더 얻거나 더 세밀하게 업데이트하면 최소화할 수 있습니다.\n\n#plt.title(\"w_1 : {} // w_0: {}\".format(round(W_hat[1].tolist()[0],3),round(W_hat[0].tolist()[0],3)))\nplt.title(\"Linear Regression\")\ntext=f\"What = ({round(t[0].tolist()[0],3)},{round(t[1].tolist()[0],3)})\"\nplt.plot(X[:,1],y,\"bo\",alpha=0.5)\nplt.plot(X[:,1],X@W_hat,\"r--\")\nplt.gca().axes.xaxis.set_visible(False)\nplt.gca().axes.yaxis.set_visible(False)\nplt.title(text)\n\nText(0.5, 1.0, 'What = (-0.125,0.969)')"
  },
  {
    "objectID": "posts/DL/Linear Regression.html#appendix",
    "href": "posts/DL/Linear Regression.html#appendix",
    "title": "Linear Regression",
    "section": " Appendix",
    "text": "Appendix"
  },
  {
    "objectID": "posts/DL/Linear Regression.html#mle의-해와-mse유도",
    "href": "posts/DL/Linear Regression.html#mle의-해와-mse유도",
    "title": "Linear Regression",
    "section": " MLE의 해와 MSE유도",
    "text": "MLE의 해와 MSE유도"
  },
  {
    "objectID": "posts/DL/Linear Regression.html#참고자료",
    "href": "posts/DL/Linear Regression.html#참고자료",
    "title": "Linear Regression",
    "section": " 참고자료",
    "text": "참고자료\nMaximum Likelihood Estimation(MLE) & Maximum A Posterior(MAP)"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html",
    "href": "posts/DL/Logistic Regression.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "로지스틱회귀에 대해서 정리한 글입니다."
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#기댓값에-대한-고찰",
    "href": "posts/DL/Logistic Regression.html#기댓값에-대한-고찰",
    "title": "Logistic Regression",
    "section": "기댓값에 대한 고찰",
    "text": "기댓값에 대한 고찰\n기댓값은 실험 또는 시행을 무한히 반복했을때 확률변수가 취하는 값의 평균으로(또는 샘플링된 값의 평균) 기대되는 값입니다. 확률변수가 베르누이 분포를 따르는 경우 확률변수에 대한 기댓값(\\(E\\,[y|x_{1,i},x_{2,i}\\.,\\dots,x_{m,i}]\\))과 모수\\((p_i)\\)가 같은 값을 가집니다. 그러므로,만약에 주어진 샘플데이터로부터 베르누이분포의 모수를 적절히 추정할 수 있다면 주어진 조건하에서 실험 또는 시행을 무한히 반복할 경우 확률변수가 1인사건과 0인사건중 어떤 사건이 더 많이 발생할지 알 수 있고 이를 바탕으로 종속변수 Y의 값을 결정하는 것은 타당합니다. - e.g.\n\n\\(E\\,[y]\\, = \\hat{p_i}<0.5\\) => 무한히 실행했을때 0인 경우가 더 많을 것임 => 관측치를 0으로 예측 \n\\(E\\,[y]\\, = \\hat{p_i}\\geq0.5\\)=>무한히 실행했을때 1인 경우가 더 많을 것임 => 관측치를 1로 예측"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#concept",
    "href": "posts/DL/Logistic Regression.html#concept",
    "title": "Logistic Regression",
    "section": "concept",
    "text": "concept\n선형회귀에서 추정하고자하는 변수\\(y\\)는 \\(x_0,x_1,...,x_m\\)과 \\(w_0,w_1,...,w_m\\)과의 linear combination이였습니다.위에서 언급했듯이 특정샘플에 대한 모수를 적절하게 추정할 수 있다면 관측치가 어떤 클래스에 속할지 합리적으로 알 수 있으므로,로지스틱회귀에서도 선형회귀에서의 아이디어를 핵심아이디어를 가지고와서 추정하고자 하는 모수\\(p_i\\)를 \\(x_0,x_1,...,x_m\\)과 \\(w_0,w_1,...,w_m\\)의 linear combination로 표현하고자 합니다.\n선형회귀의 아이디어(linear combination) + 모수에 대한 표현이라는 조건을 만족하기 위해서 최종적인 식은 다음과 조건을 만족해야 것입니다. - \\((x_0,x_1,...,x_m)\\,,(w_0,w_1,..,w_m)\\)의 linear combination 식에 있어야 함. - linearcombination = 모수(추정하고자하는값)여야 함.\nwhy linear combination?"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#본격적인-유도",
    "href": "posts/DL/Logistic Regression.html#본격적인-유도",
    "title": "Logistic Regression",
    "section": "본격적인 유도",
    "text": "본격적인 유도\n\n모수를 로지스틱함수로 바꾸기\n\n\\((x_0,x_1,...,x_m)\\,,(w_0,w_1,..,w_m)\\)의 linear combination이 식에 존재해야 합니다. 그러므로 선형방정식을 하나 만듭니다. \\[\\begin{align}\nf(i) = x_{1,i}w_0 + x_{2,i}w_1 + x_2w_2 + ... + x_{m,i}w_m = X_iW \\nonumber \\\\\nwhere,X_i = \\,[x_{1,i},x_{2,i},\\dots,x_{m,i}]\\, ,W = \\,[w_0,w_1,\\dots,w_m]^\\text{T} \\nonumber \\\\\n\\end{align}\\]\n좌변은 예측하고자 하는 값인 모수여야 합니다. 좌변을 바꿔봅니다. \\[p_i = WX_i\\]\n좌변의 베르누이 분포의 모수 \\(p_i\\)는 확률변수 \\(y = 1\\)인 사건이 일어날 확률입니다. 그러므로 \\([0,1]\\)이라는 범위를 가지는 반면 우변의 값\\(WX_i\\)은 \\(\\,[-\\infty,\\infty]\\,\\)에 범위를 가집니다. 여기서 Odss Ratio를 써서 모수 \\(p_i\\)를 포함하며 더 넓은 range를 갖도록 좌변을 수정합니다. \\[\\text{Odds Ratio} = \\frac{p_i}{1-p_i} = WX_i\\]\n좌변을 Odds Ratio로 수정했지만 여전히 좌변의 범위는\\(\\,[0,\\infty]\\,\\)으로 우변에 비해 좁습니다. 따라서 Odds Ratio에 로짓변환을 취하여 좌변의 범위를 \\(\\,[-\\infty,\\infty]\\)로 넓혀줍니다. \\[\\text{logit}(p) = \\text{ln}\\frac{p_i}{1-p_i} = WX_i\\]\n\n위 식을 해석하기 위해 \\(X\\)의 첫번째 요소인 \\(x_1\\)에 대응하는 회귀계수 \\(w_1\\)이 학습결과 3으로 정해졌다고 가정해봅시다.만약 \\(x_1\\)의 값이 1증가한다면 로그오즈비가 3증가합니다.\n\n이제 양변의 범위는 맞춰졌으므로 추정하고자 하는 변수 \\(p_i\\)가 좌변에 오도록 정리해봅시다. \\[p_i = \\frac{1}{\\,(1 + e^{-WX_i})\\, }\\] (전개) \\(\\frac{p_i}{1-p_i} = e^{WX_i}\\) \\(\\Longleftrightarrow p_i = \\,(1-p_i)\\,e^{WX_i}\\) \\(\\Longleftrightarrow p_i = \\,e^{WX_i}-p_ie^{WX_i}\\) \\(\\Longleftrightarrow p_i + p_ie^{WX_i} = \\,e^{WX_i}\\) \\(\\Longleftrightarrow p_i\\,(1 + e^{WX_i})\\, = \\,e^{WX_i}\\) \\(\\Longleftrightarrow p_i = \\frac{\\,e^{WX_i}}{\\,(1 + e^{WX_i})\\, }\\) \\(\\Longleftrightarrow p_i = \\frac{1}{\\,(1 + e^{-WX_i})\\, }\\)\n\n최종적으로, 앞서 목적이었던 X와 W의 선형조합이 수식내부에 존재하도록 새롭게 표현한 모수는 다음과 같습니다. \\[p_i(y) = Pr\\,(y = 1|X_i;W)\\, = \\frac{1}{\\,1 + e^{-WX_i}\\,}\\]\n\n\n베르누이 분포의 pmf 정리\n베르누이분포의 모수 \\(p_i\\)가 새롭게 표현되었으므로 확률질량함수도 새롭게 표현할 수 있습니다. 마지막 수식은 베르누이 분포의 확률질량함수가 모수\\(W\\)에 관한 식으로 바뀌었음을 표현합니다.\n\\[\\begin{align}\nBern(y;p_i) = Pr\\,(Y_{i} = y|x_{1,i},x_{2,i},\\dots,x_{m,i};p_i) &=\n\\begin{cases}\np_i & \\text{if}\\,y=1 \\\\\n1-p_i & \\text{if}\\,y=0\n\\end{cases} \\\\\n&= p_i^{y}(1-p_i)^{1-y} \\\\\n&= \\frac{e^{yWX_i}}{1+e^{WX_i}}\n\\end{align}\\]"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#setting",
    "href": "posts/DL/Logistic Regression.html#setting",
    "title": "Logistic Regression",
    "section": "setting",
    "text": "setting\n\nimport torch\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n#sig = lambda z:torch.exp(z)/(1+torch.exp(z))\nsig = torch.nn.Sigmoid()"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#data",
    "href": "posts/DL/Logistic Regression.html#data",
    "title": "Logistic Regression",
    "section": "data",
    "text": "data\n\ntorch.manual_seed(2022)\nn=400\n\n#1 모수 W가정\nW = torch.tensor(\n    [[-0.8467],\n    [0.041]]).float()\n\n#2 각각의 관측치(데이터요소)에서의 모수 p_i시각화(시그모이드 함수 시각화)\n_x = torch.linspace(-150,150,n).reshape(-1,1)\n_one = torch.ones((n,1))\nX = torch.concat((_one,_x),axis=1)\np_i = sig(X@W)\ny = torch.bernoulli(p_i)\nplt.xlim([-150,150])\nplt.plot(X[:,1],y,\"bo\",alpha=0.5)\nplt.plot(X[:,1],p_i,\"r--\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y,$p_i$\")\nplt.title(\"realizations $y_1,\\dots,y_{300}$ from $Bern(p_1),\\dots,Bern(p_{300})$\")\nplt.legend([\"y\",\"p\"])\n\n<matplotlib.legend.Legend at 0x1f2684bfe20>"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#gradient-descent-1",
    "href": "posts/DL/Logistic Regression.html#gradient-descent-1",
    "title": "Logistic Regression",
    "section": "Gradient Descent",
    "text": "Gradient Descent\n\nimport torch\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\n\ntorch.manual_seed(2022)\nn=400\n\n#2 임의의 W에 대한 estimated value(추정치) What 초기화\nWhat = torch.tensor(\n    [[0.],\n    [-0.03]],requires_grad=True)\n\n_x = torch.linspace(-150,150,n).reshape(-1,1)\n_one = torch.ones((n,1))\nX = torch.concat((_one,_x),axis=1)\nyhat = sig(X@What)\n\nplt.plot(X[:,1].data,y,\"bo\",alpha=0.3)\nplt.plot(X[:,1].data,p_i,\"r\")\nplt.plot(X[:,1].data,yhat.data,\"g\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"realizations $y_1,\\dots,y_{60}$ from $Bern(p_1),\\dots,Bern(p_{60})$\")\nplt.legend([\"y\",\"$p_i$\",\"$\\hat{y}(\\hat{p_i})$\"])\n\n<matplotlib.legend.Legend at 0x1f268e11e50>\n\n\n\n\n\n\nloss_fn = torch.nn.BCELoss()\n\"\"\"\ndef BCE_Loss(yhat,y):\n    return torch.mean(y * torch.log(yhat) + (1-y) * torch.log(1-yhat))\n\"\"\"\n\n'\\ndef BCE_Loss(yhat,y):\\n    return torch.mean(y * torch.log(yhat) + (1-y) * torch.log(1-yhat))\\n'\n\n\n\n#custom sigmoid + torch.BCELoss 쓰면 오류 발생. 0과 1사이의 범위 아님\n#torch.nn.Sigmoid + custom BCE Loss 써도 오류발생 => nan\nplt.subplots(2,5,figsize=(20,8))\nplt.subplots_adjust(hspace=0.3)\ni=1\n\nfor epoch in range(200):\n    #1 yhat \n    yhat = sig(X@What)\n    #2 loss\n    loss = loss_fn(yhat,y)\n    if epoch % 20 == 0:\n        plt.subplot(2,5,i)\n        #plt.plot(X[:,1].data,y,\"bo\",alpha=0.3)\n        plt.plot(X[:,1].data,p_i,\"r\")\n        plt.plot(X[:,1].data,yhat.data,\"g\")\n        plt.xlabel(\"x\")\n        plt.ylabel(\"y\")\n        #plt.title(\"realizations $y_1,\\dots,y_{60}$ from $Bern(p_1),\\dots,Bern(p_{60})$\")\n        plt.legend([\"p\",\"yhat\"])\n        title = \"loss : {}\".format(round(loss.tolist(),5))\n        plt.title(title)\n        i+=1\n    #3 derivative\n    loss.backward()\n    #4 update & clean\n    What.data = What.data - 0.00005 * What.grad\n    What.grad = None\n\n\n\n\n\nround(loss.tolist(),4)\n\n0.3109\n\n\n\nplt.plot(X[:,1].data,y,\"bo\",alpha=0.3)\nplt.plot(X[:,1].data,p_i,\"r\")\nplt.plot(X[:,1].data,yhat.data,\"g\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Logistic Regression\")\nplt.legend([\"y\",\"$p_i$\",\"$\\hat{y}(\\hat{p_i})$\"])\nplt.gca().axes.xaxis.set_visible(False)\nplt.gca().axes.yaxis.set_visible(False)"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#베르누이-분포-전개",
    "href": "posts/DL/Logistic Regression.html#베르누이-분포-전개",
    "title": "Logistic Regression",
    "section": "1.베르누이 분포 전개",
    "text": "1.베르누이 분포 전개\n\\[\\begin{aligned}\np_i^y(1-p_i)^{1-y} &= \\ (\\frac{1}{\\,1 + e^{-WX_i}\\,})^y\\,\\,(1-\\frac{1}{\\,1 + e^{-WX_i}\\,})^{1-y} \\\\\n&= (\\frac{1}{1+e^{-WX_i}})^{y}(\\frac{e^{-WX_i}}{1+e^{-WXi}})^{1-y} \\\\\n&= (\\frac{1}{1+e^{-WX_i}})^{y}(\\frac{1}{1+e^{WXi}})^{1-y} \\\\\n&= (\\frac{1+e^{WX_i}}{1+e^{-WX_i}})^{y}(\\frac{1}{1+e^{WX_i}}) \\\\\n&= (\\frac{e^{WX_i}+e^{2WX_i}}{1+e^{WX_i}})^{y}(\\frac{1}{1+e^{WX_i}}) \\\\\n&= (\\frac{e^{WX_i}(1+e^{WX_i})}{1+e^{WX_i}})^{y}(\\frac{1}{1+e^{WX_i}}) \\\\\n&= e^{yWX_i}\\frac{1}{1+e^{WX_i}} \\\\\n&= \\frac{e^{yWX_i}}{1+e^{WX_i}}\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#nll전개with-parameter-w",
    "href": "posts/DL/Logistic Regression.html#nll전개with-parameter-w",
    "title": "Logistic Regression",
    "section": "2.NLL전개(with parameter \\(W\\))",
    "text": "2.NLL전개(with parameter \\(W\\))\n\\[\\begin{aligned}\nLL &= \\text{ln}(\\underset{i=1}{\\overset{n}{\\large{\\prod}}}\\,\\frac{e^{y_iWX_i}}{1+e^{WX_i}}) \\\\\n&=\\overset{n}{\\underset{i=1}{\\large{\\sum}}}(\\text{ln}\\frac{e^{y_iWX_i}}{1+e^{WX_i}}) \\\\\n&= \\overset{n}{\\underset{i=1}{\\large{\\sum}}}\\,[\\text{ln}e^{y_iWX_i} - \\text{ln}(1+e^{WX_i})]\\, \\\\\n&= \\overset{n}{\\underset{i=1}{\\large{\\sum}}}\\,[y_iWX_i - \\text{ln}(1+e^{WX_i})], \\\\\n&= \\overset{n}{\\underset{i=1}{\\large{\\sum}}}y_iWX_i - \\overset{n}{\\underset{i=1}{\\large{\\sum}}}ln(1+e^{WX_i}) \\\\\n\n\nNLL &= -\\overset{n}{\\underset{i=1}{\\large{\\sum}}}y_iWX_i + \\overset{n}{\\underset{i=1}{\\large{\\sum}}}ln(1+e^{WX_i}) \\\\\n\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/DL/Logistic Regression.html#nll전개cross-entropy-유도하기",
    "href": "posts/DL/Logistic Regression.html#nll전개cross-entropy-유도하기",
    "title": "Logistic Regression",
    "section": "3.NLL전개(Cross Entropy 유도하기)",
    "text": "3.NLL전개(Cross Entropy 유도하기)\n임의의 i번째 항에서의 확률변수 \\(Y_i\\)가 따르는 베르누이 분포는 다음과 같습니다. \n\\[\\begin{aligned}\nBern(y|X_i;p_i) = (p_i)^y(1-p_i)^{y-1}\n\\end{aligned}\\]\n모수가 \\(p_i\\)인 각각의 베르누이 분포를 따르는 확률변수 \\(Y_1,Y_2\\dots Y_n\\)으로부 n개의 realization(sample) \\(y_1,y_2\\dots y_n\\)에 대한 NLL는 다음과 같습니다. \n\\[\\begin{aligned}\nNLL &= -\\text{ln}\\prod_{i=1}^{n}p_i^{y_i}(1-p_i)^{1-y_i} \\\\\n&= -\\sum_{i=1}^{n}\\text{ln}p_i^{y_i}(1-p_i)^{1-y_i} \\\\\n&= -\\sum_{i=1}^{n}\\text{ln}p_i^{y_i} + \\text{ln}(1-p_i)^{1-y_i} \\\\\n&= -\\sum_{i=1}^{n}y_i\\text{ln}p_i + (1-y_i)\\text{ln}(1-p_i)\n\\end{aligned}\\]\n참고링크 1. 로지스틱 회귀 전개 2. 위키피디아 - 로지스틱 회귀 3. ratsgo’s blog"
  },
  {
    "objectID": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html",
    "href": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html",
    "title": "Multinomial Logistic Regression & Softmax Regression",
    "section": "",
    "text": "[Deep Learning Series - Part3]\n안녕하세요!!😀 이번 포스트에서는 다항로지스틱 회귀와 소프트맥스 회귀에 대해서 정리해보고자 합니다. 공부하면서 생각보다 모르는 내용이 많아서 다시 처음부터 공부하고 복습해야 하는 내용이 많았네요. 잡담은 그만하고 시작해보겠습니다!! 읽어주셔서 감사해요😎"
  },
  {
    "objectID": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#가정-1",
    "href": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#가정-1",
    "title": "Multinomial Logistic Regression & Softmax Regression",
    "section": "가정 (1)",
    "text": "가정 (1)\n로지스틱회귀를 복기해보면… 종속변수 \\(y_i\\)는 베르누이분포를 따르는 확률변수\\(Y_i\\)로부터 샘플링된 값으로 가정했습니다. 또한 베르누이분포의 모수\\(W\\)는 주어진 조건인 \\(X_i\\)와 회귀계수(가중치)\\(W\\)의 일차결합으로 가정했습니다. 이렇게 모수를 가정하면서 베르누이분포의 확률질량함수도 새로운 모수\\(W\\)를 가지게되었고 W를 적절히 추정하면 데이터가 0또는1에 속할 확률을 알아내게 되어 확률이 더 높은 클래스를 주어진데이터에 대한 클래스로 예측했었습니다.다항로지스틱회귀와 소프트맥스회귀에서도 이러한 과정 즉,분포를 가정하고 데이터를 기반으로 모수를 추정하여 확률분포를 기반으로 예측하는 매커니즘은 거의 그대로입니다.\n먼저 다항로지스틱회귀와 소프트맥스회귀에서 종속변수에 대한 가정을 해보겠습니다. 다항로지스틱 회귀와 소프트맥스회귀에서 모두 각각의 관측치(each observation)에서 종속변수의 realization인 \\(y_i\\)는 확률변수\\(Y_i\\)로부터 표본추출(sampling)되었다고 가정합니다. 이때 각각의 관측치에서의 확률변수 \\(Y_i\\)가 따르는 분포는 설명변수 \\(x_{1,i},x_{2,i},\\dots,x_{M,i}\\)가 조건으로 주어질 때, 각각의 범주(클래스)에 속할 확률들을 모수로 가지는 카테고리분포를 따릅니다.\n\\[\\begin{aligned}\n&\n\\begin{aligned}\nY_i|x_{1,i},x_{2,i},\\dots,x_{M,i} \\sim \\text{Cat}(y|x_{1,i},x_{2,i},\\dots,x_{M,i};\\mu_i)\n& =\n\\begin{cases}\n\\mu_{1,i} \\text{ if } y = (1,0,\\dots,0,0) \\\\\n\\mu_{2,i} \\text{ if } y = (0,1,\\dots,0,0) \\\\\n\\quad\\quad \\vdots \\\\\n\\mu_{K,i} \\text{ if } y = (0,0,\\dots,0,1) \\\\\n\\end{cases} \\\\\n&= \\mu_{1,i}^{y_1}\\mu_{2,i}^{y_2},\\dots,\\mu_{K,i}^{y_K} \\\\\n&= \\prod_{K=1}^{K}\\mu_{K,i}y_{K,i} \\\\\n\\end{aligned} \\\\\n&\n\\begin{aligned}\n&\\text{where, }\\\\\n&\\mu_i = {\\mu_{1,i},\\mu_{2,i},\\dots,\\mu_{K,i}} \\\\\n&\\mu_{1,i} = Pr(Y_i = (1,0,\\dots,0)|x_{1,i},\\dots,x_{M,i}) \\\\\n&\\mu_{2,i} = Pr(Y_i = (0,1,\\dots,0)|x_{1,i},\\dots,x_{M,i}) \\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\mu_{K,i} = Pr(Y_i = (0,0,\\dots,0,1)|x_{1,i},\\dots,x_{M,i}) \\\\\n\\end{aligned}\\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#가정-2",
    "href": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#가정-2",
    "title": "Multinomial Logistic Regression & Softmax Regression",
    "section": "가정 (2)",
    "text": "가정 (2)\n각각의 관측치에서 확률변수\\(Y_i\\)가 따르는 카테고리분포의 모수\\(\\mu_i\\)는 데이터포인트마다 다른 설명변수(X_i)와 시행마다 변하지 않는 고정된 회귀계수(W)의 일차결합을 포함하는 수식으로 표현됩니다. 주어진 X값을 W와 일차결합하여 추정하고자 하는 값을 표현하는 선형회귀의 핵심아이디어이자 대부분의 회귀문제에서 사용하는 중요한 아이디어 입니다.\n\\[\\begin{aligned}\n&\\mu_{k,i}  = \\mu_{k,i}(X_i;W_{k,i}) = \\mu_{k,i}(X_iW_{k,i}) =  Pr(Y_i = (0,\\dots,1_{k-th},0,\\dots,0)|X_i)\\\\\n&\\text{where},\\\\\n&w_{m,k} : \\text{$k$번째 모수를 표현하기위해 $m$번째 값과 곱해지는 가중치} \\\\\n&x_{m,i} : \\text{i-th 관측치의 $m$번째 독립변수의 값} \\\\\n&X_i = [x_{0,i},x_{1,i},\\dots,x_{M,i}]^{\\text{T}}\\text{ : i-th관측치의 feature vector(단,$x_{0,i}$ = 1)} \\\\\n&W_k = [w_{0,k},w_{1,k},\\dots,w_{M,k}]^{\\text{T}}\\text{ : 카테고리 분포의 임의의 k-th 모수$\\mu_k$를 구하기 위한 가중치를 모아놓은 벡터} \\\\\n&\\mu_{k,i} = \\text{i-th 관측치의 $k$번째 모수}\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#xw의-선형조합을-포함한-모수의-표현-유도하기",
    "href": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#xw의-선형조합을-포함한-모수의-표현-유도하기",
    "title": "Multinomial Logistic Regression & Softmax Regression",
    "section": "X,W의 선형조합을 포함한 모수의 표현 유도하기",
    "text": "X,W의 선형조합을 포함한 모수의 표현 유도하기\n위에서 언급했듯이 대부분의 회귀에서 모델링의 핵심아이디어는 추정하고자 하는 대상을 설명변수와 가중치의 일차결합(선형조합)이 포함되도록 표현하는 것입니다. 다항로지스틱회귀도 추정하고자 하는 모수\\(\\mu_i = (\\mu_{1,i},\\mu_{2,i},\\dots,\\mu_{K,i})\\)를 각각을 설명변수와 가중치의 일차결합으로 표현해야 합니다.이진로지스틱회귀와에서도 이렇게 모수를 표현했었는데 다항로지스틱회귀에서는 일차결합으로 표현해야할 모수가 좀 더 많습니다. -_-;;\n차근차근 한번 유도해보겠습니다. 일단 K개의 모수를 표현하는 일차결합을 만들어줍니다. 이러한 일차결합에서 x는 관측치마다 존재하는 설명변수의 값에 따라서 회귀계수(가중치)인 W는 관측치에 따라서 변하지 않는 일정한 값입니다.\n\\[\\begin{aligned}\n&\\mu_{1,i} = Pr(Y_i=(1,0,0,\\dots,0)|X_i;W_1)\\quad \\\\\n&\\quad\\,\\,\\, = w_{0,1}x_{0,i}+w_{1,1}x_{1,i} + w_{2,1}x_{2,i} + \\dots \\ + w_{M,1}x_{M,i} = W_1^TX_i-\\text{ln}Z \\\\\n&\\mu_{2,i} = Pr(Y_i=(0,1,0,\\dots,0)|X_i;W_2) = \\\\\n&\\quad\\,\\,\\, = w_{0,2}x_{0,i}+w_{1,2}x_{1,i} + w_{2,2}x_{2,i} + \\dots \\ + w_{M,2}x_{M,i} = W_2^TX_i-\\text{ln}Z \\\\\n&\\mu_{3,i} = Pr(Y_i = (0,0,1,\\dots,0)|X_i;W_2)) = \\\\\n&\\quad\\,\\,\\, = w_{0,3}x_{0,i}+w_{1,3}x_{1,i} + w_{2,3}x_{2,i} + \\dots \\ + w_{M,3}x_{M,i} = W_3^TX_i-\\text{ln}Z \\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\vdots \\\\\n&\\mu_{k,i} = Pr(Y_i = (0,0,\\dots,1_{k-th},\\dots,0,0)|X_i;W_k)) \\\\\n&\\quad\\,\\,\\,= w_{0,k}x_{0,i}+w_{1,k}x_{1,i} + w_{2,k}x_{2,i} + \\dots +w_{m,k}x_{m,i} \\dots + w_{M,k}x_{M,i} = W_k^TX_i {\\text{ (임의의 k번째 항)}}\\\\  \n&\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\vdots \\\\\n&\\mu_{K-1,i} = Pr(Y_i = (0,0,0,\\dots,1,0)|X_i;W_{K-1})) \\\\\n&\\quad\\,\\,\\,= w_{0,K}x_{0,i}+w_{1,K-1}x_{1,i} + w_{2,K-1}x_{2,i} + \\dots \\ + w_{M,K-1}x_{M,i} = W_{K-1}^TX_i \\\\ \\\\\n&where,\\\\\n&w_{m,k} : \\text{$k$번째 모수를 표현하기위해 $m$번째 값과 곱해지는 가중치} \\\\\n&x_{m,i} : \\text{i-th 관측치의 $m$번째 독립변수의 값} \\\\\n&X_i = [x_{0,i},x_{1,i},\\dots,x_{M,i}]^{\\text{T}}\\text{ : i-th관측치의 feature vector(단,$x_{0,i}$ = 1)} \\\\\n&W_k : [w_{0,k},w_{1,k},\\dots,w_{M,k}]^{\\text{T}}\\text{ : 카테고리 분포의 임의의 k-th 모수$\\mu_k$를 구하기 위한 가중치를 모아놓은 벡터} \\\\\n\\end{aligned}\\]\n 한 가지 유의해야 할 점은 마지막 모수는 일차결합으로 표현하지 않는다는 것입니다. 카테고리분포에서 모수의 총합은 1이기 때문에 마지막 \\(K\\)번째 모수는 1에서 전부 빼면 되기 때문입니다.\n그런데 섣불리 일차결합을 만들다보니 … 좌변에 있는 모수는 \\([0,1]\\)의 범위이고 우변은 \\([-\\infty,\\infty]\\)의 범위이므로 가지므로 양변의 범위가 전혀 맞지 않습니다. 그러므로 좌변을 Odds Ratio(엄밀히 Odds Ratio는 아니지만 통일성을 위해 Odds Ratio라고 하겠습니다.) + Logit transform을 취하여 좌변이 우변과 같은 범위를 가질 수 있도록 확장하여 줍니다. (로그안에 있는 분모가 K번째 클래스에 대한 항임을 유의합니다.) \\[\\text{ln}\\frac{\\mu_{k,i}}{Pr(Y_i = (0,\\dots,0,1)|X_i)} = \\text{ln}\\frac{Pr(Y_i = (0,\\dots,1_{k-th},0,\\dots,0)|X_i;W_k)}{Pr(Y_i = (0,\\dots,0,1)|X_i)} = W_k^TX_i\\]\n원래의 목적은 모수에 대한 일차결합이 포함된 항을 얻는 것이었습니다. 그러므로 정리하여 모수에 대한 표현을 얻습니다.\n\\[\\begin{aligned}\n\\mu_{k,i} = Pr(Y_i = (0,\\dots,0,1_{k-th},0,\\dots,0|X_i;W_k) = Pr(Y_i = K|X_i)e^{X_iW_k}\n\\end{aligned}\\]\n여기까지 해서 모수에 대한 표현을 얻었습니다. 다만 \\(Y_i\\)가 \\(K\\)번째 클래스에 대한 확률은 카테고리분포에서의 모수에 대한 제약조건을 활용하여 더 간단하게 바꿀 수 있습니다.\n\\[\\begin{aligned}\n&Pr(Y_i = K|X_i) = 1- \\sum_{k=1}^{K-1}Pr(Y_i = K|X_i)e^{X_iW_k} = 1-Pr(Y_i = K|X_i)\\sum_{k=1}^{K-1}e^{X_iW_k} \\\\\n&\\Longleftrightarrow Pr(Y_i = K|X_i) = \\frac{1}{1+\\sum_{k=1}^{K-1}e^{X_iW_k}}\n\\end{aligned}\\]\n더 간단하게 표현된 항으로 다시 정리하여 쓰면 다음과 같습니다.\n\\[\\begin{aligned}\n&\\mu_{k,i}=Pr(Y_i = k|X_i) = Pr(Y_i = K|X_i)e^{X_iW_k} = \\frac{e^{X_iW_k}}{1+\\sum_{j=1}^{K-1}e^{X_iW_j}}\\\\\n&\\text{인덱스 겹치므로 시그마의 $k \\rightarrow j$}\n\\end{aligned}\\]\n 최종적으로 카테고리 분포의 모수는 다음과 같습니다. 전개하는 과정이 마지막 \\(K\\)번째 항은 제외한채 진행되었으므로 K번째 항에대한 확률은 따로 써줍니다.\n\\[\\begin{aligned}\n&\\mu_{k,i}=Pr(Y_i = k|X_i) = \\frac{e^{X_iW_k}}{1+\\sum_{j=1}^{K-1}e^{X_iW_j}} \\text{(단, $k != K$)}\\\\\n&\\mu_{K,i}=Pr(Y_i = K|X_i) = \\frac{1}{1+\\sum_{j=1}^{K-1}e^{X_iW_k}}\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#estimation",
    "href": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#estimation",
    "title": "Multinomial Logistic Regression & Softmax Regression",
    "section": "Estimation",
    "text": "Estimation\n더 공부해 오겠습니다 ^__^;;"
  },
  {
    "objectID": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#가정",
    "href": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#가정",
    "title": "Multinomial Logistic Regression & Softmax Regression",
    "section": "가정",
    "text": "가정\n소프트맥스회귀의 가정은 로지스틱회귀의 가정과 습니다. 각 datapoint에서의 종속변수의 값은 카테고리분포를 따르는 확률변수에서 샘플링되었으며 카테고리분포의 모수는 각 datapoint마다 변하는 설명변수와 회귀계수(가중치)의 일차결합으로 표현됩니다."
  },
  {
    "objectID": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#xw의-선형조합을-포함한-모수의-표현-유도하기-1",
    "href": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#xw의-선형조합을-포함한-모수의-표현-유도하기-1",
    "title": "Multinomial Logistic Regression & Softmax Regression",
    "section": "X,W의 선형조합을 포함한 모수의 표현 유도하기",
    "text": "X,W의 선형조합을 포함한 모수의 표현 유도하기\n소프트맥스 회귀마찬가지로 추정하고자 하는 모수를 설명변수와 가중치의 일차결합이 포함된 항으로 표현합니다.\n먼저 설명변수와 가중치의 일차결합형태로 모수를 나타냅니다. 임의의 i번째 관측치가 각각의 범주에 \\((1,2,...,K)\\) 속할 확률을 의미하는 모수는 다음과 같습니다.\n\\[\\begin{aligned}\n&\\mu_{1,i} = Pr(Y_i=(1,0,0,\\dots,0)|X_i;W_1)\\quad \\\\\n&\\quad\\,\\,\\, = w_{0,1}x_{0,i}+w_{1,1}x_{1,i} + w_{2,1}x_{2,i} + \\dots \\ + w_{M,1}x_{M,i} = W_1^TX_i-\\text{ln}Z \\\\\n&\\mu_{2,i} = Pr(Y_i=(0,1,0,\\dots,0)|X_i;W_2) = \\\\\n&\\quad\\,\\,\\, = w_{0,2}x_{0,i}+w_{1,2}x_{1,i} + w_{2,2}x_{2,i} + \\dots \\ + w_{M,2}x_{M,i} = W_2^TX_i-\\text{ln}Z \\\\\n&\\mu_{3,i} = Pr(Y_i = (0,0,1,\\dots,0)|X_i;W_2)) = \\\\\n&\\quad\\,\\,\\, = w_{0,3}x_{0,i}+w_{1,3}x_{1,i} + w_{2,3}x_{2,i} + \\dots \\ + w_{M,3}x_{M,i} = W_3^TX_i-\\text{ln}Z \\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\vdots \\\\\n&\\mu_{k,i} = Pr(Y_i = (0,0,\\dots,1_{k-th},\\dots,0,0)|X_i;W_k)) \\\\\n&\\quad\\,\\,\\,= w_{0,k}x_{0,i}+w_{1,k}x_{1,i} + w_{2,k}x_{2,i} + \\dots +w_{m,k}x_{m,i} \\dots + w_{M,k}x_{M,i} = W_k^TX_i \\\\  \n&\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\vdots \\\\\n&\\mu_{K-1,i} = Pr(Y_i = (0,0,0,\\dots,1,0)|X_i;W_{K-1})) \\\\\n&\\quad\\,\\,\\,= w_{0,K}x_{0,i}+w_{1,K-1}x_{1,i} + w_{2,K-1}x_{2,i} + \\dots \\ + w_{M,K-1}x_{M,i} = W_{K-1}^TX_i \\\\ \\\\\n&where,\\\\\n&w_{m,k} : \\text{$k$번째 모수를 표현하기위해 $m$번째 값과 곱해지는 가중치} \\\\\n&x_{m,i} : \\text{i-th 관측치의 $m$번째 독립변수의 값} \\\\\n&X_i = [x_{0,i},x_{1,i},\\dots,x_{M,i}]^{\\text{T}}\\text{ : i-th관측치의 feature vector(단,$x_{0,i}$ = 1)} \\\\\n&W_k : [w_{0,k},w_{1,k},\\dots,w_{M,k}]^{\\text{T}}\\text{ : 카테고리 분포의 임의의 k-th 모수$\\mu_k$를 구하기 위한 가중치를 모아놓은 벡터} \\\\\n\\end{aligned}\\]\n이렇게 나타내고 보니 좌변과 0~1사이의 수만 갖지만 우변은 어떤 수던지 나올 수 있습니다. 범위를 맞춰 주기 위해서 좌변에 로그를 씌워 로그확률로 만들어줍니다. 추가적으로 우변에 \\(-lnZ\\)라는 normalizating factor를 더해줍니다. 다음과정에서 카테고리분포의 모수의 합이 1이되도록 하는 확률질량함수의 특징을 유지하기 위해서 사용합니다.\n\\[\\begin{aligned}\n&\\text{ln}\\mu_{1,i} = w_{0,1}x_{0,i}+w_{1,1}x_{1,i} + w_{2,1}x_{2,i} + \\dots \\ + w_{M,1}x_{M,i} = W_1^TX_i-\\text{ln}Z \\\\\n\\\\\n&\\text{ln}\\mu_{2,i} = w_{0,2}x_{0,i}+w_{1,2}x_{1,i} + w_{2,2}x_{2,i} + \\dots \\ + w_{M,2}x_{M,i} = W_2^TX_i-\\text{ln}Z \\\\\n\\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\vdots \\\\\n&\\text{ln}\\mu_{k,i} = w_{0,k}x_{0,i}+w_{1,k}x_{1,i} + w_{2,k}x_{2,i} + \\dots +w_{m,k}x_{M,i} \\dots + w_{M,k}x_{M,i} = W_k^TX_i-\\text{ln}Z \\\\\n\\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\vdots \\\\\n&\\text{ln}\\mu_{K-1,i} = w_{0,K}x_{0,i}+w_{1,K-1}x_{1,i} + w_{2,K-1}x_{2,i} + \\dots \\ + w_{M,K-1}x_{M,i} = W_{K-1}^TX_i-\\text{ln}Z \\\\\n\\\\\n\\end{aligned}\\]\n따라서,임의의 \\(k\\)번째 모수는 다음과 같습니다. \\[\\mu_{k,i} = Pr(Y_i = (0,0,\\dots,1_{k-th}|X_i;W_k) = \\frac{1}{Z}e^{W_k^TX_i}\\]\n카테고리분포의 제약조건 즉,모수는 각각의 범주에 속할 확률을 나타내므로 총합이 1임을 활용합니다. 이를 활용하여 Z를 표현하면 다음과 같습니다.\n\\[\\begin{aligned}\n&\\sum_{k=1}^{K}{\\mu_{k,i}} =\\sum_{k=1}^{K}{Pr(Y_i=k)}= \\frac{1}{Z}\\sum_{k=1}^{K}e^{W_k^TX_i} = 1\\\\\n&\\Longleftrightarrow Z = \\sum_{k=1}^{K}e^{W_k^TX_i}\n\\end{aligned}\\]\n최종적으로, 결과를 정리하면 다음과 같습니다. - 추정하고자하는 카테고리분포의 모수는 \\(\\mu_k\\)는 \\(W_k\\)와 \\(X_i\\)의 일차결합으로 표현되었습니다. 이는 소프트맥스 함수이므로 소프트맥스 회귀라는 이름이 붙었습니다. \\[\\mu_{c,i}(X_i;W) = Pr(Y_i = (0,0,\\dots,1_{c-th},0,\\dots,0)|X_i;W_k) = \\frac{e^{W_c^TX_i}}{\\sum_{k=1}^{K}e^{W_k^TX_i}} = softmax(c,W_1^TX_i,W_2^TX_i,\\dots,W_K^TX_i)\\] - 카테고리분포의 위에서 구한 모수로 다시 정리하면 확률질량 함수는 새로운 모수 \\(W_1,W_2,\\dots,W_K\\)를 가집니다.(인덱스 \\(k->j,c->k\\)) \\[Y_i \\sim Cat(y|X_i;W_1,W_2,\\dots,W_K) = \\prod_{k=1}^{K}\\frac{e^{W_k^TX_i}}{\\sum_{j=1}^{K}e^{W_j^TX_i}}\\]"
  },
  {
    "objectID": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#mle",
    "href": "posts/DL/Multinomial Logistic Regression,Softmatx Regression.html#mle",
    "title": "Multinomial Logistic Regression & Softmax Regression",
    "section": "MLE",
    "text": "MLE\n여기까지의 과정으로부터 카테고리분포의 모수는 설명변수와 가중치(회귀계수)의 일차결합으로 표현되며 또한 확률질량함수가 새로운 모수 \\(W = (W_1,W_2,\\dots,W_K)\\)로 표현되었습니다.만약 카테고리분포의 모수만 추정할 수 있다면 우리는 데이터포인트가 어떤 범주에 속할 확률이 가장 높은지 알 수 있으며 범주를 분류할 수 있습니다. 여기서는 카테고리분포의 모수\\(W\\)를 MLE로 추정합니다.\n확률분포에서 임의의 모수\\(W = (W_1,W_2,\\dots,W_K)\\)를 가정할 때, 확률변수 \\(Y_1,Y_2,\\dots,Y_N\\)으로부터 realization인 \\(y_1,y_2,\\dots,y_N\\)이 나올 가능도는 다음과 같습니다.\n\\[\\begin{aligned}\n&\n\\begin{aligned}\nL({W};X_i|y_1,y_2,\\dots,y_n) &= Pr_{Y_1,Y_2,\\dots,Y_N}(y1,y2,\\dots,y_n|X_i;W)\\\\\n&= \\prod_{i=1}^{N}Pr_{Y_i}(Y_i=y_i|X_i;W) \\\\\n&= \\prod_{i=1}^{N}\\prod_{k=1}^{K}\\frac{e^{W_k^TX_i}}{\\sum_{j=1}^{K}e^{W_j^TX_i}}\\\\\n\\end{aligned}\n\\\\\n&\\text{where } \\{W\\} = \\{W1,W2,\\dots,W_N\\}\n\\end{aligned}\\]\n위와 같은 가능도를 최소화 하는 \\(W\\)를 찾는 것이 목적입니다.다음과 같습니다\n\\[\\begin{aligned}\n\\overset{*}{\\{W\\}} = \\underset{\\{W\\}}{\\text{argmax}} \\prod_{i=1}^{N}\\prod_{k=1}^{K}\\frac{e^{W_k^TX_i}}{\\sum_{j=1}^{K}e^{W_j^TX_i}}\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/DL/Pytorch Rnn 구현.html",
    "href": "posts/DL/Pytorch Rnn 구현.html",
    "title": "pytorch로 Rnn구현하기",
    "section": "",
    "text": "hi?hi!가 반복되는 텍스트 데이터에서 다음 문자가 뭐가 나올지 예측하는 RNN모형 만들기"
  },
  {
    "objectID": "posts/DL/Pytorch Rnn 구현.html#vectorization",
    "href": "posts/DL/Pytorch Rnn 구현.html#vectorization",
    "title": "pytorch로 Rnn구현하기",
    "section": "vectorization",
    "text": "vectorization\n\n여러가지 방법이 있으나(tf-idf,dense vector,one-hot encoding 등등…) 여기서는 원핫인코딩 사용\n\n\ndef mapping(txt,map_dict):\n    return [map_dict[chr]for chr in txt]\ntxt_mapped = mapping(txt,map_dict)\nprint(txt_mapped[:10])\n\ndef onehot_encoding(txt_mapped):\n    seq_encoded = torch.nn.functional.one_hot(torch.tensor(txt_mapped))\n    return seq_encoded.float()\nsequence_data_encoded = onehot_encoding(txt_mapped)\nprint(sequence_data_encoded[:10])\n\n[2, 3, 0, 2, 3, 1, 2, 3, 0, 2]\ntensor([[0., 0., 1., 0.],\n        [0., 0., 0., 1.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.]])\n\n\n데이터 살짝 변형 하나의 긴 sequence data를 RNN의 입력으로 해도 되지만 처리속도,성능을 고려했을 때 자그마한 sequencedata로 분리하여 입력해주는게 더 좋은 방법임. 분리하는 방법도 여러가지가 있을 수 있겠는데 여기서는 다음과 같이 분리함 raw sequence data : hi?hi!hi?hi!hi?hi! ……….. sequence1 : (x,y) = (hi?,h) sequence2 : (x,y) = (i?h,i) sequence3 : (x,y) = (?hi,!) …\n\ndef create_seqdataset(seq_data,seq_length):\n    #x = seq_data[:-1]\n    #y = seq_data[1:]\n    seqs_x = []\n    seqs_y = []\n    for idx in range(0,len(seq_data)-seq_length):\n        seqs_x.append(seq_data[idx:idx+seq_length])\n        seqs_y.append(seq_data[idx+seq_length])\n    return torch.stack(seqs_x),torch.stack(seqs_y)\n    #return seq_x,seq_y\n\nx_data,y_data = create_seqdataset(sequence_data_encoded,3)\nprint(x_data.shape,y_data.shape)\n\ntorch.Size([57, 3, 4]) torch.Size([57, 4])\n\n\n\n왜 저런 shape을 맞춰 주는가?\n여기서 나오는 x_data.shape = \\((57,3,4)\\)가 살짝 난해함.  파이토치 공식문서에 따르면 batch_first = True로 설정할 경우,rnn계열의 모델에 넣어줘야 하는 텐서의 shape은 \\((N,L,H_{in})\\) = (batch size,sequnce length,input_size)이고 dataloader라는 일종의 데이터 중간관리자?를 한 번 거쳐서 모델에 입력됨. dataloader에서 나오는 output.shape = \\((N,L,H_{in})\\)이 되기 위해서는 input.shape = \\((D,L,H_{in}\\)(D는 분리된 시퀀스의 갯수)이어야 함(즉 입력텐서의 차원이 3개여야 출력텐서의 차원도3개이고 차원이 나오는 순서도 저런식이 되어야 함). 따라서 저렇게 설정함.\n\n\n파라미터 잠깐 설명\nbatch size는 배치의 총 갯수(배치안에 있는 원소의 갯수 아님!), sequnce length는 시퀀스데이터의 길이이자 timestemp(시점)의 총 갯수(길이), \\(H_{in}\\)은 each timestep(각 시점)마다 입력되는 벡터의 길이라고 볼 수 있음. 위처럼 원핫인코딩을 한 경우 \\(H_{in}\\)은 시퀀스데이터에 있는 문자의 갯수로 결정되므로 4이고 L은 create_seqdataset함수에서 인수로 넣어준 3(sequnce_length)이고 마지막으로 N(batch_size)은 torch.utils.data.DataLoader안에 인수로 넣어주는 batch_size로 인해서 일정한 갯수로 배치를 나누었을때 나오는 배치들의 총 숫자임.rnn 문서에서 설명하는 batch_size는 torch.utils.dada.DataLoader에서 설정한 batch_size의 갯수만큼 데이터를 모아서 여러개의 배치로 만들었을때 나오는 배치의 총 갯수라고 보면됨.(헷갈리는 부분….)"
  },
  {
    "objectID": "posts/DL/Pytorch Rnn 구현.html#학습-준비하기",
    "href": "posts/DL/Pytorch Rnn 구현.html#학습-준비하기",
    "title": "pytorch로 Rnn구현하기",
    "section": "학습 준비하기",
    "text": "학습 준비하기\n\ndefine architecture,loss,optimizer\ndata check\n\n\n#architecture,loss,optimizer \ntorch.manual_seed(2022)\nrnn = torch.nn.RNN(4,20,batch_first = True)\nlinr = torch.nn.Linear(20,4)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=1e-3)\n\n\nds = torch.utils.data.TensorDataset(x_data,y_data)\ndl = torch.utils.data.DataLoader(ds,batch_size=8,drop_last=True)\n\nfor idx,(x,y) in enumerate(dl):\n    if idx ==5:\n        break\n    print(x.shape,y.shape)\n\ntorch.Size([8, 3, 4]) torch.Size([8, 4])\ntorch.Size([8, 3, 4]) torch.Size([8, 4])\ntorch.Size([8, 3, 4]) torch.Size([8, 4])\ntorch.Size([8, 3, 4]) torch.Size([8, 4])\ntorch.Size([8, 3, 4]) torch.Size([8, 4])\n\n\n위에서 언급했듯이 데이터로더를 거쳐서 나오는 텐서는 RNN에 바로 입력될 것임. input.shape = \\((N,L,H_{in}) = (8,3,4)\\)"
  },
  {
    "objectID": "posts/DL/Pytorch Rnn 구현.html#모형학습",
    "href": "posts/DL/Pytorch Rnn 구현.html#모형학습",
    "title": "pytorch로 Rnn구현하기",
    "section": "모형학습",
    "text": "모형학습\n\nfor epoch in range(0,101):\n    for tr_x,tr_y in dl:\n        #1 output\n        hidden,hT = rnn(tr_x)\n        #print(hidden.shape)\n        output = linr(hT[-1])\n        #2 loss\n        loss = loss_fn(output,tr_y)\n        #3 derivative\n        loss.backward()\n        #4 update & clean\n        optimizer.step()\n        optimizer.zero_grad()\n    if epoch % 10 == 0:\n        print(f'epoch : {epoch},loss : {round(loss.tolist(),5)}')\n\nepoch : 0,loss : 1.31779\nepoch : 10,loss : 0.69453\nepoch : 20,loss : 0.19338\nepoch : 30,loss : 0.05891\nepoch : 40,loss : 0.02861\nepoch : 50,loss : 0.01791\nepoch : 60,loss : 0.0126\nepoch : 70,loss : 0.00947\nepoch : 80,loss : 0.00744\nepoch : 90,loss : 0.00602\nepoch : 100,loss : 0.00499\n\n\npytorch의 rnn을 거쳐서 나오는 output은 두 가지임. - hidden : 가장 깊이 위치한 히든레이어의 각각의 시점에서의 출력값을 모아놓은 텐서 - hT : 모든 히든레이어에의 마지막 시점(시점T)에서의 출력값을 모아놓은 텐서 - 외우기! 위치 : 가장깊은 <=> 모든 , 시점 : 각각의 <=> 마지막\n위와같은 설정에서는 가장 깊이 위치한 히든레이어의 마지막시점에서의 출력값만이 우리는 다음에올 문자열을 예측할 때 필요하므로 hT[-1]을 하여 그 값을 가져옴."
  },
  {
    "objectID": "posts/DL/[PRML 정독하기] Probability Theory.html",
    "href": "posts/DL/[PRML 정독하기] Probability Theory.html",
    "title": "[PRML 읽기] 1 - 확률론 개요",
    "section": "",
    "text": "Figure1.9\n\n\n빨강색,파랑색 상자 중 하나를 선택하고 선택한 상자안에서 사과(초록) 또는 오렌지(주황)를 꺼낸다고 합시다. 여러번 반복했을 때, 빨강색 상자와 파랑색 상자가 선택된 비율이 각각 40%,60%라고 알려져 있는 상태입니다. 미래에 선택된 상자를 나타내는 변수를 B라고 하면 실제로 상자를 선택하기 전까지는 각각의 상자를 뽑을 확률(가능성)만이 존재하므로 변수B는 확률변수 입니다. 이 확률변수가 취할 수 있는 값은 r 또는 b로 두 가지 입니다. 마찬가지로 미래에 선택된 과일을 나타내는 확률변수 F를 놓을 수 있고 F가 취할 수 있는 값을 a 또는 o로 놓을 수 있습니다.\n빈도주의 관점에서 어떠한 사건이 발생할 확률은 매우 여러번 시행을 반복했을때, 어떤 사건이 나오는 경우의 비율(fraction,ratio)입니다. 예를 들어 주사위 눈이 3이나올 확률이 50%라고 하면 100번 던졌을때 50번정도는 3이 나오는 것으로 이해할 수 있습니다. 위의 문제에서 여러번 반복했을때 빨강색 또는 파랑색상자인 사건이 발생하는 경우가 각각 전체에서 40%,60%였다고 했으므로 이는 확률입니다. 또한 확률변수 B가 r을 취하는 사건에 대한 확률과 확률변수 B가 b를 취하는 사건에 대한 확률이라고 말하며 다음과 같이 적을 수 있습니다.\n\\[\\begin{aligned}\np(B = r) = 0.4 \\\\\np(B = b) = 0.6\n\\end{aligned}\\]\n각각의 상자를 선택하는 사건의 확률은 확률의 정의에 의해서 [0,1]사이의 구간에만 존재합니다. 또한 각각의 상자를 선택하는 사건은 상호베타적이면서 시행으로부터 나올 수 있는 모든 결과들 입니다. 그러므로 확률의 합은 1입니다.\n몇 가지 궁금한 점이 생겼습니다. “사과(초록)이나 오렌지(주황)가 나올 확률은?” 또는 “사과를 뽑았을 때 어떤 상자를 선택할 가능성이 높은지?”에 대해서 궁금합니다. 이는 sum rule과 product rule을 알아야 합니다.\n\n\n\n\n\n\nFigure1.9\n\n\n확률변수 \\(X,Y\\)가 존재하고 \\(X\\)가 취할 수 있는 값은 \\(x_i(i=1,2,\\dots,M)\\) \\(Y\\)가 취할 수 있는 값은 \\(y_j(j=1,2,\\dots,L)\\)라고 합시다. 총 \\(N\\)번을 시행했다고 할 때,시행의 결과 중 \\(X = x_i\\)이면서 동시에 \\(Y=y_i\\)인 경우는 \\(n_{ij}\\)번 나왔으며 \\(X = x_i\\)인 경우는 \\(c_i\\)번 나왔고 확률변수 \\(Y = y_j\\)인 경우는 \\(r_j\\)번이 나왔습니다.\n확률변수 \\(X = x_i\\)이고 \\(Y=y_j\\)인 사건이 동시에 발생할 확률을 \\(X=x_i,Y=y_j\\)일 때의 결합확률(joint probability)라고 합니다.\n\\[p(X = x_i,Y = y_j)\\]\n결합확률은 매우 여러번 시행했을 때, \\(X=x_i,Y=y_j\\)인 사건이 나오는 경우의 \\(n_{ij}\\) 비율입니다.\n\\[N \\rightarrow \\infty,\\,\\, p(X=x_i,Y=y_j) = \\frac{n_{ij}}{N}\\]\n시행으로부터 확률변수 \\(X = x_i\\)인 사건이 몇 번 나왔는지 알기위해서는 \\(c_i\\)는 \\(X = x_i,Y = y_j(\\text{for } j=1,2,\\dots,L)\\)인 사건이 발생하는 모든 경우를 전부 다 더해야 합니다. 예를 들어서 사과를 선택하는 \\(F = a\\)이 경우는 사과를 선택하고 상자가 파랑색 상자인 \\(F=a,B=r\\) 사건이 발생한 경우와 사과를 선택하고 상자가 빨강색 상자인\\(F=a,B=b\\) 사건이 발생한 경우이므로 시행으로부터 두 가지 케이스에 해당하는 모든 경우를 모두 세어야 합니다.\n\\[c_i = \\sum_{j=1}^{L}n_{ij}\\]\n결과적으로 ,\\(X = x_i\\)인 사건의 확률은 다음과 같습니다.\n\\[\\begin{aligned}\np(X = x_i) &= \\frac{c_{i}}{N} \\\\\n&=\\frac{\\sum_{j=1}^{L}n_{ij}}{N}\\\\\n&= p(X=x_i,Y=y_1) + p(X=x_i,Y=y_2) + \\dots + p(X=x_i,Y=y_L) \\\\\n&= \\sum_{j=1}^{L}p(X=x_i,Y=y_j) \\\\\n\\end{aligned}\\]\n위와 같이 하나의 확률변수에 대한 확률을 구할 때, 다른 확률변수와의 모든 결합확률을 더하여 구하는 법칙을 sum rule of probability라고 합니다. 이때 다른 확률변수와 결합확률을 marginalizing 또는 summing out하여 구하므로 marginal probability라고 합니다.\n시행의 결과가 \\(X=x_i\\)인 특정 조건을 만족하는 경우에 대해서만 고려해본다고 합시다. 조건에 맞는 경우안에서 \\(Y = y_j\\)인 사건이 나오는 횟수의 비는 \\(p(Y=y_j|X=x_i)\\)라고 표기하며 다음과 같습니다.\n\\[p(Y=y_j|X=x_i) = \\frac{n_{ij}}{c_j}\\]\n이를 \\(X=x_i\\)로 주어졌을 때, \\(Y=y_j\\)인 사건에 대한 조건부확률이라고 합니다. 조건부 확률의 경우 기호\\(|\\) 다음에 조건이 오며 분모에는 조건에 해당하는 사건이 나오는 경우가 몇 번인지 그 횟수에 값이 오지만 조건부확률이 아닌 그냥 확률의 경우 분모는 몇 번 시행했는지 입니다. 이러한 이유는 조건부확률은 일반적인 확률과 다르게 어떤 특정한 조건안에서 다른사건이 나오는 비율이기 때문입니다.\n위에서 정의한 조건부확률로 결합확률을 다시 적어보면 다음과 같습니다.\n\\[p(X=x_i,Y=y_j) = \\frac{n_{ij}}{N} = \\frac{n_{ij}}{c_i}\\frac{c_i}{N} = p(Y=y_j|X=x_i)p(X = x_i)\\]\n즉 결합확률은 \\(X=x_i\\)인 사건이 발생한 확률과 발생한 사건을 조건\\(X=x_i\\)으로하고 \\(Y=y_j\\)가 발생할 확률의 곱과 같습니다. 이는 어느정도 직관과 일치한다고 볼 수 있는데 예를 들자면 빨강색상자에서 사과를 뽑을 가능성은 먼저 빨강색상자를 고르고 그 다음 사과를 뽑을 가능성이기 때문입니다.\n\n\n\n위에서 적은 결합확률로부터 다음과 같은 식을 얻어낼 수 있습니다.\n\\[p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)}\\]\n이를 베이즈정리 라고 합니다. 베이즈 정리에서 \\(p(Y|X)\\)는 posterior probability(사후확률)로 어떤 조건 또는 증거가 발견되었을때의 확률입니다. \\(p(Y)\\)는 prior probability로 어떤 증거 또는 조건이 발견되기전의 확률입니다. 베이즈 정리로부터 우리는 posterior와 prior의 관계 즉,조건 또는 증거가 발견되기 전,후의 확률사이의 수식을 알 수 있습니다. 그러므로 사전확률을 알고 있다면 그 확률을 통하여 사후확률을 구할 수 있습니다.\n\\[p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)} = \\frac{p(X|Y)p(Y)}{\\sum_{Y}p(X,Y)} = \\frac{p(X|Y)p(Y)}{\\sum_{Y}p(X|Y)p(Y)}\\]\n분모를 sum rule과 product rule에 의하여 더 전개하면 위와 같습니다. 사후확률 \\(p(Y|X)\\)는 \\(X\\)라는 증거,조건이 주어질 때 결과 \\(Y\\)에 대한 확률이었습니다. 위의 수식을 곰곰히 보면 … \\(X\\)가 조건으로 주어질때 결과\\(Y\\)에 대한 조건부 확률을 구하기 위하여 \\(Y\\)가 주어질때의 \\(X\\)에 대한 조건부 확률로 계산합니다. 여기서 나타나는 베이즈 정리에서 핵심은 어떤 조건이 주어지고 결과에 대한 확률을 구할 때, 결과를 조건으로 조건을 결과로 역으로 바꾼 확률을 사용한다는 점입니다. 즉 \\(X\\)가 조건일 때, \\(Y\\)에 대한 조건부 확률이 잘 구해지지 않는다면 이를 뒤집어서 \\(Y\\)가 조건이고 \\(X\\)가 결과일때의 확률을 이용할 수 있습니다.\n베이즈 정리에서 분모는 normalization 상수로 모든 \\(Y\\)에 대하여 확률의 합이 1이 되도록 합니다.\n예시로 돌아가서 오렌지 또는 사과가 나올 확률과 사과를 골랐을 때 어떤 상자를 골랐을 확률이 높은지를 계산해봅시다. 각각의 경우에 대해 확률을 정리하면 다음과 같습니다.\n\\[\\begin{align}\n&p(B = r) = 0.4 \\\\\n&p(B = b) = 0.6 \\\\\n&p(F = a | B = r) = \\frac{1}{4}\\\\\n&p(F = o | B = r) = \\frac{3}{4}\\\\\n&p(F = a | B = b) = \\frac{3}{4}\\\\\n&p(F = o | B = b) = \\frac{1}{4}\\\\\n\\end{align}\\]\n(3)(4),(5)(6) 각각의 합은 normalization constant로 인해 합이 1이 되는것을 알 수 있습니다.\n이어서 원래 궁금했던 첫번째 문제인 사과 또는 오렌지가 나올 확률을 Product rule로 계산해볼 수 있습니다.\n\\[\\begin{aligned}\n&\n\\begin{aligned}\np(F = a) &= p(F=a,B=r) + p(F=a,B=b) \\\\\n&=p(F=a|B=r)p(B=r) + p(F=a|B=b)p(B=b) \\\\\n&=\\frac{1}{4}\\times\\frac{4}{10} + \\frac{3}{4}\\times\\frac{6}{10}\\\\\n&= \\frac{11}{20}\\\\\n\\end{aligned}\n\\\\\n&p(F=b) = 1-\\frac{11}{20}= \\frac{9}{20}\n\\end{aligned}\\]\n또다른 문제인 오렌지 또는 사과를 뽑았을때 어떤 박스를 선택했는지 알고 싶습니다. 즉 알고싶은 확률은 \\(p(B|F=a)\\) 또는 \\(p(B|F=o)\\)입니다. 그런데 우리에게 주어진 확률들은 사전확률인 \\(p(F)\\)와 조건과 결과가 역으로 뒤집힌 확률인 \\(p(F|B)\\)입니다. 그러므로 ,Bayes Rule을 사용하여 원하는 확률을 구할 수 있습니다.\n\\[\\begin{align}\n&p(B|F) = \\frac{p(F|B)p(F)}{p(B)} \\\\\n&p(B=r|F=o) = \\frac{p(F=o|B=r)p(B=r)}{p(F=o)} = \\frac{2}{3}\\\\\n&\\leftrightarrow p(B=b|F=o) = 1-\\frac{2}{3} = \\frac{1}{3}\n\\end{align}\\]\n오렌지를 확인하기전까지는 빨강색 박스일 확률이 절반이 안되는 0.4 였는데 오렌지를 확인하고는 \\(\\frac{2}{3}\\)로 확률이 상승했습니다. 이는 주어지는 정보,주건이 확률에 큰 영향을 미치는 것을 확인할 수 있습니다. 또한 구한 확률이 직관적으로 그림에서 확인할 수 있는 사실과도 일치함을 알 수 있습니다.\n\n\n\n두 확률변수가 독립이면 다음과 같습니다.\n\\[\\text{X and Y are independent random variables} \\iff p(X,Y) = p(X)p(Y)\\]\n예시에서 확인해봅시다.\n\\[\\begin{aligned}\n&p(B=r|F=o) = \\frac{2}{3} ,p(B=r) = \\frac{4}{10}\\\\\n&p(B=r|F=o) \\not = p(B=r) \\Longleftrightarrow \\text{X and Y are dependent}\n\\end{aligned}\\]\n만약 두 박스안에 들어있는 오랜지와 사과가 같은 비율로 들어있다고 한다면…\n\\[\\begin{aligned}\np(F=o | B=r) = p(F = o) \\\\\np(F=a | B=r) = p(F = a)  \\\\\np(F=o | B=b) = p(F = o)  \\\\\np(F=a | B=b) = p(F = a)\n\\end{aligned}\\]\n따라서 상자안에 있는 과일의 갯수가 같을 경우, 두 확률변수는 독립입니다.\n\n\n\n\n빈도주의 관점에서 확률은 매우여러번 시행했을 때, 어떤 사건이 발생하는(나오는) 비율(ratio)입니다.\nSum rule은 여러확률변수에 대한 결합확률이 주어질 때, 특정한 하나의 변수에 대한 확률(marginal probability)을 구함\n\n\\[p(X) = \\sum_Yp(X,Y)\\]\n\nProduct rule은 조건부확률과 주변확률사이의 곱으로 결합확률을 구함\n\n\\[p(X,Y) = p(Y|X)p(X) = p(X|Y)p(Y)\\]\n\n베이즈정리는 posterior(사후확률)를 prior(사전확률)과 조건과 결과가 바뀌었을때의 확률을 통해서 구합니다. 또한 사전확률과 사후확률사이의 관계(수식)입니다.\n\n\\[p(X|Y) = \\frac{p(Y|X)p(Y)}{p(X)} = \\frac{p(Y|X)p(Y)}{\\sum_Yp(X,Y)p(Y)}\\]\n\n두 확률변수가 독립일 경우 , 결합확률(분포)는 각각의 변수에 대한 (주변)확률의 곱입니다\n\n\\[\\text{X and Y are independent random variables} \\iff p(X,Y) = p(X)p(Y)\\]\n\n\n\n\n\n확률변수가 독립이라면 \\(Y\\)의 조건부확률은 조건\\(X\\)가 어떤 값이던간에 전혀 영향이 없습니다(독립적입니다).\n\\[\\begin{aligned}\n&p(Y|X) = p(Y) \\\\\n&\\leftrightarrow p(Y|X) = \\frac{p(X,Y)}{p(X)} = p(Y)\\\\\n&\\leftrightarrow p(X,Y) = p(X)p(Y)\n\\end{aligned}\\]\n반대로 해도 성립합니다.\n\n\n\n\n가장 쉽게 이해하는 베이즈 정리(Bayes’ Law)\nIndependent Random Variables\nPRML 1.2-probability theory"
  },
  {
    "objectID": "posts/DL/[PRML 정독하기] Probability Theory2.html",
    "href": "posts/DL/[PRML 정독하기] Probability Theory2.html",
    "title": "[PRML 읽기] 2 - 확률론 개요(작성중 …)",
    "section": "",
    "text": "PRML을 읽고 정리한 내용입니다."
  },
  {
    "objectID": "posts/DL/[PRML 정독하기] Probability Theory2.html#probability-density-function",
    "href": "posts/DL/[PRML 정독하기] Probability Theory2.html#probability-density-function",
    "title": "[PRML 읽기] 2 - 확률론 개요(작성중 …)",
    "section": "Probability density function",
    "text": "Probability density function\n확률밀도함수는 연속확률변수가 미소구간안에 속하는 사건에 대한 확률을 미소구간의 길이로 나눈 확률밀도값을 함숫값으로 가지는 확률함수로 정의합니다.\n\\[p(x) \\overset{\\Delta}{=} \\lim_{\\Delta x \\rightarrow 0}\\frac{p(x<X\\leq x+\\Delta x))}{\\Delta x}\\]\n확률밀도함수를 정적분하면 확률변수가 임의의 구간안에 속하는 사건에 대한 확률을 얻을 수 있습니다.(증명)\n\\[\\begin{aligned}\nP(a < X \\leq b) = \\int_{a}^{b}p(u)d(u)\n\\end{aligned}\\]\n확률밀도함수는 다음의 두 가지 조건을 만족해야 합니다. 첫번째 식은 확률(밀도)는 반드시 0보다 크거나 같음을 의미합니다. 두번째 식에서 확률변수는 반드시 \\((-\\infty,\\infty]\\)인 구간안에 속함을 의미합니다.\n\\[\\begin{align}\np(x) \\geq 0 \\\\\n\\int_{-\\infty}^{\\infty}f(t)dt = 1\n\\end{align}\\]"
  },
  {
    "objectID": "posts/DL/[PRML 정독하기] Probability Theory2.html#probabiltiy-variable-transform",
    "href": "posts/DL/[PRML 정독하기] Probability Theory2.html#probabiltiy-variable-transform",
    "title": "[PRML 읽기] 2 - 확률론 개요(작성중 …)",
    "section": "Probabiltiy variable transform",
    "text": "Probabiltiy variable transform\n이 부분의 내용은 PRML에 있는 내용을 각색한 부분입니다. 틀린부분이 있다면 알려주세요!!\n연속확률변수 \\(X\\)의 확률밀도함수를 \\(p_X(x)\\)라 할 때, 변수를 변환하여 \\(X\\)를 \\(Y\\)에 관한 식\\(X = g(Y)\\)로 표현했다고 해봅시다. 목적은 확률변수 \\(Y\\)의 확률밀도함수 \\(p_Y(y)\\)를 얻는 것입니다. \\(\\Delta x\\rightarrow 0 \\Delta y \\rightarrow 0\\)이라고 한다면 다음이 성립합니다.\n\\[\\begin{aligned}\n&\\lim_{\\Delta x \\rightarrow 0}\\frac{p(x < X \\leq x + \\Delta x)}{\\Delta x} \\times \\Delta x \\overset{\\sim}{=} \\lim_{\\Delta y \\rightarrow 0}\\frac{p(y < Y \\leq y + \\Delta y)}{\\Delta y} \\times \\Delta y \\\\\n&\\Longleftrightarrow p_X(x)dx \\overset{\\sim}{=} p_Y(y)dy\n\\end{aligned}\\]\n윗식은 Jacobian factor에 의해 등식으로 바꿀 수 있습니다.\n\\[\\begin{aligned}\np_Y(y) &= p_X(x) \\begin {vmatrix} \\frac{dx}{dy} \\end {vmatrix} \\\\\n&= p_X(g(y))|g^{'}(y)|\n\\end{aligned}\\]\n확률변수의 변환은 확률분포함수를 최대화 하는 문제에서 유용하게 사용할 수 있다고 합니다. 변환할 변수를 선택하면 최대화해야하는 확률함수를 바꿀 수 있습니다."
  },
  {
    "objectID": "posts/DL/[PRML 정독하기] Probability Theory2.html#sum-rule-product-rule-of-continuous-variable",
    "href": "posts/DL/[PRML 정독하기] Probability Theory2.html#sum-rule-product-rule-of-continuous-variable",
    "title": "[PRML 읽기] 2 - 확률론 개요(작성중 …)",
    "section": "Sum rule & Product rule of continuous variable",
    "text": "Sum rule & Product rule of continuous variable\n이산확률변수에 대해서는 Sum rule과 Product rule을 살펴봤었지만 연속확률변수 대해서는 보지 않았었습니다. 연속확률변수의 경우 다음과 같습니다. 엄밀한 증명은 measure theroy로 증명해야 하므로 .. 생략하겠습니다.(간략한 증명)\n\\[\\begin{aligned}\n&p(x) = \\int_y f(x,y)dy \\\\\n&p(x,y) = p(y|x)p(x)\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/DL/[PRML 정독하기] Probability Theory2.html#expectations-and-variances",
    "href": "posts/DL/[PRML 정독하기] Probability Theory2.html#expectations-and-variances",
    "title": "[PRML 읽기] 2 - 확률론 개요(작성중 …)",
    "section": "Expectations and Variances",
    "text": "Expectations and Variances\n함수의 기댓값(또는 평균)은 함숫값이 어떤 값을 중심으로 분포하는지를 알려줍니다. 가능한 모든\\(x\\)에 대하여 함숫값과 그때의 확률분포의 값을 곱하여 얻은 가중평균입니다.\n\\[\\begin{aligned}\n&\\mathbb{E}[f] = \\sum_x p(x)f(x) \\quad \\text{If X is a discrete R.V} \\\\\n&\\mathbb{E}[f] = \\int_x p(x)f(x)dx \\quad \\text{If X is a continuous R.V}\n\\end{aligned}\\]\n표본의 크기가 무한할 경우, 표본으로 부터 구한 함숫값의 평균과 기댓값은 값이 같습니다. 이를 통해서 확률분포의 기댓값을 알 수 있다면 표본이 적당히 크기가 클 경우 함숫값이 어느정도 일지 대략적으로 예측할 수 있습니다.\n\\[\\mathbb{E}[f] = \\lim_{N \\rightarrow \\infty}\\frac{1}{N}\\sum_{n=1}^{N}f(x_n)\\]\n다변수함수는 여러개의 변수를 가지는 함수입니다. 따라서 각각의 변수가 따르는 확률분포중에서 하나를 선택하여 그때의 확률분포와 함숫값의 기댓값을 구할 수 있습니다. 이때 기댓값은 나머지 확률변수에 대한 함수가 됩니다.\n\\[\\mathbb{E}_x[f(x,y)] = f(y)\\]\n함수의 조건부 기댓값은 조건부 확률분포와의 가중평균으로 정의할 수 있습니다. \\(y\\)가 조건으로 주어질 때, \\(x\\)의 조건부 기댓값은 다음과 같습니다.\n\\[\\mathbb{E}_x[f|y] = \\sum_x{p(x|y)}{f(x)}\\]\n확률변수 \\(f(x)\\)의 분산(variance)는 함수가 기댓값을 중심으로 얼마나 퍼져있는지 알려줍니다. 편차제곱의 기댓값(평균)으로 정의합니다.\n\\[\\begin{aligned}\n&\\mathbb{E}[x] = \\int_xxp(x)dx \\text{ or } \\sum_xxp(x)\\\\\n&\n\\begin{aligned}\n\\text{var}[x]\n&= \\mathbb{E}[(x - \\mathbb{E}[x])^2] \\\\\n&= \\mathbb{E}[x^2] - \\mathbb{E}[x]^2\\\\\n\\end{aligned}\n\\end{aligned}\\]\n두 개의 확률변수에 대해서 공분산은 다음과 같습니다.(2번째 식에 대한 전개)\n\\[\\begin{align}\n\\text{cov}[x,y] &= \\mathbb{E}_{x,y}[\\{x-\\mathbb{E}[x]\\}\\{y-\\mathbb{E}[y]\\}] \\\\\n&=\\mathbb{E}_{x,y}[xy] - \\mathbb{E}[x]\\mathbb{E}[y]\n\\end{align}\\]"
  },
  {
    "objectID": "posts/DL/[PRML 정독하기] Probability Theory2.html#appendix",
    "href": "posts/DL/[PRML 정독하기] Probability Theory2.html#appendix",
    "title": "[PRML 읽기] 2 - 확률론 개요(작성중 …)",
    "section": "Appendix",
    "text": "Appendix\n\n확률밀도함수에 관한 여러가지 증명\n누적분포함수는 연속확률변수가 \\((-\\infty,x]\\)인 구간안에 속할 확률입니다.\n\\[F(x) = P(-\\infty<X\\leq x)\\]\n따라서,연속확률분포의 분자를 누적분포함수로 나타낼 수 있습니다. 이는 누적분포함수의 도함수가 확률밀도함수이며 누적분포함수의 기울기,변화율이 확률밀도함수임을 나타냅니다.\n\\[p(x) = \\lim_{\\Delta x \\rightarrow 0}\\frac{p(x<X\\leq x+\\Delta x))}{\\Delta x} = \\lim_{\\Delta x \\rightarrow 0}\\frac{F(x+\\Delta x) - F(x)}{\\Delta x} = \\frac{dF}{dx}\\]\n누적분포함수의 도함수가 확률밀도함수이므로 확률밀도함수의 적분은 누적분포함수입니다.\n\\[\\int_{-\\infty}^{x}f(t)dt = F(x) = P(-\\infty<X\\leq x)\\]\n임의의 구간 \\((a,b]\\)사이에 확률변수 \\(X\\)가 속하는 사건에 대한 확률은 다음과 같습니다.\n\\[\\begin{aligned}\nP(a < X \\leq b) &= P(-\\infty < X \\leq b) - P(-\\infty < X \\leq a) \\\\\n&= F(b) - F(a) \\\\\n&= \\int_{-\\infty}^{b}f(t)dt - \\int_{-\\infty}^{a}f(t)dt \\\\\n&= \\int_{a}^{b}f(t)dt\n\\end{aligned}\\]\n\n\n공분산 전개하기\n\\[\\begin{aligned}\n\\text{cov}[x,y] &= \\mathbb{E}_{x,y}[\\{x-\\mathbb{E}[x]\\}\\{y-\\mathbb{E}[y]\\}] \\\\\n&=\\mathbb{E}_{x,y}[xy - x\\mathbb{E}[y] - y\\mathbb{E}[x] + \\mathbb{E}[x]\\mathbb{E}[y]]\\\\\n&=\\mathbb{E}_{x,y}[xy] - \\mathbb{E}_{x,y}[x\\mathbb{E}[y]] - \\mathbb{E}_{x,y}[y\\mathbb{E}[x]] + \\mathbb{E}[x]\\mathbb{E}[y]]\\\\\n\\end{aligned}\\]\n여기서 \\(\\mathbb{E}_{x,y}[x\\mathbb{E}[y]]\\)는 다음과 같다.\n\\[\\begin{aligned}\n\\int_{\\infty}^{\\infty}\\int_{\\infty}^{\\infty}x\\mathbb{E}[y]p(y)p(x)dydx &=  \\int_{\\infty}^{\\infty}x\\mathbb{E}[y]p(x)\\bigg(\\int_{\\infty}^{\\infty}p(y)dy\\bigg)dx \\\\\n&= \\int_{\\infty}^{\\infty}x\\mathbb{E}[y]p(x)dx \\\\\n&= \\mathbb{E}[y]\\int_{\\infty}^{\\infty}xp(x)dx \\\\\n&= \\mathbb{E}[y]\\mathbb{E}[x]\n\\end{aligned}\\]\n마찬가지로 \\(\\mathbb{E}_{x,y}[y\\mathbb{E}[x]]\\)도 같은 값을 가진다. 따라서 다음과 같다.\n\\[\\begin{aligned}\n\\text{cov}[x,y] &= \\mathbb{E}_{x,y}[xy] - \\mathbb{E}_{x,y}[x\\mathbb{E}[y]] - \\mathbb{E}_{x,y}[y\\mathbb{E}[x]] + \\mathbb{E}[x]\\mathbb{E}[y]]\\\\\n&= \\mathbb{E}_{x,y}[xy] - \\mathbb{E}[y]\\mathbb{E}[x] - \\mathbb{E}[x]\\mathbb{E}[y] + \\mathbb{E}[x]\\mathbb{E}[y] \\\\\n&=\\mathbb{E}_{x,y}[xy] - \\mathbb{E}[x]\\mathbb{E}[y]\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/Linear Algebra/Ax=b의 해의 갯수 알아내기/Ax = b의 해석.html",
    "href": "posts/Linear Algebra/Ax=b의 해의 갯수 알아내기/Ax = b의 해석.html",
    "title": "Ax=b의 해의 갯수 알아내기",
    "section": "",
    "text": "유투브 - 혁펜하임님의 선형대수학강의를 정리하기 위해 작성한 글입니다.Rank와 Null space로 Ax=b의 해의 갯수를 파악합니다.\n연립일차방정식은 행렬 Ax=b로 나타내고 행렬의 랭크와 열공간을 기반으로 해의 갯수를 나타낼 수 있습니다.\n\n열공간을 기반으로 한 Ax=b의 해석\n행렬\\(A = \\begin{bmatrix}a_1 & a_2 & \\dots & a_n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\\)와 벡터\\(x = \\begin{bmatrix}x_1,x_2,\\dots,x_n\\end{bmatrix}^T\\in \\mathbb{R}^{n \\times 1}\\)의 곱을 생각해보자. 행렬과 벡터의 곱은 다음과 같이 열벡터의 일차결합으로 바라볼 수 있다.\n\\[\\begin{aligned}\nAx = \\begin{bmatrix}a_1 & a_2 & \\dots & a_n\\end{bmatrix}\n\\begin{bmatrix}\nx_1\\\\\nx_2\\\\\n\\vdots\\\\\nx_n\n\\end{bmatrix}\n= a_1x_1 + a_2x_2 + \\dots a_nx_n\n\\end{aligned}\\]\n행렬 A의 열공간은 열벡터들의 선형생성이다.\n\\[\\begin{aligned}\n&\\text{C}(A) = \\text{span}(a_1,a_2,\\dots,a_n) = \\{c_1a_1 + c_2a_2 + \\dots c_na_n|c_1,c_2,\\dots,c_n \\in K\\}\n\\end{aligned}\\]\n그러므로, 행렬 \\(A\\)의 열공간은 임의의 \\(x\\)에 대하여 가능한 \\(Ax\\)의 모든 집합과 같다. 가능한 모든 스칼라\\(x_1,x_2,\\dots,x_n\\)로 벡터의 일차결합이 이루는 집합은 생성(span)과 같기 때문이다 \\[\\text{C}(A) = \\text{span}(a_1,a_2,\\dots,a_n) = \\{Ax |x\\in K^n\\}\\]\n만약 \\(Ax = b\\)인 방정식의 해 \\(x\\)를 구하려 한다 하자. \\(\\text{C}(A)\\)는 가능한 \\(Ax\\)의 모든 집합이였으므로 만약 \\(\\text{C}(A)\\)가 \\(b\\)를 포함한다면(즉,\\(b\\)가 열공간의 원소라면) \\(Ax=b\\)인 \\(x\\)가 존재하여 방정식의 해가 존재하고 \\(\\text{C}(A)\\)가 \\(b\\)를 포함하지 않는다면 \\(Ax = b\\)인 \\(x\\)값이 존재하지 않고 따라서 방정식의 해가 존재하지 않는다.\n\n\nCase1 : A가 full column rank일 때\n문제 : \\(A \\in \\mathbb{R}^{m \\times n},\\text{rank}(A) = n<m\\,,x = \\in \\mathbb{R}^{n \\times 1}\\,,b\\in \\mathbb{R}^{m \\times 1}\\) 일때, \\(Ax = b\\)를 만족하는 x의 갯수는?\n 위의 문제에서 A는 full column rank이다. full column rank일 경우 \\(Ax\\)의 모양은 위와 같고 열공간은 m차원 벡터공간의 부분공간이자 n차원 벡터공간이다.앞에서 “m차원 벡터공간의 부분공간인 n차원 벡터공간” 이라 했는데 그 이유는 (열)벡터가 m차원 벡터공간의 원소(벡터)이기 때문이다. m차원 벡터공간에 있는 (열)벡터 n개를 기저로 생성된 공간이기 때문에 m차원 벡터공간의 부분공간이면서 동시에 n차원 벡터공간이 된다. \n위에서 언급했듯이 열공간은 임의의 x에 대하여 가능한 \\(Ax\\)의 집합이기에 방정식의 해가 존재하려면 b가 열공간안에 있으면 되고 아니면 바깥에 있으면 된다. 그렇다면 이 경우 b의 위치는 어떻게 될까?\n\n가능한 b의 위치는 2가지이다. 1의 경우는 열공간안에 b가 없는 경우다. 이 경우 b는 m차원 벡터공간에는 있으면서(\\(b \\in R^{m \\times 1}\\)이기에 당연하다) 부분공간인 n차원 열공간안에는 없게된다. 따라서 이 경우 해는 존재하지 않는다. 2의 경우는 열공간안에 b가 있는 경우다. 이 경우 b는 m차원 벡터공간에 속하면서 동시에 부분공간인 n차원 벡터공간에도 속한다.\n이렇게 생각하면 끝난 것 같은데 한가지 더 생각해야 할 것이 있다. 바로 null space이다. 만약 Ax = b를 만족하는 하나의 해인 \\(x_{particular}\\)가 있다고 해보자. 이때 \\(Ax=0\\)을 만족하는 널공간의 임의의 원소인 \\(x\\)를 \\(x_{null}\\in N(A)\\)이라고 하면 다음이 성립한다.\n\\[A(x_{particular} + x_{null}) = Ax_{particular} + Ax_{null} = b\\]\n윗식에 의해서 null space의 원소인 \\(x_{null}\\)과 \\(x_{particular}\\)의 합도 방정식의 해이므로 해를 구할때 null space도 확인해야 한다. null space에 대한 x를 추가한 완전해는 다음과 같다. \\[x_{complete} = x_{particular} + x_{null}\\]\n그렇다면 x_{null}을 어떻게 확인할 수 있을까? 랭크-널리티 정리로 확인할 수 있는데 위와같이 full column rank인 경우는 다음과 같다.\n\\[\\begin{aligned}\n&\\text{rank}(A) + \\text{nulity(A)} = n\\\\\n&\\Longleftrightarrow \\text{nulity(A)} = n - rank(A) = n - n = 0\n\\end{aligned}\\]\n랭크-널리티 정리에 의하여 null space의 차원이 0임을 확인했다. 차원이 0인 널공간(벡터공간)은 \\(\\{\\bf{0}\\}\\)이므로 \\(x_{null} \\in N(A)\\)인 \\(x_{null} ={\\bf 0}\\)이다. 따라서 2번의 경우, \\(x_{particular}\\)가 존재하여 \\(Ax = 0\\)일 경우의 완전해는 다음과 같다. \\[\\therefore  x_{total} = x_{particular} + x_{null} = x_{particular} + {\\bf 0} = x_{particular}\\]\n결론적으로, full column rank일 경우 해가 존재하지 않거나 단 하나 존재한다.\n\n\nCase2 : A가 full row rank일 때\n문제 : \\(A \\in \\mathbb{R}^{m \\times n},\\text{rank}(A) = m<n\\,,x = \\in \\mathbb{R}^{n \\times 1}\\,,b\\in \\mathbb{R}^{m \\times 1}\\) 일때, \\(Ax = b\\)를 만족하는 x의 갯수는?\n 위의 문제에서 A는 full row rank이다. 위해서 한 것처럼 먼저 \\(C(A)\\)와 \\(b\\)가 어떻게 위치하고 있을지 파악하고 null space를 따져 완전해를 구하는 것이다. 먼저 \\(C(A)\\)를 생각해보자. \\(C(A)\\)는 행렬의 랭크가 m이기에 n개의 (열)벡터 중 선형독립인 column vector는 m개 뿐이다. 따라서 벡터의 span인 열공간은 m차원 벡터공간이다. (n개의 열벡터가 존재하지만,선형종속이기떄문이다.)\n이전문제와 다른점도 존재하는데 바로 열공간이 (열)벡터가 존재하는 벡터공간의 부분공간이 아니라는 점이다. 이 문제에서 각각의 열벡터는 m차원 공간의 벡터이고 열벡터의 생성도 m차원 벡터공간이기때문에 열벡터가 존재하는 바로 그 공간이 열공간이다.\n위와 같이 열공간에 대해서 생각했으면 이제 b에 대해서 생각해볼 차례다. b의 위치는 어떻게 될까? b는 A의 열공간에 속하는 벡터일까 아닐까?\n\nb의 경우 \\(b \\in \\mathbb{R}^{m \\times 1}\\)이기에 열공간에 속하는 벡터이다. 그러므로 full row rank인 경우는 반드시 해가 존재한다.\n여기서 완전해를 구하기 위해서 null space도 생각해야한다. 랭크-널리티 정리에 의해 다음과 같다.\n\\[\\begin{aligned}\n&rank(A) + nulity(A) = n \\\\\n&\\Longleftrightarrow nulity(A) = n - rank(A) =  n - m\n\\end{aligned}\\]\n랭크정리에 의해서 null space는 n-m차원의 벡터공간이다. 이 경우 가능한 \\(x_{null}\\)은 무한히 많이 존재하므로 해가 무수히 많다. 완전해는 다음과 같다.\n\\[\\begin{aligned}\n\\therefore\\,\\,  &x_{complete} = x_{particular} + x_{null}\\\\\n&\\text{where, } x_{null} \\in N(A) = \\mathbb{R}^{n-m}\n\\end{aligned}\\]\n결론적으로, full row rank의 경우 해는 무수히 많다.\n\n\nCase3 : A가 full rank일 때\n문제 : \\(A \\in \\mathbb{R}^{m \\times m},\\text{rank}(A) = m\\,,x = \\in \\mathbb{R}^{n \\times 1}\\,,b\\in \\mathbb{R}^{m \\times 1}\\) 일때, \\(Ax = b\\)를 만족하는 x의 갯수는?\n\n사실 이 문제의 해는 다음과 같다. \\[x = A^{-1}b\\] 그러므로,full rank인 경우 해의 갯수가 1개이다.\n위처럼 간단하게 해를 구할 수 있지만 … 그래도 기하학적으로 생각해보기 위에서 했던 것처럼 따져보자. column space는 m차원 벡터공간이다. column vector는 column space 그 자체인 m차원 벡터공간의 원소이다. \\(b\\in \\mathbb{R}^{m \\times 1}\\)의 경우 m차원 벡터공간의 원소이다. 그러므로, column space는 반드시 b를 포함하며 그림으로 표현하면 다음과 같다.\n\n널공간을 따지기 위해 랭크-널리티 정리를 사용해 보면 다음과 같다.\n\\[\\begin{aligned}\n&\\text{rank}(A)+\\text{nulity}(A) = m\\\\\n&\\Longleftrightarrow \\text{nulity}(A) = m - \\text{rank}(A) = m - m = 0\n\\end{aligned}\\]\nnull space는 차원이 0이므로 \\(N(A) = \\{{\\bf 0}\\}\\)이고 다음과 같다. \\[x_{complete} = x_{particular} + x_{null} = x_{particular} + {\\bf 0} = x_{particular}\\]\n결과적으로, full rank인 경우 해는 반드시 존재하며 갯수는 1개이다.\n\n\nCase4 : A가 rank deficient 일 때\n문제 : \\(A \\in \\mathbb{R}^{m \\times n},\\text{rank}(A) = \\alpha < \\text{min}(m,n)\\,,x = \\in \\mathbb{R}^{n \\times 1}\\,,b\\in \\mathbb{R}^{m \\times 1}\\) 일때, \\(Ax = b\\)를 만족하는 x의 갯수는?\n\n위의 예시에서는 A가 rank deficient인 경우 중, \\(m<n\\) 인 경우를 생각해보자. 행렬 A의 column space는 m차원 공간의 부분공간이자 \\(\\alpha\\)차원의 벡터공간이다.\\(b \\in \\mathbb{R}^{m \\times 1}\\)이므로 가능한 경우는 아래와 같다.\n\n1번의 경우라면 b는 column space의 원소가 아니므로 방정식의 해는 존재하지 않는다. 만약 2번의 경우라면 해가 존재한다. 이때에는 null space를 고려한 완전해를 따져야하므로 랭크-널리티 정리를 확인한다.\n\\[\\begin{aligned}\n&\\text{rank}(A) + \\text{nulity}(A) = \\alpha + \\text{nulity}(A) = n \\\\\n&\\Longleftrightarrow \\text{nulity}(A) = n - \\alpha > 0\n\\end{aligned}\\]\n랭크정리에 의해서 null space는 \\(n - \\alpha\\)차원의 벡터공간이다. 이 경우 null space의 임의의 원소인 \\(x_{null}\\)는 무한히 많이 존재하므로 해가 무수히 많다. 완전해는 다음과 같다.\n\\[\\begin{aligned}\n\\therefore\\,\\,  &x_{complete} = x_{particular} + x_{null}\\\\\n&\\text{where, } x_{null} \\in N(A) = \\mathbb{R}^{n-\\alpha}\n\\end{aligned}\\]\n결론적으로, rank deficient의 경우 해는 무수히 많거나 해는 존재하지 않는다.\n\n\n정리\n\n\n\n\n\n\n\n\nrank type\nexpression\n해의 갯수\n\n\n\n\nfull column rank\n\\(A \\in \\mathbb{R}^{m \\times n}\\),\\(\\text{rank}(A) = n<m\\)\n해가 없거나 해가 한개만 존재한다.\n\n\nfull row rank\n\\(A \\in \\mathbb{R}^{m \\times n}\\),\\(\\text{rank}(A) = m<n\\)\n해가 무수히 많다.\n\n\nfull rank\n\\(A \\in \\mathbb{R}^{m \\times m}\\),\\(\\text{rank}(A) = m\\)\n해가 한개만 존재한다.\n\n\nrank deficient\n\\(A \\in \\mathbb{R}^{m \\times n}\\),\\(\\text{rank}(A) < \\text{min}(m,n)\\)\n해가 없거나 해가 무수히 많다.\n\n\n\n\n\n참고자료\n혁펜하임 - [선대] 2-11강. Ax=b 의 해의 수 알아내기 프린키피아"
  },
  {
    "objectID": "posts/Linear Algebra/eigendecomposition.html",
    "href": "posts/Linear Algebra/eigendecomposition.html",
    "title": "Eigendecomposition & Property",
    "section": "",
    "text": "유투브 - 혁펜하임님의 선형대수학강의를 정리하기 위해 작성한 글입니다.\n\n eigendecomposition\n행렬 \\(A \\in \\mathbb{R}^{2 \\times 2}\\)의 eigen value는 \\(2\\)개 eigen vector도 \\(2\\)개라 하자. 즉 다음과 같다\n\\[\\begin{aligned}\n&Av_1 = \\lambda_1v_1 \\\\\n&Av_2 = \\lambda_2v_2 \\\\\n\\end{aligned}\\]\n\n\n\n\n\n\nNote\n\n\n\n이때 \\(A\\in \\mathbb{R}^{2\\times 2}\\)인 정사각행렬이다. 지금부터 전개할 고윳값분해는 정사각행렬의 행 또는 열의 길이가 고윳값 또는 고유벡터의 길이와 같을때 가능하다.(다를때는 또다른 방법(특잇값분해)가 있다.)\n\n\n여기서 다음과 같은 등식을 생각해볼 수 있다.\n\\[\\begin{aligned}\nA\\begin{bmatrix}v_1\\,v_2\\end{bmatrix} = \\begin{bmatrix}Av_1\\,Av_2\\end{bmatrix} = \\begin{bmatrix}\\lambda_1v_1\\,\\lambda_2v_2\\end{bmatrix} = \\begin{bmatrix}v_1\\,v_2\\end{bmatrix}\\begin{bmatrix}\\lambda_1 & 0 \\\\ 0 & \\lambda_2\\end{bmatrix}\n\\end{aligned}\\]\n\\(V = \\begin{bmatrix}v_1\\,v_2\\end{bmatrix},\\Lambda = \\begin{bmatrix}\\lambda_1 & 0 \\\\ 0& \\lambda_2\\end{bmatrix}\\)라 하면 다음과 같이 정리할 수 있다.\n\\[\\begin{aligned}\n&AV = V\\Lambda \\\\\n&\\Longleftrightarrow A = V\\Lambda V^{-1}\n\\end{aligned}\\]\n이때 A를 decomposition했다고 하며 이렇게 decompose하는 것을 eigendecomposition이라고 한다.\n\n\n diagonalizable\n윗 식을 다음과 같이 적을 수도 있다.\n\\[\\begin{aligned}\n&AV = V\\Lambda \\\\\n&\\Longleftrightarrow A = V\\Lambda V^{-1}\\\\\n&\\Longleftrightarrow V^{-1}A V = \\Lambda\n\\end{aligned}\\]\n이때 \\(A\\)는 diagonalizable(대각화 가능하다)이라고 한다.\n\n\n 대각화 관련 동치명제 정리\n\\(A \\in \\mathbb{R}^{n \\times n}\\)이라 했을때 다음의 명제는 동치이다.\n\\[\\begin{aligned}\n&A\\text{가 diagonalizable하다.} \\\\\n&\\longleftrightarrow A \\text{가 eigendecomposition이 가능하다.}\\\\\n&\\longleftrightarrow A \\text{의 independent한 eigenvector가 n개 존재한다.}\n\\end{aligned}\\]\n\n\n 좋은 점\n\n행렬의 거듭제곱을 간단히 구한다.\n\\[\\begin{aligned}\nA^k =  V\\Lambda V^{-1}V\\Lambda V^{-1}V\\Lambda V^{-1} \\dots V\\Lambda V^{-1} = V\\Lambda^kV^{-1}\n\\end{aligned}\\]\n\n\ninverse matrix의 계산이 간단해진다.\n\\[A^{-1} = (V\\Lambda V^{-1})^{-1} = V\\Lambda ^{-1}V^{-1}\\]\n\n\neigenvector를 모두 곱하면 determinant이다.\n임의의 행렬에 대해서 \\(\\text{det}(A^{-1}) = \\frac{1}{\\text{det}(A)}\\)이다. 또한 대각행렬의 행렬식은 주대각선에 있는 원소를 모두 곱하는 것과 같다. 그러므로 다음과 같다.\n\\[\\begin{aligned}\n&\\text{det}(A) = \\text{det}(V\\Lambda V^{-1}) = \\text{det}(V)\\text{det}(\\Lambda)\\text{det}(V^{-1}) = \\text{det}(\\Lambda) = \\prod_{i=1}^n\\lambda_i \\\\\n&\\text{where, } \\Lambda = \\text{diag}(\\lambda_1,\\lambda_2,\\dots,\\lambda_n)\n\\end{aligned}\\]\n\n\neigenvector를 모두 더하면 trace이다.\n\\[\\text{tr}(A) = \\text{tr}(V\\Lambda V^{-1}) = \\text{tr}(V^{-1}V\\Lambda) = \\text{tr}(\\Lambda) = \\sum_{i=1}^n\\lambda_i\\]\n$= 0 $인 eigenvalue가 하나 이상 존재하는가?\n\\[\\begin{aligned}\n&\\text{행렬 A가 rank - defficient}이다. \\\\\n&\\Longleftrightarrow \\text{det}(A) = 0 \\\\\n&\\Longleftrightarrow  \\prod_{i=1}^n\\lambda_i = 0 \\\\\n&\\Longleftrightarrow \\text{0인 eigen value가 하나 이상 존재한다.}\n\\end{aligned}\\]\n\n\n\n 알아둬야 할 것들\n\n\\(A^T\\)의 eigen value와 \\(A\\)의 eigen value는 같다.\n(characteristic equation이 같음을 보인다.)\n\\[\\begin{aligned}\n\\text{det}(A-\\lambda I) &= \\text{det}((A-\\lambda I)^T)\\quad(\\text{ by} |A| = |A^T|)\\\\\n&= \\text{det}(A^T - \\lambda I)\n\\end{aligned}\\]\n\n\n\\(Q\\)가 \\(Q^{-1} = Q^T\\)인 orthonomal matrix라면 \\(\\lambda = 1 \\text{ or } \\lambda = -1\\)\n\\[\\begin{aligned}\n&Qv = \\lambda v \\\\\n&\\longleftrightarrow (Qv)^TQv = v^TQ^TQv = v^Tv = |v|_2^2 = \\lambda^2|v|_2^2\\\\\n&\\longleftrightarrow \\lambda = 1 \\text{ or } \\lambda = -1\n\n\\end{aligned}\\]\n\n\n대칭행렬이 positive definite \\(\\leftrightarrow \\forall i,\\lambda_i > 0\\) (단,\\(A=A^T\\)인 symmetric matrix,\\(\\lambda_i\\)는 행렬A의 모든 고윳값)\n\n증명1: 대칭행렬이 positive definite \\(\\rightarrow \\forall i,\\lambda_i > 0\\)\n\n먼저 대칭행렬은 랭크1 매트릭스의 합임을 보인다.\n\n\\[\\begin{aligned}\nA &= V\\Lambda V^T\n=\n\\begin{bmatrix}v_1 & v_2 & \\dots &  v_n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda_1 & 0 &\\dots & 0 \\\\\n0 & \\lambda_2 &\\dots &0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0& \\dots & \\lambda_n\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^T \\\\ v_2^T \\\\ \\vdots \\\\ v_n^T\n\\end{bmatrix}\n\\\\\n&=\n\\begin{bmatrix}\n\\lambda_1v_1 & \\lambda_2v_2 & \\dots & \\lambda_nv_n\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^T \\\\ v_2^T \\\\ \\vdots \\\\ v_n^T\n\\end{bmatrix} \\\\\n&=\\sum_{i=1}^{n}\\lambda_iv_iv_i^T\n\\end{aligned}\\]\n\n대칭행렬\\(A\\)가 양의 정부호일 경우 \\({\\bf{x}}^TA{\\bf{x}} >0\\) 이므로 \\(x\\)를 행렬A의 임의의 고유벡터인 \\(v_j\\)로 놓아도 성립해야한다. 즉 다음과 같다.\n\n\\[\\begin{aligned}\n&\\forall j\\in(1,\\dots,n),\\,v_j^TAv_j >0 \\\\\n&\\longleftrightarrow\\forall j\\in(1,\\dots,n),\\,v_j^T(\\sum_{i=1}^n\\lambda_iv_iv_i^T)v_j >0\n\\end{aligned}\\]\n\n그런데 대칭행렬의 경우 고유벡터는 직교(orthogonal)한다. 즉 다음과 같이 정리된다.\n\n\\[\\begin{aligned}\n&\\forall j\\in(1,\\dots,n),\\,v_j^T(\\sum_{i=1}^n\\lambda_iv_iv_i^T)v_j >0\\\\\n&\\longleftrightarrow\\forall j\\in(1,\\dots,n),\\, v_j^T(\\lambda_1v_1 + \\lambda_2v_2 + \\dots + \\lambda_jv_j + \\dots \\lambda_nv_n)v_j >0\\\\\n&\\longleftrightarrow\\forall j\\in(1,\\dots,n),\\,\\lambda_jv_j^Tv_j = \\lambda_j|v_j|_2^2>0\\\\\n&\\longleftrightarrow\\forall j\\in(1,\\dots,n),\\,\\lambda_j>0\n\\end{aligned}\\]\n그러므로, 고윳값은 항상0보다 크다.\n\n\n증명2: \\(\\forall i,\\lambda_i > 0 \\rightarrow\\) 대칭행렬이 positive definite\n\n이차형식은 다음과 같다.\n\n\\[\\begin{aligned}\n{\\bf{x}}^TA{\\bf{x}} &= {\\bf{x}}^T(\\sum_{i=1}^{n}\\lambda_iv_iv_i^T){\\bf{x}} = \\sum_{i=1}^n\\lambda_i{\\bf{x}}^Tv_iv_i^T{\\bf{x}} = \\sum_{i=1}^n\\lambda_i{\\bf{x}}^Tv_i({\\bf{x}}^Tv_i)^T \\\\\n&=\\sum_{i=1}^n\\lambda_i({\\bf{x}}^Tv_i)^T{\\bf{x}}^Tv_i = \\sum_{i=1}^n\\lambda_i||{\\bf{x}}^Tv_i||^2\\\\\n&=\\lambda_1||{\\bf{x}}^Tv_1||^2 + \\lambda_2||{\\bf{x}}^Tv_2||^2 + \\dots + \\lambda_n||{\\bf{x}}^Tv_n||^2\n\\end{aligned}\\]\n\n행렬A의 고유벡터의 집합을 \\(B = {v_1,v_2,\\dots,v_n}\\)으로 두면 고유벡터는 서로간에 직교하므로 orthogonal set이며 이는 \\(\\mathbb{R}^n\\)의 직교기저가 될 수 있음을 의미한다.그러므로, \\({\\bf{x}} \\in \\mathbb{R}^n\\)인 \\({\\bf{x}}\\)에 대하여 내적\\({\\bf{x}}^Tv_i\\)의 값은 적어도 하나는 고유벡터에서는 0보다 커야한다.(간단히 2차원상에 존재하는 벡터는 2차원 공간을 span하는 기저와 모두 직교할 수 없으며 적어도 하나의 기저와는 내적을 했을때 0보다 크다.)\n\n\\[||{\\bf{x}}^Tv_1||^2 + ||{\\bf{x}}^Tv_2||^2 + \\dots + ||{\\bf{x}}^Tv_n||^2 > 0\\]\n\n결과적으로,\\(\\forall i,\\lambda_i>0\\)이라고 가정했으므로 다음과 같다.\n\n\\[{\\bf{x}}^TA{\\bf{x}} = \\lambda_1||{\\bf{x}}^Tv_1||^2 + \\lambda_2||{\\bf{x}}^Tv_2||^2 + \\dots + \\lambda_n||{\\bf{x}}^Tv_n||^2 > 0\\]\n\n\n\nDiagonalizable matrix의 non-zero eigenvalue의 수 = rank(A)\n\n행렬A의 고윳값 분해는 다음과 같다.\n\n\\[\\begin{aligned}\nA = V\\Lambda V^{-1}\n\\end{aligned}\\]\n\n임의의 행렬이 서로다른 행렬의 곱인 경우 가장 작은 랭크는 가장작은 랭크를 따라간다. 윗 식에서 \\(V,V^{-1}\\)는 fullrank이므로 랭크는 \\(\\Lambda\\)에 달려있다.\n\n\\[\\begin{aligned}\n&\\text{rank}(A) = \\text{rank}(V\\Lambda V^{-1}) = \\text{rank}(\\Lambda)\\\\\n&\\text{where } \\Lambda =\n\\begin{bmatrix}\n\\lambda_1 & 0 &\\dots & 0 \\\\\n0 & \\lambda_2 &\\dots &0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0& \\dots & \\lambda_n\n\\end{bmatrix}\n\\end{aligned}\\]\n\n그러므로,\\(\\text{rank}(\\Lambda)\\)는 0이아닌 고윳값의 갯수와 같음을 알 수 있다."
  },
  {
    "objectID": "posts/Linear Algebra/eigenvalue eigenvector.html",
    "href": "posts/Linear Algebra/eigenvalue eigenvector.html",
    "title": "eigenvalue & eigenvector",
    "section": "",
    "text": "유튜브 - 혁펜하임님의 선형대수학 강의 정리용 입니다.\n\n사전지식 : 행렬은 선형변환이다\n함수는 어떤 입력을 주면 출력을 내뱉는다.\n함수그림\n행렬도 마찬가지로 함수이다. 벡터와 행렬의곱 \\(Av\\)는 함수\\(A\\)에 벡터\\(v\\)를 통과시켜 나온 출력이다.\n행렬그림\n행렬은 함수중에서도 선형변환(linear transformation,linear mapping)이다. 왜냐하면 선형변환의 두 가지 조건을 만족하기 때문이다. 선형변환의 두 조건을 만족하기 때문이다. 선형변환의 두 조건은 다음과 같다.\n\\[\\begin{aligned}\n&T(u+v) = T(u) + T(v)\\\\\n&T(av) = aT(v)\n\\end{aligned}\\]\n임의의 행렬 \\(A\\)와 벡터\\(u,v\\)에 대해서 생각해보자. 위의 식을 행렬버전으로 적어보자\n\\[\\begin{aligned}\n&A(u + v) = Au + Av \\\\\n&A(ku) = aAu\n\\end{aligned}\\]\n\n\nDefinition\n\\[\\begin{aligned}\n&Av = \\lambda v(v \\not = {\\bf{{\\bf{0}}}}) \\\\\n&\\text{where, }A \\in \\mathbb{R}^{m \\times m},v \\in \\mathbb{R}^{m \\times 1}\n\\end{aligned}\\]\n위와 같은 방정식에서 \\(\\lambda\\)를 행렬A의 eigenvalue , \\(v\\)를 이에 대응하는 eigenvector라고 한다.\n\n\n예시\n위의 그림에서 왼쪽과 같은 선형변환을 생각해보자. 보라색벡터\\([-1,1]^T\\),초록색벡터\\([1,1]^T\\)의 경우 \\(Av = \\lambda v\\)를 만족하는 eigenvector 이며 대응하는 eigenvalue는 각각 3,1임을 알 수 있다. 또한 오른쪽그림으로부터 선형변환 \\(A\\)의 eigenvector인 보라색벡터와 초록색벡터는 함수\\(A\\)를 통과했을 때, eigenvalue만큼 각각 3,1만큼 길이가 늘어나며 방향이 바뀌지 않고 단순히 스칼라배가 되는 것을 알 수 있다.\n위에서는 초록색 보라색만 찾았지만 사실 선형변환\\(A\\)의 eigenvector는 무한히 많다. 또다른 어떤 선형변환의 경우에는 아예 존재하지 않는 경우도 있다.\n\n\n선형변환 관점에서 invertible\n선형변환(함수) 관점에서 invertible하다는 서로다른 입력이 들어갔을때 서로다른 출력이 나온다이다.\n위의 그림에서 선형변환 \\(A\\)는 각각의 서로다른 입력에 대해서 서로다른 출력이 나오므로 invertible하다. 이는 자연스러운데 각각의 출력으로부터 입력에 하나씩 대응되는 역함수를 생각해볼 수 있기 때문이다.\n위의 그림에서 선형변환 \\(A\\)는 각각의 서로다른 입력에 대하여 동일한 출력을 내뱉으므로 invertible하지 않다. 출력에서 입력으로 대응되는 값이 두개이므로 역함수가 될 수 없다.\n\n\neigenvector,eigenvalue 구하기\n\\[\\begin{align}\n&Av = \\lambda v(v \\not = {\\bf{{\\bf{0}}}}) \\\\\n&\\text{where, }A \\in \\mathbb{R}^{m \\times m},v \\in \\mathbb{R}^{m \\times 1}\n\\end{align}\\]\neigenvector,eigenvalue를 구하기 위한 조건을 끌어내기 위하여 식을 약간 바꾸면 다음과 같다.\n\\[\\begin{aligned}\nAv - \\lambda v = (A-\\lambda I)v = {\\bf{0}}\n\\end{aligned}\\]\n\\(\\lambda\\)는 상수이므로 \\(v\\)로 묶기 위해서 \\(I\\)(항등행렬)를 곱해줬다. 또한 \\(\\lambda Iv = \\lambda v\\)이므로 등호는 여전히 성립한다.윗식에서 eigenvector인 \\(v\\)는 \\(v\\not = \\bf{{\\bf{0}}}\\)의 조건을 만족해야 한다. 만약 \\(\\text{det}(A-\\lambda I) \\not = {\\bf{0}}\\)이라면 \\(A-\\lambda I\\)의 역행렬이 존재하므로 \\(v = (A-\\lambda)I{\\bf{0}} = {\\bf{0}}\\)이 되어 조건을 만족하지 못하게 된다.따라서 \\(\\text{det}(A-\\lambda I) = {\\bf{0}}\\)이어야 한다. 또한 윗식에 의해서 \\(v\\)는 \\((A-\\lambda I)\\)의 null space임을 알 수 있다. 즉 다음과 같다.\n\\[\\begin{aligned}\n&\\text{det}(A-\\lambda I ) \\not = 0 \\text{을 만족하는 } \\lambda\\text{는 eigen value} \\\\\n&v \\in N(A-\\lambda I) \\text{를 만족하는 }v\\text{는 eigen vector}\n\\end{aligned}\\]\n그런데 \\(N(A-\\lambda I)\\)의 원소는 무수히 많으며 그 안에 있는 벡터들은 모두 고유벡터가 맞지만 그냥 null space의 기저만을 대표로 고유벡터로 삼는다."
  },
  {
    "objectID": "posts/Linear Algebra/Least Squares/Least Squares.html",
    "href": "posts/Linear Algebra/Least Squares/Least Squares.html",
    "title": "Least Squares",
    "section": "",
    "text": "\\(A \\in \\mathbb{R}^{m \\times n},\\text{rank}(A) = n<m,x \\in \\mathbb{R}^{n \\times 1},b \\in \\mathbb{R}^{m \\times 1}\\) 가 주어지고 방정식 \\(Ax = b\\)를 만족하는 해인 \\(x\\)를 구할 수 없을 때, \\(Ax\\)가 \\(b\\)와 가장 비슷하게 하는 \\(x\\)를 찾는 것이 목적입니다."
  },
  {
    "objectID": "posts/Linear Algebra/Least Squares/Least Squares.html#projection-matrix",
    "href": "posts/Linear Algebra/Least Squares/Least Squares.html#projection-matrix",
    "title": "Least Squares",
    "section": "projection matrix",
    "text": "projection matrix\n위해서 구한 \\(\\hat{x}\\)를 \\(A\\hat{x}\\)에 대입하면 다음과 같습니다. \\[A\\hat{x} = (A^TA)^{-1}A^Tb\\]\n위 식은 우변의 \\(b\\)에 \\(A(A^TA)^{-1}A^T\\)를 곱하여 \\(C(A)\\)에서 \\(b\\)와 가장 비슷하면서(거리가 가장 가까우면서) \\(b\\)를 \\(C(A)\\)에 정사영(projection) 한 벡터 \\(A\\hat{x}\\)을 얻음을 의미합니다. 따라서 \\(A(A^TA)^{-1}A^T\\)를 projection matrix라 부르고 \\(p_A\\)로 표기합니다."
  },
  {
    "objectID": "posts/Linear Algebra/orthonormal diagonalizability.html",
    "href": "posts/Linear Algebra/orthonormal diagonalizability.html",
    "title": "Diagonalization of symmetric matrix(정리중)",
    "section": "",
    "text": "수튜브님의 직교대각화가능(orthogonal diagonalizability)을 보고 정리한 내용입니다.\n\n orthogonally similar\n다음과 같은 식을 만족하면 C는 A와 orthogonally similar(직교닮음)이다.\n\\[\\begin{aligned}\n&C = P^{-1}AP \\\\\n&\\text{where } P^{-1} = P^T\n\\end{aligned}\\]\n여기서 \\(P^{-1} = P^T\\)는 orthonomal matrix의 정의이다.\n윗 식에 의해서 A도 C와 orthogonally similar이다.\n\\[\\begin{aligned}\n&A = PCP^{-1} \\\\\n&\\text{where } P^{-1} = P^T\n\\end{aligned}\\]\n정리하자면 C가 A와 직교닮음이라면 A도 C와 직교닮음이므로 서로 직교닮음이라는 것을 알 수 있다.\n\n\n orthogonally diagonalize\n임의의 정사각행렬 \\(A,D\\)에 대해서 다음이 만족한다고 해보자.\n\\[\\begin{aligned}\n&\n\\begin{aligned}\nD &= P^{-1}AP \\\\\n&= P^TAP \\\\\n\\end{aligned}\n\\\\\n&\\text{where } D = diag(d_1,d_2,\\dots,d_n) , P^{-1} = P^T\n\\end{aligned}\\]\n이와 같이 \\(A\\)와 직교닮음인 대각행렬 \\(D\\)가 존재할때 행렬\\(A\\)가 직교대각화 되었다 라고 한다.\n\n\n orthogonally diagonalizable\n임의의 정사각행렬 \\(A\\)에 대해서 \\(P^{-1}AP\\)가 대각행렬D가 되게하는 가역행렬이자 orthornomal matrix인 \\(P\\)가 존재한다면 행렬\\(A\\)는 “orthogonally diagonalizable”하다고 한다.\n\n\n 정리1 : orthogonally diagonalizable \\(\\rightarrow A = A^T\\)\n행렬\\(A\\)가 orthogonally diagonalizable하다고 하자. 즉 \\(D = P^TAP\\)를 만족하는 직교행렬 \\(P\\)가 존재한다. 이때 \\(A^T\\)를 전개하면 다음과 같다.\n\\[\\begin{aligned}\n&A = PDP^{-1} = PDP^T\\\\\n&A^T = (PDP^T)^T = PD^TP^T = PDP^T = A\n\\end{aligned}\\]\n\n\n 정리2 : $A = A^T $ orthogonally diagonalizable\n귀납법으로 증명한다.즉 아래의 두 가지가 증명 가능함을 보인다.\n\n\\(A \\in \\mathbb{R}^{1 \\times 1}\\) 일때 직교대각화가 가능하다.\n\\(A \\in \\mathbb{R}^{(n-1)\\times (n-1)}\\)때 직교대각화가 가능하다고 가정하고 \\(A \\in \\mathbb{R}^{n \\times n}\\)때 직교대각화가 가능함을 보인다.\n\n먼저 \\(A \\in \\mathbb{R}^{1 \\times 1}\\) 일때 직교대각화가 가능함을 보인다. 먼저 \\(A\\)와 \\(P\\)행렬을 잡는다.\n\\[\\begin{aligned}\n&A = \\begin{bmatrix}a\\end{bmatrix}\n\\in \\mathbb{R}^{1 \\times 1} \\\\\n&P = \\begin{bmatrix}1\\end{bmatrix}\n\\in \\mathbb{R}^{1 \\times 1}\n\\end{aligned}\\]\n여기서 \\(A=A^T\\)인 대칭행렬이며 \\(P\\)의 경우 \\(P^{-1} = P^T\\)가 성립하는 orthonomal matrix이다.\n\\[\\begin{aligned}\nD = P^{-1}AP = \\begin{bmatrix}a\\end{bmatrix}\n\\end{aligned}\\]\nD는 대각행렬이다. 따라서 \\(D = P-1AP\\)를 만족하는 가역행렬이자 직교행렬인\\(P\\)와 대각행렬\\(D\\)가 존재하므로 행렬\\(A \\in \\mathbb{R}^{1 \\times 1}\\)는 orthogonally diagonalizable하다.\n생략 …..\n\n\n 최종정리 : $A = A^T $ orthogonally diagonalizable\n“임의의 행렬\\(A\\)가 orthogonally diagonalizable하다”는 “\\(A = A^T\\)이다.”와 동치이다.\n\n\n 참고자료\n수튜브"
  },
  {
    "objectID": "posts/Linear Algebra/orthonormal matrix.html",
    "href": "posts/Linear Algebra/orthonormal matrix.html",
    "title": "Diagonalization of symmetric matrix(정리중)",
    "section": "",
    "text": "수튜브님의 직교대각화가능(orthogonal diagonalizability)을 보고 정리한 내용입니다."
  },
  {
    "objectID": "posts/Linear Algebra/orthonormal matrix.html#definition",
    "href": "posts/Linear Algebra/orthonormal matrix.html#definition",
    "title": "Diagonalization of symmetric matrix(정리중)",
    "section": " Definition",
    "text": "Definition\n(definition) orthonormal matrix(orthogonal matrix) is a real square matrix whose columns and rows are orhonormal vectors\n즉, 행벡터들과 열벡터들이 orthonormal인 matrix 정사각행렬을 orthonormal matrix라 한다.이러한 orthonormal matrix Q는 다음을 만족한다.(orthogonal 또는 orthonormal 둘 다 맞는 표현이다.그러나 직교 + 크기가 1인 벡터가 열벡터이기에 orthogonal + normal = orthonormal이 더 맞는 듯 하다.)"
  },
  {
    "objectID": "posts/Linear Algebra/orthonormal matrix.html#expression-1",
    "href": "posts/Linear Algebra/orthonormal matrix.html#expression-1",
    "title": "Diagonalization of symmetric matrix(정리중)",
    "section": " expression 1",
    "text": "expression 1\northonormal matrix \\(Q\\)의 정의는 다음과 같이 수식으로 표현할 수 있다.\n\\[\\begin{aligned}\n&Q^TQ = QQ^T = I \\\\\n&\\text{where } I \\text{ is the identity matrix}\n\\end{aligned}\\]\n정의가 왜 위와같은 수식을 만족하는지 확인해보자. 임의의 \\(Q \\in \\mathbb{R}^{n \\times n}\\)가 다음과 같다고 해보자.\n\\[\\begin{aligned}\n&Q =\n\\begin{bmatrix}\nq_1 & q_2 & \\dots q_n\n\\end{bmatrix}\n\\end{aligned}\\]\n여기서 \\(q_i \\in \\mathbb{R}^{n \\times 1}(i=1,2,\\dots,n)\\)은 \\(Q\\)의 column vector이다. \\(Q^TQ = I\\)를 계산해보면 …\n\\[\\begin{aligned}\nQ^TQ =\n\\begin{bmatrix}\nq_1 \\\\ q_2 \\\\ \\vdots \\\\ q_n\n\\end{bmatrix}\n\\begin{bmatrix}\nq_1 & q_2 & \\dots & q_n\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\text{dot}(q_1,q_1) & \\text{dot}(q_1,q_2) & \\dots & \\text{dot}(q_1,q_n) \\\\\n\\text{dot}(q_2,q_1) & \\text{dot}(q_2,q_2) & \\dots & \\dots \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\n\\text{dot}(q_n,q_1) & \\text{dot}(q_n,q_2) & \\dots & \\text{dots}(q_n,q_n)\\\\\n\\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 & \\dots & 0\\\\\n0 & 1 & \\dots & 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & 1\\\\\n\n\n\\end{bmatrix}\n\\end{aligned}\\]\n이는 같은 벡터끼리 내적을 하면 1이고 다른벡터끼리 내적하면 0임을 의미한다.\n\\[\\begin{aligned}\ndot(q_i,q_j) =\n\\begin{cases}\n1 \\quad (i = j)\\\\\n0 \\quad (\\text{otherwise})\n\\end{cases}\n\\text{for all }i \\in (1,\\dots,n),\\,j \\in (1,\\dots,n)\n\\end{aligned}\\]\n그러므로, 임의의 벡터\\(q_i\\)의 크기는 1인 unit vector이며 열벡터들은 orthonormal하다.\n\\[\\begin{aligned}\n&\\text{for all }i \\in (1,...,n), j \\in (1,...,n) \\\\\n&|q_i| = \\sqrt{q_i} = \\sqrt{dot(q_i,q_i)} = 1 \\\\\n&dot(q_i,q_j)=0 \\longleftrightarrow q_i\\perp q_j\n\n\\end{aligned}\\]\n\\(Q\\)의 행벡터를 \\(q_i^T\\)로 잡고 동일한 과정을 수행하면 행벡터들도 orthonormal하다는 것을 알 수 있다."
  },
  {
    "objectID": "posts/Linear Algebra/orthonormal matrix.html#expression-2",
    "href": "posts/Linear Algebra/orthonormal matrix.html#expression-2",
    "title": "Diagonalization of symmetric matrix(정리중)",
    "section": " expression 2",
    "text": "expression 2\n또한 정의에 대한 expression1은 다음의 식과 동치이다.\n\\[\\begin{aligned}\n&Q^T = Q^{-1} \\\\\n\\end{aligned}\\]\n즉,어떤 행렬의 transpose가 그것의 inverse와 같으면 orthonormal matrix라는 것이며 이것또한 orthonormal matrix의 정의이다.\n왜 그런가 하면 expression1에서 \\(Q^TQ = QQ^T = I\\)였다. 그러므로 \\(Q\\)의 역행렬\\(Q^{-1}\\)는 \\(Q^T\\)와 같다. (Q의 역행렬은 \\(Q^{-1}Q = QQ{-1} = I\\)를 만족하는 행렬이다.)"
  },
  {
    "objectID": "posts/Linear Algebra/orthonormal matrix.html#정리1-orthogonally-diagonalizable-하면-a-at",
    "href": "posts/Linear Algebra/orthonormal matrix.html#정리1-orthogonally-diagonalizable-하면-a-at",
    "title": "Diagonalization of symmetric matrix(정리중)",
    "section": " 정리1 : orthogonally diagonalizable 하면 A = A^T",
    "text": "정리1 : orthogonally diagonalizable 하면 A = A^T\n행렬\\(A\\)가 orthogonally diagonalizable하다고 하자. 즉 \\(D = P^TAP\\)를 만족하는 직교행렬 \\(P\\)가 존재한다. 이때 \\(A^T\\)를 전개하면 다음과 같다.\n\\[\\begin{aligned}\n&A = PDP^{-1} = PDP^T\\\\\n&A^T = (PDP^T)^T = PD^TP^T = PDP^T = A\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/Linear Algebra/orthonormal matrix.html#정리2-대칭행렬이면-orthogonally-diagonalizable",
    "href": "posts/Linear Algebra/orthonormal matrix.html#정리2-대칭행렬이면-orthogonally-diagonalizable",
    "title": "Diagonalization of symmetric matrix(정리중)",
    "section": " 정리2 : 대칭행렬이면 orthogonally diagonalizable",
    "text": "정리2 : 대칭행렬이면 orthogonally diagonalizable\n귀납법으로 증명한다.즉 아래의 두 가지가 증명 가능함을 보인다.\n\n\\(A \\in \\mathbb{R}^{1 \\times 1}\\) 일때 직교대각화가 가능하다.\n\\(A \\in \\mathbb{R}^{(n-1)\\times (n-1)}\\)때 직교대각화가 가능하다고 가정하고 \\(A \\in \\mathbb{R}^{n \\times n}\\)때 직교대각화가 가능함을 보인다.\n\n먼저 \\(A \\in \\mathbb{R}^{1 \\times 1}\\) 일때 직교대각화가 가능함을 보인다. 먼저 \\(A\\)와 \\(P\\)행렬을 잡는다.\n\\[\\begin{aligned}\n&A = \\begin{bmatrix}a\\end{bmatrix}\n\\in \\mathbb{R}^{1 \\times 1} \\\\\n&P = \\begin{bmatrix}1\\end{bmatrix}\n\\in \\mathbb{R}^{1 \\times 1}\n\\end{aligned}\\]\n여기서 \\(A=A^T\\)인 대칭행렬이며 \\(P\\)의 경우 \\(P^{-1} = P^T\\)가 성립하는 orthonomal matrix이다.\n\\[\\begin{aligned}\nD = P^{-1}AP = \\begin{bmatrix}a\\end{bmatrix}\n\\end{aligned}\\]\nD는 대각행렬이다. 따라서 \\(D = P-1AP\\)를 만족하는 가역행렬이자 직교행렬인\\(P\\)와 대각행렬\\(D\\)가 존재하므로 행렬\\(A \\in \\mathbb{R}^{1 \\times 1}\\)는 orthogonally diagonalizable하다.\n생략 …..\n따라서 “행렬 A가 orthogonally diagonalizable하다.”는 “행렬A는 대칭행렬이다.”와 동치이다."
  },
  {
    "objectID": "posts/Linear Algebra/quadratic form/quadratic forms.html",
    "href": "posts/Linear Algebra/quadratic form/quadratic forms.html",
    "title": "Quadratic Form(작성중)",
    "section": "",
    "text": "딥러닝공부방,soohee410님의 블로그을 읽고 정리한 내용입니다.\n\n Definition of Quadratic Form\n벡터\\({\\bf{x}}\\)의 이차형식(Quadratic form)은 다음과 같이 정의한다.\n\\[\\begin{aligned}\n&Q({\\bf{x}}) = {\\bf{x}}^TA{\\bf{x}}\\\\\n&\\text{where }\n\\begin{aligned}\n&A = A^T \\in \\mathbb{R}^{n \\times n},x \\in \\mathbb{R}^{n \\times 1}\n\\end{aligned}\n\\end{aligned}\\]\n여기서 행렬\\(A\\)는 이차형식의 행렬(matrix of quadratic form)이라고 하며 \\(A=A^T\\)를 만족하는 대칭행렬이며 \\({\\bf{x}}\\)는 벡터이다.\n\n\n Example\n\\({\\bf{x}} = [x_1,x_2]^T\\) ,\\(A = \\begin{bmatrix}3 & -2 \\\\ -2 & 7\\end{bmatrix}\\)일때, quadratic form을 구해보자.\n\\[\\begin{aligned}\n&Q({\\bf{x}}) = {\\bf{x}}^TA{\\bf{x}} =\n\\begin{bmatrix}\nx_1 & x_2\n\\end{bmatrix}\n\\begin{bmatrix}3 & -2 \\\\ -2 & 7\\end{bmatrix}\n\\begin{bmatrix}\nx_1 \\\\ x_2\n\\end{bmatrix}\n= \\begin{bmatrix}\nx_1 & x_2\n\\end{bmatrix}\n\\begin{bmatrix}\n3x_1-2x_2 \\\\ -2x_1 + 7x_2\n\\end{bmatrix}\n= 3x_1^2 -4x_1x_2 + 7x_2^2\n\\end{aligned}\\]\n\n\n Change of Variable in a Quadratic From\n\n\n\ncross product항이 존재하지 않는 경우\n\n\n위의 그림은 이차형식을 좌표계에서 표현한 것이다. 각각의 이차형식에서 원점으로부터 거리가 가장 먼 좌표를 찾아보자. 초록색 이차형식의 경우 x1 = 0을 대입하여 바로 x2를 구할 수 있다. 그러나 빨강색 이차형식의 거리가 가장 먼 곳의 좌표가 어디인지 바로 직관적을 파악하기가 어렵다. 이는 crossproduct항이 이차형식안에 존재하여 축에서 부터 사선방향으로 그래프를 회전시키기 때문이다.\n\n만약 빨강색 이차형식이 다음과 같이 새로운축을 기준으로 cross product를 제거하여 회전되지 않은 형태로 표현된다면 어떨끼? 초록색 이차형식에서 직관적으로 거리가 가장 먼 곳의 좌표를 알 수 있었던 것처럼 가장 먼 곳의 좌표가 y2 = 0인 점이라는 것이 직관적으로 보이므로 이를 대입하여 거리가 가장 먼 곳의 좌표를 간단하게 구할 수 있을 것이다.\n이와 같이 축을 바꿔서 하여 cross product항을 제거하면 최소 또는 최대가 되는 좌표를 바로 구할 수 있게 해줘서 최적화 관점에서 이점이 많다. 그렇다면 식을 새로운 축을 기준으로 어떻게 바꾸는 방법은 뭘까? 이는 이차형식의 변수변환을 활용하면 된다.\n먼저 어떤 \\(\\bf{x}\\)를 \\(\\bf{{\\bf{y}}}\\)에 행렬 A의 고유벡터행렬인 \\(P\\)가 곱해진 꼴로 생각하자. 이때 행렬A는 대칭행렬이며 직교대각화가 가능하므로 \\(P\\)는 \\(P^{-1} = P^T\\)를 만족하는 orthonomal matrix로 두자.\n\\[\\begin{aligned}\n&{\\bf{x}} = P{\\bf{{\\bf{y}}}} \\\\\n&{\\bf{{\\bf{y}}}}=P^{-1}{\\bf{x}}\\\\\n&\\text{where }P^{-1} = P^T\n\\end{aligned}\\]\n이때 \\(P = \\begin{bmatrix}p_1 & p_2 & \\dots &p_n \\end{bmatrix}\\)인 정규직교행렬이므로 \\(P\\)의 고유벡터들은 orthonomal하다. 그러므로 고유벡터들의 집합인 \\(B = \\{p_1,p_2,\\dots,p_n\\}\\)를 구성하면 \\(B\\)는 \\(\\mathbb{R}^n\\)공간의 또다른 (표준기저가아닌)정규직교기저이며 \\({\\bf{y}}\\)는 \\({\\bf{x}}\\)를 정규직교기저 \\(B\\)로 표현한 좌표\\([{\\bf{x}}]_B\\)이다. 즉 다음과 같다.\n\\[\\begin{aligned}\n&{\\bf{x}} = P{\\bf{y}}\\\\\n&\\longleftrightarrow {\\bf{x}} = p_1y_1 + p_2y_2 + \\dots + p_ny_n\\\\\n&\\longleftrightarrow {\\bf{y}} = [{\\bf{x}}]_B\n\\end{aligned}\\]\n이를 이차형식에 대입해보자\n\\[\\begin{aligned}\n&{\\bf{x}}^TA{\\bf{x}} = (P{\\bf{y}})^TA(P{\\bf{y}}) = {\\bf{y}}^TP^TAP{\\bf{y}} = {\\bf{y}}^TD{\\bf{y}}\\\\\n&\\text{where } D = P^TAP,P^T = P^{-1}\n\\end{aligned}\\]\n\\(A\\)는 대각행렬이므로 직교대각화\\(D = P^TAP\\)가 가능하다. 따라서 \\({\\bf{x}}\\)의 이차형식은 벡터\\({\\bf{y}}\\)의 이차형식이 되었음을 알 수 있다.\n\\[\\begin{aligned}\n{\\bf{x}}^TA{\\bf{x}}= {\\bf{y}}^TD{\\bf{y}} =\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda_1 & 0 &\\dots & 0 \\\\\n0 & \\lambda_2 &\\dots & 1 \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n0 & 0 & \\dots & \\lambda_n \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1 & y_2 & \\dots & y_n\n\\end{bmatrix}\n= \\lambda_1y_1^2 + \\lambda_2y_2^2 + \\dots + \\lambda_ny_n^2\n\\end{aligned}\\]\n조금 더 전개해보면 다음과 같은 \\(y\\)에 관한 식으로 나타난다.결론적으로 \\(D\\)가 대각행렬이기 때문에 crossproduct term이 나타나지 않으며 \\(B = \\{p_1,p_2,\\dots,p_n\\}\\)을 기저로 하는 새로운 좌표축에서 식을 표현할 수 있다.\n\n\n Example - 직교대각화\n행렬 \\(A =\\begin{bmatrix}4 & 2 & 2 \\\\ 2 & 4 & 2 \\\\ 2 & 2 & 4\\end{bmatrix}\\) 를 직교대각화해라.\n먼저 행렬 A의 고윳값과 고유벡터를 구해보자. 다음과 같은 방정식을 만족하는 \\(\\lambda\\)가 고윳값이다.\n\\[\\begin{aligned}\n&\\text{det}(\\lambda I - A) = {\\bf{0}} \\\\\n&\\longleftrightarrow\n\\begin{bmatrix}\n\\lambda -4 & -2 & -2 \\\\\n-2 & \\lambda -4 & -2 \\\\\n-2 & -2 & \\lambda -4\n\\end{bmatrix} = {\\bf{0}} \\\\\n&\\longleftrightarrow(\\lambda-2)^2(\\lambda-8) = 0\n\\end{aligned}\\]\n따라서 고윳값은 2와 8이다.\n각각의 고윳값에 대한 단위고유벡터를 구해보면 다음과 같다. (이때 고유공간을 생성하는 orthonormal set을 구하는 방법은 나중에 공부를 더 해야할 듯 하다(그람슈미트?직교여공간?))\n\\[\\begin{aligned}\n&\n\\lambda=2 : p_1 = \\begin{bmatrix}-1/\\sqrt{2} & 1/\\sqrt{2}& 0\\end{bmatrix}^T,p_2 = \\begin{bmatrix}-1/\\sqrt{6}&-1/\\sqrt{6}&2/\\sqrt{6}\\end{bmatrix}^T \\\\\n&\\lambda=8 : p_3 = \\begin{bmatrix}1/\\sqrt{3} & 1/\\sqrt{3} & 1/\\sqrt{3}\\end{bmatrix}^T\n\\end{aligned}\\]\n대각행렬 D를 구해보면 다음과 같다.\n\\[\\begin{aligned}\nD = P^{-1}AP = \\text{diag}(2,2,8)\n\\end{aligned}\\]\n\nimport torch\nA = torch.FloatTensor([\n    [4,2,2],\n    [2,4,2],\n    [2,2,4]\n])\np_1 = torch.FloatTensor(\n    [[-1/2**(1/2),1/2**(1/2),0]]\n).T\np_2 = torch.FloatTensor(\n    [[-1/6**(1/2),-1/6**(1/2),2/6**(1/2)]]\n).T\np_3 = torch.FloatTensor(\n    [[1/3**(1/2),1/3**(1/2),1/3**(1/2)]]\n).T\nP = torch.concat([p_1,p_2,p_3],axis=1)\nP_inv = P.inverse()\n#대각화\nD = P_inv @ A @ P\nprint(\"대각행렬 D\\n\",D.round())\n\n대각행렬 D\n tensor([[2., 0., -0.],\n        [-0., 2., -0.],\n        [0., 0., 8.]])\n\n\n\n\n Example - Change of Variable in Quadratic Form\n위에서 구한 \\({\\bf{x}} = [x_1,x_2]^T\\) ,\\(A = \\begin{bmatrix}3 & -2 \\\\ -2 & 7\\end{bmatrix}\\)일때, quadratic form을 변수변환해보자.\n\\[\\begin{aligned}\n&Q({\\bf{x}}) = {\\bf{x}}^TA{\\bf{x}}\n= 3x_1^2 -4x_1x_2 + 7x_2^2\n\\end{aligned}\\]\n먼저 고윳값과 고유벡터를 구하면 다음과 같다. 이때 고유벡터는 모두 단위벡터이자 orthonomal한 벡터들이다.\n\\[\\begin{aligned}\n&\n\\lambda=3 : p_1 = \\begin{bmatrix}2/\\sqrt{5} & -1/\\sqrt{5}\\end{bmatrix}^T\\\\\n&\\lambda=-7 : p_2 = \\begin{bmatrix}1/\\sqrt{5} & 2/\\sqrt{5} \\end{bmatrix}^T\n\\end{aligned}\\]\n\\(P\\)는 고유벡터행렬이자 \\(P^{-1} = P^T\\)를 만족하는 orthonomal matrix(정규직교행렬)이다. 다음과 같다.\n\\[\\begin{bmatrix}2/\\sqrt{5} & 1/\\sqrt{5}\\\\-1\\sqrt{5} & 2/\\sqrt{5}\\end{bmatrix}\\]\n대각화도 한번 해보면 다음과 같다.\n\\[D = P^{-1}AP = \\begin{bmatrix}3 & 0 \\\\ 0 & -7\\end{bmatrix}\\]\n이제 위에서 구한 \\(P\\)로 변수변환을 할 수 있다. \\({\\bf{x}}\\)=\\(P{\\bf{y}}\\)를 quadratic form에 대입하면 다음과 같이 정리된다.\n\\[\\begin{aligned}\nQ({\\bf{x}}) &= x^TAx = (Py)^TA(Py) = y^TP^TAPy = y^TP^TAPy\\\\\n&=y^TDy = 3y_1^2 - 7y_2^2\n\\end{aligned}\\]\n이러한 변수변환을 시각화 해보면 다음과 같다고 한다.\n\n\\({\\bf{x}} = P{\\bf{y}}\\)관계를 가질때 \\({\\bf{x}}^TA{\\bf{x}} = {\\bf{y}}^TD{\\bf{y}}\\)와 같은 값에 mapping됨을 잘 보여준다.\n\n\n The Principal Axes Theorem\n행렬 \\(A = A^T \\in R^{n \\times n}\\)라 가정해보자. 두 벡터사이에 \\({\\bf{x}}=P{\\bf{y}}\\)인 관계가 있다면 \\({\\bf{x}}\\)의 이차형식 \\(Q({\\bf{x}}) = {\\bf{x}}^TA{\\bf{x}}\\)는 cross-product form이 없는 \\(\\bf{y}\\)의 이차형식 \\({\\bf{y}}^TD{\\bf{y}}\\)와 같다는 정리이다. 이때 \\(A\\)행렬의 고유벡터가 각각의 column을 이루는 orthonormal matrix(정규직교행렬) \\(P\\)의 각각의 열들을 이차형식 \\(x^TAx\\)의 주축(principal axes)라고 부른다.\n\n위의 그림의 (a)는 바로 위 예제에서 사용된 이차형식이다. \\(y_1\\)과 \\(y_2\\)는 \\(\\mathbb{R}\\)^2의 기저인 \\(B = \\{p_1,p_2\\}\\)을 기저로 하는 새로운 축이며 타원은 이 축을 기준으로 원점에 놓이며 회전하지 않은 형태이다.\n\n\nClassifiying Quadratic Forms\n이차형식의 부호는 다음과 같이 정의할 수 있다.\n\\[\\begin{aligned}\n&x \\not =0,Q(x)>0 \\leftrightarrow \\text{positive definite}\\\\\n&x \\not =0,Q(x)<0 \\leftrightarrow \\text{negative definite}\\\\\n&\\text{Q(x)가 양수와 음수 모두 지닌다면} \\leftrightarrow \\text{indefinite}\\\\\n&Q(x)\\geq 0 \\leftrightarrow \\text{positive semidefinite}\\\\\n&Q(x)\\leq 0 \\leftrightarrow \\text{negative semidefinite}\n\\end{aligned}\\]\n고윳값으로 이차형식의 부호를 알 수 있다. 이차형식을 전개하면 다음과 같다.\n\\[Q({\\bf{x}}) = {\\bf{x}}^TA{\\bf{x}} = \\lambda_1x_1^2 + \\lambda_2x_2^2 + \\dots + \\lambda_nx_n^2\\]\n\\(x\\)에 관한 제곱항은 모두 양수이므로 행렬 \\(A\\)의 고윳값의 부호에 의하여 이차형식의 부호가 결정된다.\n\\[\\begin{aligned}\n&\\forall i,\\lambda_i > 0 \\leftrightarrow \\text{positive definite}\\\\\n&\\forall i,\\lambda_i < 0 \\leftrightarrow \\text{negative definite}\\\\\n&\\forall i,\\lambda_i\\text{ 가 양수이거나 음수이다.}\\leftrightarrow \\text{indefinite}\n\\end{aligned}\\]\n\n\n \\({\\bf{x}}^TA{\\bf{x}}> 0 \\rightarrow\\) A : invertible\n임의의 행렬 \\(A \\in \\mathbb{R}^{n \\times n}\\)일 때 다음이 성립한다.\n$$(A) = _1_2_n\n만약 \\(A = A^T\\)인 대칭행렬이며 이차형식이 positive definite라면 다음과 같다.\n\\[({\\bf{x}}^TA{\\bf{x}}>0) \\leftrightarrow \\text{positive definite}\\rightarrow \\forall i,\\lambda_i >0 \\rightarrow \\text{det(A)}>0 \\rightarrow A : \\text{invertible}\\]\n그러므로, 이차형식이 positive definite라면 이차형식의 행렬\\(A\\)는 invertible하다."
  },
  {
    "objectID": "posts/Linear Algebra/rank and null space/rank and null space.html",
    "href": "posts/Linear Algebra/rank and null space/rank and null space.html",
    "title": "rank & null space(kernel)",
    "section": "",
    "text": "유투브 - 혁펜하임님의 선형대수학강의를 정리하기 위해 작성한 글입니다."
  },
  {
    "objectID": "posts/Linear Algebra/rank and null space/rank and null space.html#예제",
    "href": "posts/Linear Algebra/rank and null space/rank and null space.html#예제",
    "title": "rank & null space(kernel)",
    "section": "예제",
    "text": "예제\n\\[\\begin{pmatrix}\n1&2&3\\\\\n0&0&0\n\\end{pmatrix}\\]\n위에 있는 행렬에서 선형독립인 열벡터의 갯수 = 1이다. 또한 선형독립인 열벡터의 갯수 = 선형독립인 행벡터의 갯수 = 열공간의 차원 = 행공간의 차원이므로 랭크정리도 성립한다.\n위와 같은 \\(2 \\times 3\\) 행렬은 랭크보다 행,열의 갯수가 많이 부족하므로 rank-deficient 라고 한다.\n\\[\\begin{pmatrix}\n1&0&1\\\\\n0&1&1\n\\end{pmatrix}\\]\n위에 있는 행렬에서 선형독립인 열벡터의 갯수 = 2이다. 또한 선형독립인 열벡터의 갯수 = 선형독립인 행벡터의 갯수 = 열공간의 차원 = 행공간의 차원이므로 랭크정리도 성립한다.\n위와 같은 행렬은 행의 갯수만큼 랭크가 다 차있으므로 full row rank라 한다."
  },
  {
    "objectID": "posts/Linear Algebra/rank and null space/rank and null space.html#용어정리",
    "href": "posts/Linear Algebra/rank and null space/rank and null space.html#용어정리",
    "title": "rank & null space(kernel)",
    "section": "용어정리",
    "text": "용어정리\n\\(A \\in \\mathbb{R}^{m \\times n},\\text{rank}(A) = n<m \\Rightarrow\\) 열벡터가 모두 선형독립,full column rank,위아래로 길쭉하고 양옆은 좁은 직사각행렬 \\(A \\in \\mathbb{R}^{m \\times n},\\text{rank}(A) = n>m \\Rightarrow\\) 행벡터가 모두 선형독립,full row rank,위아래가 좁고 좌우 양옆으로 길쭉한 직사각행렬 \\(A \\in \\mathbb{R}^{n \\times n},\\text{rank}(A) = n \\Rightarrow\\) 행백터,열벡터가 모두 선형독립,full rank,위,아래,양,옆의 길이가 모두 같은 정사각행렬 \\(A \\in \\mathbb{R}^{m \\times n},\\text{rank}(A) < \\text{min}(n,m)\\) = 선형종속인 행벡터,열벡터 반드시 존재,rank deficient"
  },
  {
    "objectID": "posts/Linear Algebra/rank and null space/rank and null space.html#예제1",
    "href": "posts/Linear Algebra/rank and null space/rank and null space.html#예제1",
    "title": "rank & null space(kernel)",
    "section": "예제1)",
    "text": "예제1)\n행렬 A = \\(\\begin{pmatrix}1&0&1 \\\\0&1&1\\end{pmatrix}\\)일 때, 행렬A의 영공간은?\n먼저 만족하는 \\(x\\)를 찾아보자. 어떤 방법이던 사용가능하지만 문제가 간단하므로 직관적으로 풀이한다.\n\\[\\begin{aligned}\n&Ax = x_1\\begin{pmatrix}1\\\\0\\end{pmatrix} + x_2\\begin{pmatrix}0 \\\\ 1\\end{pmatrix} + x_3\\begin{pmatrix}1\\\\1\\end{pmatrix} = {\\bf 0} \\\\\n&\\Longleftrightarrow\n\\begin{cases}\nx_1 + x_3 = 0 \\\\\nx_2 + x_3 = 0\n\\end{cases}\n\\\\\n&\\Longleftrightarrow x_3 = t,x_2 = -t,x_1 = t \\\\\n&\\Longleftrightarrow x = t\\begin{pmatrix}1\\\\-1\\\\1\\end{pmatrix} \\\\\n&\\therefore \\text{N}(A) = \\Bigg\\{t\\begin{pmatrix}1\\\\-1\\\\1 \\end{pmatrix}|t \\in \\mathbb{R}\\Bigg\\}\n\\end{aligned}\\]\n방정식의 해를 구해보니 1)\\([1,-1,1]^T\\)의 span이 영공간이며 2)영공간은 행렬곱에 의해서(중간에서 차원일치 \\(2 \\times 3 과 3 \\times 1\\)) 행벡터가 존재하는 차원인 3차원 벡터공간의 부분공간인 1차원 벡터공간을 생성함을 알 수 있다.\n영공간의 원소(방정식의 해)는 무수히 많음이 자명한데 왜냐하면 \\(Ax = 0\\)을 만족하는 임의의 x벡터에 대한 스칼라배에 대해 다음이 성립하기 때문이다.\n\\[\\begin{aligned}\n&Ax = {\\bf 0} \\\\\n&\\Longleftrightarrow cAx = c{\\bf 0} = {\\bf 0} \\\\\n&\\Longleftrightarrow A(cx) ={\\bf 0} \\\\\n\\end{aligned}\\]\n따라서 \\(x\\)의 스칼라배인 \\(cx\\)도 \\(A\\)와 곱해져서 \\({\\bf 0}\\) 만들기 \\(x\\)의 스칼라배도 영공간의 원소이다. \nrank-nulity theoreom도 성립함을 확인할 수 있다. 영공간의 차원은 영공간의 기저의 갯수인데 \\([1,-1,1]^T\\)이 기저의 조건인 1)선형생성 = 벡터공간 2)선형독립 이라는 두 조건을 만족하므로 차원은 1이다.랭크는 다른방식으로도 구할 수 있지만 행렬이 간단해서 바로2임을 확인할 수 있으므로 다음과 같다 \\[\\text{nulity}(A) + \\text{rank}(A)= n   \\Longleftrightarrow  1 + 2 = 3\\]"
  },
  {
    "objectID": "posts/Linear Algebra/rank and null space/rank and null space.html#예제2",
    "href": "posts/Linear Algebra/rank and null space/rank and null space.html#예제2",
    "title": "rank & null space(kernel)",
    "section": "예제2)",
    "text": "예제2)\n행렬 A = \\(\\begin{pmatrix}1&2&3 \\\\0&0&0\\end{pmatrix}\\)일 때, 행렬A의 영공간은?\n마찬가지로 만족하는 \\(x\\)를 먼저 찾아보자.\n\\[\\begin{aligned}\n&Ax = x_1\\begin{pmatrix}1\\\\0\\end{pmatrix} + x_2\\begin{pmatrix}2 \\\\ 0\\end{pmatrix} + x_3\\begin{pmatrix}3\\\\0\\end{pmatrix} = {\\bf 0} \\\\\n&\\Longleftrightarrow\nx_1 + 2x_2 + 3x_3 = 0 \\\\\n&\\Longleftrightarrow x_3 = t,x_2 = q,x_1 = -2q -3t \\\\\n&\\Longleftrightarrow x = \\begin{pmatrix}-2q-3t\\\\q\\\\t\\end{pmatrix} = q\\begin{pmatrix}-2\\\\1\\\\0\\end{pmatrix} + t\\begin{pmatrix}-3\\\\0\\\\1\\end{pmatrix} \\\\\n&\\therefore \\text{N}(A) = \\Bigg\\{q\\begin{pmatrix}-2\\\\1\\\\0 \\end{pmatrix} + t\\begin{pmatrix}-3\\\\0\\\\1\\end{pmatrix}|t,q \\in \\mathbb{R}\\Bigg\\}\n\\end{aligned}\\]\n방정식의 해를 구해보니 1)두 벡터의 span이 영공간이며 2)생성된 영공간은 행렬곱에 의해서(중간에서 차원일치 \\(2 \\times 3\\) 과 \\(3 \\times 1\\)) 행벡터가 존재하는 차원인 3차원 벡터공간안에서 부분공간인 1차원 벡터공간을 생성함을 알 수 있다.\n\\(Ax = 0\\)을 만족하는 2개의 x의 선형조합이 모두 영공간의 원소임을 확인해보자.\n\\[\\begin{aligned}\n&Ax_1 = {\\bf 0},Ax_2 = {\\bf 0} \\\\\n&\\Longleftrightarrow cAx_1 = c{\\bf 0}={\\bf 0},cAx_2 = c{\\bf 0}={\\bf 0} \\\\\n&\\Longleftrightarrow A(cx_1) + A(cx_2) = A(cx_1 + cx_2) = {\\bf 0} \\\\\n\\end{aligned}\\]\n따라서 \\(x\\) 방정식을 만족하는 두 벡터의 선형조합인 \\(c(x_1 + cx_2)\\)도 \\(A\\)와 곱해져서 영공간의 원소임을 알 수 있다. \n마찬가지로 rank-nulity theoreom도 성립함을 확인할 수 있다. 영공간의 차원은 영공간의 기저의 갯수이고 \\([-2,1,0]^T,[-3,0,1]^T\\)가 기저의 조건인 1)선형생성 = 벡터공간(여기서 영공간) 2)선형독립 이라는 두 조건을 만족하므로 영공간의 기저는 \\([-2,1,0]^T,[-3,0,1]^T\\)이고 차원은 2이다.랭크는 다른방식으로도 구할 수 있지만 행렬이 간단해서 바로1임을 확인할 수 있으므로 다음과 같다 \\[\\text{nulity}(A) + \\text{rank}(A)= n   \\Longleftrightarrow  2 + 1 = 3\\]"
  },
  {
    "objectID": "posts/Linear Algebra/span과 columns space.html",
    "href": "posts/Linear Algebra/span과 columns space.html",
    "title": "Linear Combination & Span",
    "section": "",
    "text": "유투브 - 혁펜하임님의 선형대수학강의를 정리하기 위해 작성한 글입니다.\n\nlinear Combination\n벡터 \\(\\bf{v_1,v_2,\\dots,v_n}\\)의 선형결합(또는 일차결합)은 다음과 같다. \\[w_1{\\bf v_1} + w_2{\\bf v_2} + \\dots + w_n{\\bf v_n}\\] 선형결합의 결과는 여러가지 벡터들의 결합이다. 여기서 각각의 \\(w_1,w_2,\\dots,w_n\\)은 스칼라이며 대응하는 \\(x_1,x_2,\\dots,x_n\\)를 결합에 사용하는 정도를 의미한다. 만약 \\(w_1 = 0.0001\\)이면 여러 벡터들을 결합하지만 그 결합 중 \\(\\bf v_1\\)이 아주 사용하여 결합하는 것이고 \\(w_2 = 120\\)이라면 결합에서 \\(\\bf v_2\\)를 아주 많이 사용하는 것이다.\n\n\nspan\n벡터 \\(v_1,v_2,\\dots,v_n\\)의 선형결합에서 \\(w_1,w_2,\\dots,w_n\\)(스칼라,결합에 사용하는 정도)를 바꿨을때 가능한 모든 벡터들의 집합이며 즉,벡터의 선형결합으로 가능한 모든 집합들이며 정의는 다음과 같다. \\[\\text{span}({\\bf{v_1,v_2,\\dots,v_n}}) := \\{w_1{\\bf{v_1}} + w_2{\\bf{v_2}} + \\dots + w_n{\\bf{v_n}}:w_1,w_2,\\dots,w_n \\in K\\}\\]  span은 선형결합으로 만들어지는 또다른 벡터공간이다. 여기서 K는 field를 의미하는데 스칼라는 field라는 또다른 집합으로부터 가져온 원소이기때문에 그렇다.임의의 벡터들의 span은 어떨까? 아래의 그림을 확인해보자.\n<참고> span은 동사로도 사용한다. ex : 벡터공간을 생성한다. 열공간은 열벡터들이 생성하는 공간이다.(=열공간은 열벡터의 생성이다.).기저들이 벡터공간을 생성한다.\n:는 조건을 의미합니다.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nplt.style.use(\"ggplot\")\n\ndef linrcmb(v1,v2):\n    linrcomb_x= []\n    linrcomb_y= []\n\n    _w = np.linspace(-50,50,300).tolist()\n    for i in range(2000):\n    #w1,w2를 -100~100사이의 임의의 숫자로\n        w1 = random.sample(_w,1)\n        w2 = random.sample(_w,1)\n        #print(w1,w2)\n    #선형결합 계산\n        linrcomb = w1 * v1 + w2 * v2\n    #시각화를 위해 선형결합의 x값 y값 따로 모아놓기\n        linrcomb_x.append(linrcomb[0][0])\n        linrcomb_y.append(linrcomb[1][0])\n    return linrcomb_x,linrcomb_y\n\nv1 = np.array([[0],[0]])\nv2 = np.array([[0],[0]])\nx,y = linrcmb(v1,v2)\nfig,ax = plt.subplots(figsize=(30,5))\nplt.subplot(1,5,1)\nplt.title(\"$v_1 = [0,0]^{T},v_2 = [0,0]^T$\")\nplt.scatter(x,y,color=\"black\")\n\nv1 = np.array([[1],[0]])\nv2 = np.array([[-3],[0]])\nx,y = linrcmb(v1,v2)\nplt.subplot(1,5,2)\nplt.title(\"$v_1 = [1,0]^{T},v_2 = [-3,0]^T$\")\nplt.scatter(x,y)\n\nv1 = np.array([[1],[1]])\nv2 = np.array([[0],[0]])\nx,y = linrcmb(v1,v2)\nplt.subplot(1,5,3)\nplt.title(\"$v_1 = [1,0]^{T},v_2 = [0,0]^T$\")\nplt.scatter(x,y,color=\"green\",alpha=1)\n\n\nv1 = np.array([[1],[0]])\nv2 = np.array([[0],[1]])\nx,y = linrcmb(v1,v2)\nplt.subplot(1,5,4)\nplt.title(\"$v_1 = [1,0]^{T},v_2 = [0,1]^T$\")\nplt.scatter(x,y,color=\"purple\",alpha=1)\n\ndef linrcmb2(v1,v2):\n    linrcomb_x= []\n    linrcomb_y= []\n\n    _w = (np.linspace(-250,250,300)).tolist()\n    for i in range(2000):\n        w1 = random.sample(_w,1)[0] * 100 #그래프를 그리기 위한 값 조절\n        w2 = random.sample(_w,1)[0] \n        #선형결합 계산\n        linrcomb = w1 * v1 + w2 * v2\n        #시각화를 위해 선형결합의 x값 y값 따로 모아놓기\n        linrcomb_x.append(linrcomb[0][0])\n        linrcomb_y.append(linrcomb[1][0])\n    \n    return linrcomb_x,linrcomb_y\nlinrcmb2(v1,v2)\n\nv1 = np.array([[-1],[0]])\nv2 = np.array([[2],[2]])\nx,y = linrcmb2(v1,v2)\nplt.subplot(1,5,5)\nplt.title(\"$v_1 = [1,0]^{T},v_2 = [2,2]^T$\")\nplt.scatter(x,y,color=\"blue\",alpha=1)\nplt.subplots_adjust(wspace=0.4,hspace=0.5)\nplt.suptitle(\"span$(v_1,v_2)$\",y=1.02,fontsize=20)\n\n\nText(0.5, 1.02, 'span$(v_1,v_2)$')\n\n\n\n\n\n점 하나는 벡터 하나를 나타낸다. 1번째 그림에서 벡터들의 생성(span)은 2차원 벡터공간의 부분공간이자 0차원 벡터공간(점)이며 2,3번째 그림에서 벡터들의 생성(span)은 2차원 벡터공간의 부분공간이자 1차원 벡터공간(직선)이다. 이와는 다르게 3번째 그림에서의 벡터들의 생성(span)은 3차원 벡터공간 그 자체인데 그 이유는 3차원 벡터공간의 모든 점을 표현할 수 있기 때문이다.\n\n\ncolumn Space\n열공간(columns space)은 행렬의 열벡터들의 span 즉, 행렬의 열벡터들로 가능한 모든 선형조합(벡터)의 집합입니다. \\(v_1,v_2,\\dots,v_n\\)이 행렬A의 열벡터들이라고 할 때, 열공간은 다음과 같습니다. \\[\\text{C}(A) = \\text{span}(v_1,v_2,\\dots,v_n) = \\{w_1{\\bf v_1} + w_2{\\bf v_2} + \\dots + w_n{\\bf v_n}:w_1,w_2,\\dots,w_n \\in K\\}\\] 열공간은 방정식 \\(Ax = b\\)의 해의 갯수를 파악하는데 쓰입니다.\n\n\n참고자료\n[선형대수] 벡터공간(vector space), 벡터 부분공간(vector subspace), 생성공간(span), 차원(dimension) 위키피디아-Linear span 위키피디아-Row and columns spaces 혁펜하임 - [선대] 2-6강. span 과 column space (열공간) 직관적 설명"
  },
  {
    "objectID": "posts/Linear Algebra/행렬곱에 대한 여러가지 시각.html",
    "href": "posts/Linear Algebra/행렬곱에 대한 여러가지 시각.html",
    "title": "행렬곱에 대한 여러가지 관점",
    "section": "",
    "text": "유튜브 - 혁펜하임님의 선형대수학 강의 정리용 입니다.\n\n행렬곱은 내적이다.\n\\[\\begin{aligned}\n&\\text{Let }A \\in \\mathbb{R}^{m \\times n},B \\in \\mathbb{R}^{n \\times p} \\\\\n&AB =\n\\begin{bmatrix}\na_1^T\\\\\na_2^T\\\\\n\\vdots\\\\\na_m^T\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1 & b_2 & \\dots & b_p\n\\end{bmatrix}=\n\\begin{bmatrix}\na_1^Tb_1 & a_1^Tb_2 & \\dots & a_1^Tb_p \\\\\na_2^Tb_1 & a_2^Tb_2 & \\dots & a_2^Tb_p \\\\\n\\vdots & \\vdots  & \\vdots & \\vdots \\\\\na_{m}^Tb_1 & a_m^Tb_2 & \\dots & a_m^Tb_p \\\\\n\\end{bmatrix}\n\\end{aligned}\\]\n\n\n행렬곱은 rank-1 matrix의 합이다.\n\\[\\begin{aligned}\n&\\text{Let }A \\in \\mathbb{R}^{m \\times n},B \\in \\mathbb{R}^{n \\times p} \\\\\n&AB =\n\\begin{bmatrix}\na_1 & a_2 & \\dots & a_n\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1^T \\\\\nb_2^T \\\\\n\\vdots \\\\\nb_n^T\n\\end{bmatrix}\n= a_1b_1^T + a_2b_2^T + \\dots + a_nb_n^T\n\\end{aligned}\\]\n\n\n행렬과 벡터의 곱은 열공간에 속한 임의의 벡터이다.\n\\[\\begin{aligned}\n&\\text{Let }A \\in \\mathbb{R}^{m \\times n},x \\in \\mathbb{R}^{n \\times 1} \\\\\n&Ax =\n\\begin{bmatrix}\na_1 & a_2 & \\dots & a_n\n\\end{bmatrix}\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n\n\\end{bmatrix}\n= a_1x_1 + a_2x_2 + \\dots + a_nx_n\n\\end{aligned}\\]\n\\(a_1,a_2,\\dots,a_n\\)은 벡터 \\(x_1,x_2,\\dots,x_n\\)은 스칼라이다. 행렬곱은 위와같이 열공간의 기저(행렬\\(A\\)의 열벡터)와 스칼라(미지수벡터\\(x\\)의 원소)와의 일차결합이므로 기저인 열벡터가 생성(span)하는 열공간의 원소이다. 이는 방정식 \\(Ax=b\\)의 해의 갯수를 알아내는데에 사용하는 중요한 개념이다.(참고 : 방정식 Ax = b의 해의 갯수 알아내기)\n열공간(column space) : 행렬에서 (열)벡터의 일차결합으로 생성되는 벡터공간. 열벡터의 span\n\n\n행벡터와 행렬의 곱은 row space(행공간)에 속한 임의의 벡터이다.\n\\[\\begin{aligned}\n&\\text{Let }x \\in \\mathbb{R}^{1 \\times n},X \\in \\mathbb{R}^{n \\times p} \\\\\n&xA =\n\\begin{bmatrix}\nx_1 & x_2 & \\dots & x_n\n\\end{bmatrix}\n\\begin{bmatrix}\na_1^T \\\\\na_2^T \\\\\n\\vdots \\\\\na_n\n\\end{bmatrix}\n= x_1a_1^T + x_2a_2^T + \\dots + x_na_n^T\n\\end{aligned}\\]\n\\(a_1^T,a_2^T,\\dots,a_n^T\\)은 벡터 \\(x_1,x_2,\\dots,x_n\\)은 스칼라이다. 행렬곱은 위와같이 행공간의 기저(행렬\\(A\\)의 행벡터)와 스칼라(\\(x\\)의 원소)와의 일차결합으로 기저인 행벡터가 생성하는 행공간의 원소이다.\n행공간 : 행렬에서 행벡터의 일차결합으로 생성되는 벡터공간. 행벡터의 span\n\n\n참고문헌\n혁펜하임 - 선대 2-5강. 행렬의 곱셈과 네 가지 관점 (열공간 (column space) 등)"
  },
  {
    "objectID": "posts/numpy/np.meshgrid.html",
    "href": "posts/numpy/np.meshgrid.html",
    "title": "np.meshgrid",
    "section": "",
    "text": "np.meshgrid"
  },
  {
    "objectID": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html",
    "href": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html",
    "title": "Finite Difference Method with np.gradient",
    "section": "",
    "text": "\\({\\bf x} =\\begin{bmatrix}x_1&x_2&\\dots&x_m\\end{bmatrix}^T\\)일 때, \\(x\\)에 대한 다변수함수 \\(f({\\bf x})\\)의 gradient는 다음과 같다.\n\\[\\begin{aligned}\n&\\text{gradient of }f({\\bf{x}}) = \\frac{\\partial f}{\\partial {\\bf x}} = \\nabla f(\\bf{x}) =\n\\begin{pmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial }{\\partial x_m}\n\\end{pmatrix}\n\\end{aligned}\\]\n함수가 가지는 모든 변수에 대해서 편미분 한 뒤 모아놓은 벡터라고 생각하면 된다. 함수의 수식을 알고 미분이 가능하면 우리는 해석적으로 미분해서(미분공식써서) 그레디언트를 구하고 각각의 어떤 point에서의 편미분계수들도 구할 수 있다. 그러나 우리가 주어진 데이터는 함수f의 함숫값들이 주어진다. 예를 들면 다음과 같다.\n\nimport numpy as np\nf = np.array([1,2,4,7,11,17],dtype = float)\nprint(\"f(x)\")\nprint(f)\n\nf(x)\n[ 1.  2.  4.  7. 11. 17.]\n\n\n위와 같은 함숫값들만 주어질때에는 원래의 함수를 알기는 불가능하다. 따라서 도함수를 통한 정확한 미분계수를 구하기가 불가능하므로 주어진 데이터로 \\(\\bf x\\)에서의 미분계수의 값을 근사적으로 구할 수 있는데 이를 수치미분이라 한다."
  },
  {
    "objectID": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#차원-배열의-경우",
    "href": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#차원-배열의-경우",
    "title": "Finite Difference Method with np.gradient",
    "section": "1차원 배열의 경우",
    "text": "1차원 배열의 경우\n\nEx) \\(dx\\) = 1\n넘파이 1차원 배열이 다음과 같이 주어져 있다고 하자.\n\nfrom IPython.display import display, Markdown\nf = np.array([1,2,4,7,11,16],dtype=float)\nprint(f)\n\n[ 1.  2.  4.  7. 11. 16.]\n\n\nnp.gradient함수는 1차원 배열의 내부에 있는 각각의 값들은 \\(x\\)값이 거리가 \\(dx\\)=1씩 변화할때마다의 함숫값\\(f(x)\\)들로 이해한다. 즉,다음과 같다.\n\nfor i in range(len(f)):\n    display(Markdown(rf'$x_{i+1}$에서의 함숫값 $f(x_{i+1})$ = {f[i]}'))\n\n\\(x_1\\)에서의 함숫값 \\(f(x_1)\\) = 1.0\n\n\n\\(x_2\\)에서의 함숫값 \\(f(x_2)\\) = 2.0\n\n\n\\(x_3\\)에서의 함숫값 \\(f(x_3)\\) = 4.0\n\n\n\\(x_4\\)에서의 함숫값 \\(f(x_4)\\) = 7.0\n\n\n\\(x_5\\)에서의 함숫값 \\(f(x_5)\\) = 11.0\n\n\n\\(x_6\\)에서의 함숫값 \\(f(x_6)\\) = 16.0\n\n\n위에서 넘파이의 그래디언트는 끝값을 제외한 내부의 요소에는 중앙차분근사 양끝값에 대해서는 후향차분 또는 전향차분을 사용한다고 언급했었다. 계산한,\\(x_2,x_5\\)에서 미분계수의 2차중앙차분근사는 다음과 같다.\n\\[\\begin{aligned}\n&f^{'}(x_2) \\overset{\\sim}{=} \\frac{f(x_3)-f(x_1)}{2h} = \\frac{4-1}{2} = 1.5 \\\\\n&f^{'}(x_5) \\overset{\\sim}{=} \\frac{f(x_6)-f(x_4)}{2h} = \\frac{16-7}{2} = 4.5 \\\\\n&\\text{where, } h = x_3-x_2 = x_2-x_1 = 1\n\\end{aligned}\\]\n1차원 배열의 가장 처음에 오는 값에 전향차분근사를 사용하고 가장 마지막에 오는 값에서는 후향차분근사를 사용한다.\n\\[\\begin{aligned}\n&f^{'}(x_1) = \\frac{f(x_2) - f(x_1)}{h} = \\frac{2-1}{1} = 1 \\\\\n&f^{'}(x_6) = \\frac{f(x_6) - f(x_5)}{h} = \\frac{16-11}{1} = 5\n\\end{aligned}\\]\n계산한 값과 실제로 일치하는지 확인.\n\nnum_diff = np.gradient(f)\nprint(\"np.gradient의 출력값\")\nprint(num_diff)\nfor i in range(len(num_diff)):\n    display(Markdown(rf'$x_{i+1}$에서의 도함수의 근삿값 $\\frac{{dy}}{{dx}}|_{{x = x_{i+1}}}$ ~= {num_diff[i]}'))\n\nnp.gradient의 출력값\n[1.  1.5 2.5 3.5 4.5 5. ]\n\n\n\\(x_1\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_1}\\) ~= 1.0\n\n\n\\(x_2\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_2}\\) ~= 1.5\n\n\n\\(x_3\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_3}\\) ~= 2.5\n\n\n\\(x_4\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_4}\\) ~= 3.5\n\n\n\\(x_5\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_5}\\) ~= 4.5\n\n\n\\(x_6\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_6}\\) ~= 5.0\n\n\n\n\nEx) \\(dx \\not = 1\\) (default가 아닐 경우)\n거리\\(dx=2\\)일때 계산한,\\(x_2,x_5\\)에서 미분계수의 2차중앙차분근사는 다음과 같다.\n\\[\\begin{aligned}\n&f^{'}(x_2) \\overset{\\sim}{=} \\frac{f(x_3)-f(x_1)}{2h} = \\frac{4-1}{4} = 0.75 \\\\\n&f^{'}(x_5) \\overset{\\sim}{=} \\frac{f(x_6)-f(x_4)}{2h} = \\frac{16-7}{4} = 2.25 \\\\\n&\\text{where, } h = x_3-x_1 = x_6-x_4 = 2\n\\end{aligned}\\]\n거리가 \\(dx=2\\)일때 배열의 양 끝값에서 전향,후향차분근사를 통한 미분계수의 값은 다음과 같다.\n\\[\\begin{aligned}\n&f^{'}(x_1) = \\frac{f(x_2) - f(x_1)}{h} = \\frac{2-1}{2} = 0.5 \\\\\n&f^{'}(x_6) = \\frac{f(x_6) - f(x_5)}{h} = \\frac{16-11}{2} = 2.5\n\\end{aligned}\\]\nx값 사이의 거리\\(dx\\)를 바꾸고 싶다면? => 두번째 인수에 스칼라 대입하면 된다.\n\ndx = 2\nnum_diff = np.gradient(f,dx)\nprint(\"np.gradient의 출력값\")\nprint(num_diff)\nfor i in range(len(num_diff)):\n    display(Markdown(rf'$x_{i+1}$에서의 도함수의 근삿값 $\\frac{{dy}}{{dx}}|_{{x = x_{i+1}}}$ ~= {num_diff[i]}'))\n\nnp.gradient의 출력값\n[0.5  0.75 1.25 1.75 2.25 2.5 ]\n\n\n\\(x_1\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_1}\\) ~= 0.5\n\n\n\\(x_2\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_2}\\) ~= 0.75\n\n\n\\(x_3\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_3}\\) ~= 1.25\n\n\n\\(x_4\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_4}\\) ~= 1.75\n\n\n\\(x_5\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_5}\\) ~= 2.25\n\n\n\\(x_6\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_6}\\) ~= 2.5\n\n\n\n\nEx) x값의 좌표를 직접 정해주는 경우\n이전에는 각각의 인덱스간의 거리는 모두 동일하게 기본값 1이거나 다른값을 사용했다. 그러지 않고 \\(x_1,x_2,\\dots,x_6\\)의 좌표를 직접 지정해주는 것도 가능하다. 함수의 2번재 인수에 좌표를 직접 넣어주면 된다.\n먼저 x값의 좌표를 다음과 같다고 해보자.\n\nx = np.array([0., 1., 1.5, 3.5, 4., 6.], dtype=float)\nf = np.array([1,2,4,7,11,16],dtype=float)\nprint(\"각각의 좌표와 함숫값\")\nfor i in range(len(x)):\n    display(Markdown(rf'$x_{i+1}$ = {x[i]}, $f(x_{i+1})$ = {f[i]}'))\n\n각각의 좌표와 함숫값\n\n\n\\(x_1\\) = 0.0, \\(f(x_1)\\) = 1.0\n\n\n\\(x_2\\) = 1.0, \\(f(x_2)\\) = 2.0\n\n\n\\(x_3\\) = 1.5, \\(f(x_3)\\) = 4.0\n\n\n\\(x_4\\) = 3.5, \\(f(x_4)\\) = 7.0\n\n\n\\(x_5\\) = 4.0, \\(f(x_5)\\) = 11.0\n\n\n\\(x_6\\) = 6.0, \\(f(x_6)\\) = 16.0\n\n\n각각의 좌표에서 도함수의 근삿값을 구하면 아래와 같다.(수식 계산은 잘 모르겠네요 … 추후에 더 공부하겠습니다!)\n\nnum_diff = np.gradient(f,x)\nprint(\"np.gradient의 출력값\")\nprint(num_diff)\nfor i in range(len(num_diff)):\n    display(Markdown(rf'$x_{i+1}$에서의 도함수의 근삿값 $\\frac{{dy}}{{dx}}|_{{x = x_{i+1}}}$ ~= {num_diff[i]}'))\n\nnp.gradient의 출력값\n[1.  3.  3.5 6.7 6.9 2.5]\n\n\n\\(x_1\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_1}\\) ~= 1.0\n\n\n\\(x_2\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_2}\\) ~= 2.9999999999999996\n\n\n\\(x_3\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_3}\\) ~= 3.5\n\n\n\\(x_4\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_4}\\) ~= 6.700000000000001\n\n\n\\(x_5\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_5}\\) ~= 6.899999999999999\n\n\n\\(x_6\\)에서의 도함수의 근삿값 \\(\\frac{dy}{dx}|_{x = x_6}\\) ~= 2.5"
  },
  {
    "objectID": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#차원-배열의-경우-1",
    "href": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#차원-배열의-경우-1",
    "title": "Finite Difference Method with np.gradient",
    "section": "2차원 배열의 경우",
    "text": "2차원 배열의 경우\n2차원 배열의 경우 axis=0(세로축)과 axis=1(가로축) 두 축방향으로 계산한 도함수의 근삿값을 반환한다.axis=0일 경우 각각의 열마다 따로따로 독립적으로 \\(x_1,x_2...\\)에 대한 함숫값\\(f(x_1),f(x_2),\\dots\\)이 있다고 생각하면 되고 axis=1일 경우 각각의 행마다 따로따로 독립적으로 \\(x_1,x_2...\\)에 대한 함숫값\\(f(x_1),f(x_2),\\dots\\)이 있다고 생각하면 된다.또한 1차원 배열과 유사하게 각각의 행,열의 끝값에는 전향or후향차분근사를 행,열의 내부에 있는 값은 중앙차분근사를 사용한다.\n\nEx) \\(dx=1,dy=1\\)\n2차원 배열은 다음과 같다.\n\nnp.array([[1, 2, 6], [3, 4, 5]], dtype=float)\n\narray([[1., 2., 6.],\n       [3., 4., 5.]])\n\n\n\nax0_difcoef,ax1_difcoef= np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float))\nprint(f'axis = 0 방향으로 도함수의 근삿값 계산 \\n{ax0_difcoef}')\nprint(f'axis = 1 방향으로 도함수의 근삿값 계산 \\n{ax1_difcoef}')\n\naxis = 0 방향으로 도함수의 근삿값 계산 \n[[ 2.  2. -1.]\n [ 2.  2. -1.]]\naxis = 1 방향으로 도함수의 근삿값 계산 \n[[1.  2.5 4. ]\n [1.  1.  1. ]]\n\n\n\n\nEx) \\(dx \\not = 1,dy \\not = 1\\) (default가 아닌 경우)\n각각의 행,열마다 거리를 따로 설정해주고 싶은 경우? => 스칼라 2개 인수로 전달.\n\ndx = 2;dy = 2\nax0_difcoef,ax1_difcoef= np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float),dx,dy)\nprint(f'axis = 0 방향으로 도함수의 근삿값 계산 \\n{ax0_difcoef}')\nprint(f'axis = 1 방향으로 도함수의 근삿값 계산 \\n{ax1_difcoef}')\n\naxis = 0 방향으로 도함수의 근삿값 계산 \n[[ 1.   1.  -0.5]\n [ 1.   1.  -0.5]]\naxis = 1 방향으로 도함수의 근삿값 계산 \n[[0.5  1.25 2.  ]\n [0.5  0.5  0.5 ]]"
  },
  {
    "objectID": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#전향차분근사-유도",
    "href": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#전향차분근사-유도",
    "title": "Finite Difference Method with np.gradient",
    "section": "전향차분근사 유도",
    "text": "전향차분근사 유도\n\\(x_1,x_2,\\dots,x_{i-1},x_i,x_{i+1},\\dots,x_n\\)과 각각에 대응하는 함숫값 \\(f(x_1),f(x_2),\\dots,f(x_{i-1}),f(x_i),f(x_{i+1}),\\dots,f(x_n)\\) 주어진 데이터라고 가정하자. 목적은 x_i에서의 미분계수를 구하는 것이다. \\(a = x_i\\)에서 함수\\(f(x)\\)의 테일러 급수 근사는 다음과 같다. \\[f(x) = \\sum_{n=0}^{\\infty}\\frac{f^{n}(x_i)}{n!}(x-x_i)^n = f(x_i) + \\frac{f^{'}(x_i)}{1!}(x-x_i) + \\frac{f^{''}(x_i)}{2!}(x-x_i)^2 + \\dots \\]\n\\(x=x_{i+1}\\)에서의 함숫값은 다음과 같다. \\[f(x_{i+1}) = \\sum_{n=0}^{\\infty}\\frac{f^{n}(x_i)}{n!}(x_{i+1}-x_i)^n = f(x_i) + \\frac{f^{'}(x_i)}{1!}(x_{i+1}-x_i) + \\frac{f^{''}(x_i)}{2!}(x_{i+1}-x_i)^2 + \\dots \\]\n\\(f'(x_i)\\)가 포함된항만 남겨두고 나머지는 이항하면 다음과 같다. \\[f^{'}(x_i)(x_{i+1}-x_i) = f(x_{i+1}) - f(x_i) - \\frac{f^{''}(x_i)}{2!}(x_{i+1}-x_i)^2 + \\dots\\]\n\\(h = x_{i+1}-x_i\\)로 두고 양변을 h로 나누면 다음과 같다. \\[f'(x_i) = \\frac{f(x_{i+1})}{h} - \\frac{f(x_i)}{h} - \\frac{hf^{''}(x_i)}{2!} - \\frac{h^2f^{'''}(x_i)}{3!}\\]\n여기서 우변의 두개의 항만 남겨두고 \\(O(h) = - \\frac{hf^{''}(x_i)}{2!} - \\frac{h^2f^{'''}(x_i)}{3!} - \\dots\\)라 하면 다음과 같다. \\[\\begin{align}\n&f'(x_i) \\overset{\\sim}{=} \\frac{f(x_{i+1})-f(x_i)}{h}\\\\\n&O(h) = - \\frac{hf^{''}(x_i)}{2!} - \\frac{h^2f^{'''}(x_i)}{3!} - \\dots\\\\\n&\\text{where, } h = x_{i+1} - x_i \\nonumber\n\\end{align}\\]"
  },
  {
    "objectID": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#후향차분근사-유도",
    "href": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#후향차분근사-유도",
    "title": "Finite Difference Method with np.gradient",
    "section": "후향차분근사 유도",
    "text": "후향차분근사 유도\n\\(x_1,x_2,\\dots,x_{i-1},x_i,x_{i+1},\\dots,x_n\\)과 각각에 대응하는 함숫값 \\(f(x_1),f(x_2),\\dots,f(x_{i-1}),f(x_i),f(x_{i+1}),\\dots,f(x_n)\\) 주어진 데이터라고 가정하자. 목적은 x_i에서의 미분계수를 구하는 것이다. \\(a = x_i\\)에서 함수\\(f(x)\\)의 테일러 급수 근사는 다음과 같다. \\[f(x) = \\sum_{n=0}^{\\infty}\\frac{f^{n}(x_i)}{n!}(x-x_i)^n = f(x_i) + \\frac{f^{'}(x_i)}{1!}(x-x_i) + \\frac{f^{''}(x_i)}{2!}(x-x_i)^2 + \\dots \\]\n\\(f(x_i)\\)는 다음과 같다. \\[f(x_{i-1}) = \\sum_{n=0}^{\\infty}\\frac{f^n(x_i)}{n!}(x_{i-1}-x_i)^n = f(x_i) + \\frac{f^{'}(x_i)}{1!}(x_{i-1}-x_i) + \\frac{f^{''}(x_i)}{2!}(x_{i-1}-x_i)^2+\\dots \\]\n1차미분이 포함된 항만 남기고 나머지는 이항하면 다음과 같다. \\[f^{'}(x_i)(x_{i-1}-x_i) = f(x_{i-1}) - f(x_i) - \\frac{f^{''}(x_i)}{2!}(x_{i-1}-x_i)^2-\\frac{f^{'''}(x_i)}{3!}(x_{i-1}-x_i)^3-\\dots \\]\n\\(h = x_{i} - x_{i-1}\\)로 놓으면 다음과 같다. \\[f^{'}(x_i)(-h) = f(x_{i-1}) - f(x_i) - \\frac{f^{''}(x_i)}{2!}h^2+\\frac{f^{'''}(x_i)}{3!}h^3-\\dots \\]\n양변을 \\(-h\\)로 나누면 다음과 같다.\n\\[\\begin{aligned}\nf^{'}(x_i) &= \\frac{f(x_{i-1})}{-h} + \\frac{f(x_i)}{h} + \\frac{f^{''}(x_i)}{2!}h-\\frac{f^{'''}(x_i)}{3!}h^2+\\dots \\\\\n&=\\frac{f(x_i)-f(x_{i-1}) }{h} +  \\frac{f^{''}(x_i)}{2!}h-\\frac{f^{'''}(x_i)}{3!}h^2+\\dots\n\\end{aligned}\\]\n마찬가지로 우변의 두개 항만 남겨두고 \\(O(h) = \\frac{hf^{''}(x_i)}{2!} - \\frac{h^2f^{'''}(x_i)}{3!} + \\dots\\)라 하면 다음과 같다. \\[\\begin{align}\n&f'(x_i) \\overset{\\sim}{=} \\frac{f(x_{i})-f(x_{i-1})}{h}\\\\\n&O(h) = \\frac{h}{2!}f^{''}(x_i) - \\frac{h^2}{3!}f{'''}(x_i)+\\dots \\\\\n&\\text{where, } h = x_{i} - x_{i-1}, \\nonumber\n\\end{align}\\]"
  },
  {
    "objectID": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#중앙차분근사-유도",
    "href": "posts/numpy/수치미분 & np.gradient/수치미분 & np.gradient.html#중앙차분근사-유도",
    "title": "Finite Difference Method with np.gradient",
    "section": "중앙차분근사 유도",
    "text": "중앙차분근사 유도\n전향차분근사와 후향차분근사의 유도과정에서의 테일러 전개식은 다음과 같다. \\[f'(x_i) = \\frac{f(x_{i+1})}{h} - \\frac{f(x_i)}{h} - \\frac{hf^{''}(x_i)}{2!} - \\frac{h^2f^{'''}(x_i)}{3!} - ...\\] \\[f'(x_i) = \\frac{f(x_{i})}{h} - \\frac{f(x_{i-1})}{h} + \\frac{hf^{''}(x_i)}{2!} - \\frac{h^2f^{'''}(x_i)}{3!} + ...\\]\n두 식을 더해주면 다음과 같다.\n\\[\\begin{aligned}\n&2f^{'}(x_i) = \\frac{f(x_{i+1})-f(x_{i-1})}{h} - \\frac{2h^2f^{'''}(x_i)}{3!} \\\\\n&\\Leftrightarrow f^{'}(x_i) = \\frac{f(x_{i+1})-f(x_{i-1})}{2h} - \\frac{h^2f^{'''}(x_i)}{3!} - ...\n\\end{aligned}\\]\n마찬가지로 우변의 두개 항만 남겨두고 절단오차\\(O(h^2) = -\\frac{h^2f^{'''}(x_i)}{3!} - \\dots\\)라 하면 다음과 같다. \\[\\begin{align}\n&f'(x_i) \\overset{\\sim}{=} \\frac{f(x_{i+1})-f(x_{i-1})}{2h}\\\\\n&O(h) = - \\frac{h^2}{3!}f{'''}(x_i)+\\dots \\\\\n&\\text{where, } h = x_{i} - x_{i-1}\\,\\,\\text{or}\\,\\, h = x_{i+1} - x_i\\nonumber\n\\end{align}\\]"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html",
    "href": "posts/open/Dakon competetion chisquare test.html",
    "title": "Untitled",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nimport os\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy.stats import chisquare\nimport warnings\nwarnings.filterwarnings('ignore')\ntest_path = \"C:/Users/22668/Desktop/github/sin-hoyeon/open/test.csv\"\ntrain_path = \"C:/Users/22668/Desktop/github/sin-hoyeon/open/train.csv\"\n\n\nclass CFG:\n    SEED = 42\n\n\ntrain = pd.read_csv(train_path)\ntrain_len = len(train)\ntest = pd.read_csv(test_path)\nid_test = test[\"id\"]\ntest = pd.read_csv(test_path)\n\n\ndataset = pd.concat([train,test],axis=0).reset_index(drop=True)\n\n\ndataset\n\n\n\n\n\n  \n    \n      \n      id\n      father\n      mother\n      gender\n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      ...\n      SNP_07\n      SNP_08\n      SNP_09\n      SNP_10\n      SNP_11\n      SNP_12\n      SNP_13\n      SNP_14\n      SNP_15\n      class\n    \n  \n  \n    \n      0\n      TRAIN_000\n      0\n      0\n      0\n      2\n      G G\n      A G\n      A A\n      G A\n      C A\n      ...\n      A A\n      G G\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      1\n      TRAIN_001\n      0\n      0\n      0\n      2\n      A G\n      A G\n      C A\n      A A\n      A A\n      ...\n      A A\n      G A\n      A A\n      A G\n      A A\n      G A\n      G G\n      A A\n      A A\n      C\n    \n    \n      2\n      TRAIN_002\n      0\n      0\n      0\n      2\n      G G\n      G G\n      A A\n      G A\n      C C\n      ...\n      A A\n      G A\n      G A\n      A G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      3\n      TRAIN_003\n      0\n      0\n      0\n      1\n      A A\n      G G\n      A A\n      G A\n      A A\n      ...\n      G G\n      A A\n      G G\n      A G\n      G G\n      G G\n      G G\n      A A\n      G G\n      A\n    \n    \n      4\n      TRAIN_004\n      0\n      0\n      0\n      2\n      G G\n      G G\n      C C\n      A A\n      C C\n      ...\n      A A\n      A A\n      A A\n      G G\n      A A\n      A A\n      A G\n      A A\n      G A\n      C\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      432\n      TEST_170\n      0\n      0\n      0\n      2\n      A G\n      G G\n      C C\n      A A\n      C A\n      ...\n      A A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      G A\n      NaN\n    \n    \n      433\n      TEST_171\n      0\n      0\n      0\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      ...\n      A A\n      A A\n      A A\n      A G\n      A A\n      A A\n      A G\n      A A\n      G A\n      NaN\n    \n    \n      434\n      TEST_172\n      0\n      0\n      0\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      ...\n      A A\n      A A\n      A A\n      G G\n      A G\n      A A\n      A G\n      A A\n      G G\n      NaN\n    \n    \n      435\n      TEST_173\n      0\n      0\n      0\n      2\n      A G\n      G G\n      C A\n      G A\n      C C\n      ...\n      A A\n      G A\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n    \n      436\n      TEST_174\n      0\n      0\n      0\n      2\n      G G\n      G G\n      C C\n      G A\n      C A\n      ...\n      G A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n  \n\n437 rows × 21 columns"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#fathermothergender",
    "href": "posts/open/Dakon competetion chisquare test.html#fathermothergender",
    "title": "Untitled",
    "section": "father,mother,gender",
    "text": "father,mother,gender\n\nfather,mother,gender = 0 => drop\n\n\ndataset = dataset.drop(columns = [\"father\",\"mother\",\"gender\"])\n\n\ndataset\n\n\n\n\n\n  \n    \n      \n      id\n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      SNP_06\n      SNP_07\n      SNP_08\n      SNP_09\n      SNP_10\n      SNP_11\n      SNP_12\n      SNP_13\n      SNP_14\n      SNP_15\n      class\n    \n  \n  \n    \n      0\n      TRAIN_000\n      2\n      G G\n      A G\n      A A\n      G A\n      C A\n      A A\n      A A\n      G G\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      1\n      TRAIN_001\n      2\n      A G\n      A G\n      C A\n      A A\n      A A\n      A G\n      A A\n      G A\n      A A\n      A G\n      A A\n      G A\n      G G\n      A A\n      A A\n      C\n    \n    \n      2\n      TRAIN_002\n      2\n      G G\n      G G\n      A A\n      G A\n      C C\n      G G\n      A A\n      G A\n      G A\n      A G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      3\n      TRAIN_003\n      1\n      A A\n      G G\n      A A\n      G A\n      A A\n      G G\n      G G\n      A A\n      G G\n      A G\n      G G\n      G G\n      G G\n      A A\n      G G\n      A\n    \n    \n      4\n      TRAIN_004\n      2\n      G G\n      G G\n      C C\n      A A\n      C C\n      A A\n      A A\n      A A\n      A A\n      G G\n      A A\n      A A\n      A G\n      A A\n      G A\n      C\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      432\n      TEST_170\n      2\n      A G\n      G G\n      C C\n      A A\n      C A\n      A G\n      A A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      G A\n      NaN\n    \n    \n      433\n      TEST_171\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      A G\n      A A\n      A A\n      A G\n      A A\n      G A\n      NaN\n    \n    \n      434\n      TEST_172\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      G G\n      A G\n      A A\n      A G\n      A A\n      G G\n      NaN\n    \n    \n      435\n      TEST_173\n      2\n      A G\n      G G\n      C A\n      G A\n      C C\n      G G\n      A A\n      G A\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n    \n      436\n      TEST_174\n      2\n      G G\n      G G\n      C C\n      G A\n      C A\n      A A\n      G A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n  \n\n437 rows × 18 columns"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_01",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_01",
    "title": "Untitled",
    "section": "SNP_01",
    "text": "SNP_01\n\nclass = B 인 경우, AA는 아예 없음 = > feature extraction hasGG 추가\n\n추후 고려사항 - class = A 인 경우, AA가 좀 높음 - class = B 인 경우, GG가 압도적으로 높음 - class = C 인 경우, GG가 좀 높음\n\ncol = \"SNP_01\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_02",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_02",
    "title": "Untitled",
    "section": "SNP_02",
    "text": "SNP_02\n\nclass = A인 경우, AA는 없음 => f.e has02AA\n\n추후 고려 - B,의 경우 AG->GG-AA 순 - C,의 경우 AG->GG->AA 순\n\ncol = \"SNP_02\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_03",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_03",
    "title": "Untitled",
    "section": "SNP_03",
    "text": "SNP_03\n\nA인 경우 , 무조건 AA만 존재 => feature extraction\n\n추후 고려 나머지는 뭐 대충 고르게\n\ncol = \"SNP_03\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    plt.ylim(20,60)\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_04",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_04",
    "title": "Untitled",
    "section": "SNP_04",
    "text": "SNP_04\n\nC인 경우 , GG는 없음 => feature extraction has04GG\n\n추후 고려 나머지는 뭐 대충 고르게 - class A인 경우,AA가 압도적으로 낮음 => feature extraction\n\ncol = \"SNP_04\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_05",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_05",
    "title": "Untitled",
    "section": "SNP_05",
    "text": "SNP_05\n\nclass = A인 경우, CC는 없음\n\n\ncol = \"SNP_05\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_06",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_06",
    "title": "Untitled",
    "section": "SNP_06",
    "text": "SNP_06\n\nclass = A인 경우, AA는 없음 => feature extraction has06AA\n\n\ncol = \"SNP_06\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_07",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_07",
    "title": "Untitled",
    "section": "SNP_07",
    "text": "SNP_07\n\nA의 경우 => AA는 없음 =>f.e has07AA\nB,C의 경우 => GG는 없음=>f.e has07GG\n\n\ncol = \"SNP_07\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_08",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_08",
    "title": "Untitled",
    "section": "SNP_08",
    "text": "SNP_08\n\nA의 경우 => GG는 없음 =>f.e has08GG\n\n\ncol = \"SNP_08\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_09",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_09",
    "title": "Untitled",
    "section": "SNP_09",
    "text": "SNP_09\n\nC의 경우 => 대부분이 AA이고 GA와 GG는 사실 없다고 봐도 무방=> f.e has09AA\nB의 경우 => GG는 거의 없음 => f.e has09GG\n\n앞선 경우들은 빈도수가 낮은 경우네는 따로 feature extraction을 안해줬는데 왜 여기서는 해? => 여기서는 낮은 것들의 빈도수가 1로 너무 낮음,그래서 여기는 함.\n\ncol = \"SNP_09\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\ndataset.loc[dataset[\"class\"] == \"B\",col].value_counts()\n\nA A    91\nG A    22\nG G     1\nName: SNP_09, dtype: int64\n\n\n\ndataset.loc[dataset[\"class\"] == \"C\",col].value_counts()\n\nA A    78\nG A     1\nName: SNP_09, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_10",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_10",
    "title": "Untitled",
    "section": "SNP_10",
    "text": "SNP_10\n\nA와 B에서 낮은값들이 있긴 한데 … 그래도 특이점 1인 정도는 아님\n\n\ncol = \"SNP_10\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\nx=dataset.loc[dataset[\"class\"] == \"B\",col]\nx.value_counts()\n\nG G    110\nA G      4\nName: SNP_10, dtype: int64\n\n\n\nx=dataset.loc[dataset[\"class\"] == \"A\",col]\nx.value_counts()\n\nA G    34\nA A    32\nG G     3\nName: SNP_10, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_11",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_11",
    "title": "Untitled",
    "section": "SNP_11",
    "text": "SNP_11\n\nA의 경우 => AA는 없음 =>f.e has11AA\n\n\ncol = \"SNP_11\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_12",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_12",
    "title": "Untitled",
    "section": "SNP_12",
    "text": "SNP_12\n\nA의 경우 => AA가 있는 관측치가 거의 없음,GG가 있는 관측치는 많음\nB,C의 경우 => GG가 있는 관측치가 거의 없음,AA가 있는 관측치는 많음\n\n=>f.e has12AA =>f.e has12GG\n\ncol = \"SNP_12\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\ndataset.loc[dataset[\"class\"] == \"A\",col].value_counts()\n\nG G    48\nG A    20\nA A     1\nName: SNP_12, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_13",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_13",
    "title": "Untitled",
    "section": "SNP_13",
    "text": "SNP_13\n\nA의 경우 => AA는 없음 => f.e has13AA\n\n\ncol = \"SNP_13\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\nx=dataset.loc[dataset[\"class\"] == \"A\",col]\nx.value_counts()\n\nG G    66\nA G     3\nName: SNP_13, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_14",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_14",
    "title": "Untitled",
    "section": "SNP_14",
    "text": "SNP_14\n\nB의 경우 => AA만 존재 =>f.e has14AA 를 추가해서 AA인것들의 계수를 결정하도록\nC의 경우 CC가 있긴 한데 .. 엄청낮긴함(그래도 1은 아니니까 f.e는 안함)\n\n\ncol = \"SNP_14\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\nx=dataset.loc[dataset[\"class\"] == \"C\",col]\nx.value_counts()\n\nA A    60\nC A    17\nC C     2\nName: SNP_14, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#snp_15",
    "href": "posts/open/Dakon competetion chisquare test.html#snp_15",
    "title": "Untitled",
    "section": "SNP_15",
    "text": "SNP_15\n\n별다른 특징 없음\n\n\ncol = \"SNP_15\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\ndataset\n\n\n\n\n\n  \n    \n      \n      id\n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      SNP_06\n      SNP_07\n      SNP_08\n      SNP_09\n      SNP_10\n      SNP_11\n      SNP_12\n      SNP_13\n      SNP_14\n      SNP_15\n      class\n    \n  \n  \n    \n      0\n      TRAIN_000\n      2\n      G G\n      A G\n      A A\n      G A\n      C A\n      A A\n      A A\n      G G\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      1\n      TRAIN_001\n      2\n      A G\n      A G\n      C A\n      A A\n      A A\n      A G\n      A A\n      G A\n      A A\n      A G\n      A A\n      G A\n      G G\n      A A\n      A A\n      C\n    \n    \n      2\n      TRAIN_002\n      2\n      G G\n      G G\n      A A\n      G A\n      C C\n      G G\n      A A\n      G A\n      G A\n      A G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      3\n      TRAIN_003\n      1\n      A A\n      G G\n      A A\n      G A\n      A A\n      G G\n      G G\n      A A\n      G G\n      A G\n      G G\n      G G\n      G G\n      A A\n      G G\n      A\n    \n    \n      4\n      TRAIN_004\n      2\n      G G\n      G G\n      C C\n      A A\n      C C\n      A A\n      A A\n      A A\n      A A\n      G G\n      A A\n      A A\n      A G\n      A A\n      G A\n      C\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      432\n      TEST_170\n      2\n      A G\n      G G\n      C C\n      A A\n      C A\n      A G\n      A A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      G A\n      NaN\n    \n    \n      433\n      TEST_171\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      A G\n      A A\n      A A\n      A G\n      A A\n      G A\n      NaN\n    \n    \n      434\n      TEST_172\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      G G\n      A G\n      A A\n      A G\n      A A\n      G G\n      NaN\n    \n    \n      435\n      TEST_173\n      2\n      A G\n      G G\n      C A\n      G A\n      C C\n      G G\n      A A\n      G A\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n    \n      436\n      TEST_174\n      2\n      G G\n      G G\n      C C\n      G A\n      C A\n      A A\n      G A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n  \n\n437 rows × 18 columns"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#class별-관측치의-숫자",
    "href": "posts/open/Dakon competetion chisquare test.html#class별-관측치의-숫자",
    "title": "Untitled",
    "section": "class별 관측치의 숫자",
    "text": "class별 관측치의 숫자\n\nclass imbalance? => No\n\n\nx = dataset[\"class\"].value_counts().index\ny = dataset[\"class\"].value_counts().values\nplt.bar(x,y)\n\n<BarContainer object of 3 artists>"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#chi2-test-between-abc",
    "href": "posts/open/Dakon competetion chisquare test.html#chi2-test-between-abc",
    "title": "Untitled",
    "section": "chi^2 test, between [“A”,“B”,“C”]",
    "text": "chi^2 test, between [“A”,“B”,“C”]\n\n목적 : 각각의 클래스에서 각각의 SNP변수에서 나오는 G G or A g 등등.. 의 값의 빈도수가 같은지 아니면 다른지 카이제곱검정을 통해서 파악한 후, 클래스별로 빈도수 차이있으면 그 행만 추가\n\n\n\"\"\"\n#1 각각의 독립변수(검정에서는 class)별로 SNP_01의 특정값(예를 들면 GG)가 나오는 관측치 세어보기\n\n#컬럼,클래스 지정\nsnp_name = [col_name for col_name in dataset.columns if \"SNP\" in col_name]\nclass_name = [\"A\",\"B\",\"C\"]\n\nsignif_col = []\nunsignif_col = []\nfor snp in snp_name:\n    _snp_unique = dataset.loc[:,snp].unique().tolist()\n    for unq_vl in _snp_unique:\n        _condition = (dataset.loc[:,snp] == unq_vl)\n        _data = dataset.loc[_condition,[snp,\"class\"]].dropna(axis=0).value_counts().droplevel(axis=0,level=0).copy()\n        _data_class = _data.index\n        for cl_name in class_name:\n            if cl_name not in _data_class:\n                #print(\"존재하지 않는 class : \",cl_name)\n                #print(\"존재하지 않는 클래스 추가후 df\")\n                _data = _data.append(pd.Series({cl_name:0}))\n\n        _data = _data[class_name]\n        #특정컬럼의 특정값에 대해서 카이제곱검정 수행\n        #예를 들어서 각각의 클래스 A,B,C에서 SNP_01의 A A값을 가지는 빈도가 같은지 다른지 수행\n        f_obs = _data.values.tolist()\n        p_value = chisquare(f_obs)[1].round(5)\n        if p_value < 0.01: #유의확률 0.01\n            #print(f\"{snp}={unq_vl}\")\n            #print(\"p_value :\",p_value)\n            name = snp+\"=\"+unq_vl\n            signif_col.append(name)\n        else:\n            name = snp+\"=\"+unq_vl\n            unsignif_col.append(name)\nlen(signif_col),len(unsignif_col)\n\"\"\"\n\n'\\n#1 각각의 독립변수(검정에서는 class)별로 SNP_01의 특정값(예를 들면 GG)가 나오는 관측치 세어보기\\n\\n#컬럼,클래스 지정\\nsnp_name = [col_name for col_name in dataset.columns if \"SNP\" in col_name]\\nclass_name = [\"A\",\"B\",\"C\"]\\n\\nsignif_col = []\\nunsignif_col = []\\nfor snp in snp_name:\\n    _snp_unique = dataset.loc[:,snp].unique().tolist()\\n    for unq_vl in _snp_unique:\\n        _condition = (dataset.loc[:,snp] == unq_vl)\\n        _data = dataset.loc[_condition,[snp,\"class\"]].dropna(axis=0).value_counts().droplevel(axis=0,level=0).copy()\\n        _data_class = _data.index\\n        for cl_name in class_name:\\n            if cl_name not in _data_class:\\n                #print(\"존재하지 않는 class : \",cl_name)\\n                #print(\"존재하지 않는 클래스 추가후 df\")\\n                _data = _data.append(pd.Series({cl_name:0}))\\n\\n        _data = _data[class_name]\\n        #특정컬럼의 특정값에 대해서 카이제곱검정 수행\\n        #예를 들어서 각각의 클래스 A,B,C에서 SNP_01의 A A값을 가지는 빈도가 같은지 다른지 수행\\n        f_obs = _data.values.tolist()\\n        p_value = chisquare(f_obs)[1].round(5)\\n        if p_value < 0.01: #유의확률 0.01\\n            #print(f\"{snp}={unq_vl}\")\\n            #print(\"p_value :\",p_value)\\n            name = snp+\"=\"+unq_vl\\n            signif_col.append(name)\\n        else:\\n            name = snp+\"=\"+unq_vl\\n            unsignif_col.append(name)\\nlen(signif_col),len(unsignif_col)\\n'"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#chi2-test-between-bc",
    "href": "posts/open/Dakon competetion chisquare test.html#chi2-test-between-bc",
    "title": "Untitled",
    "section": "chi^2 test, between “B”,“C”",
    "text": "chi^2 test, between “B”,“C”\n\n목적 : 각각의 클래스에서 각각의 SNP변수에서 나오는 G G or A g 등등.. 의 값의 빈도수가 같은지 아니면 다른지 카이제곱검정을 통해서 파악한 후, 클래스별로 빈도수 차이있으면 그 행만 추가\n\n\n# EDA과정에서 trait == 1 이면 반드시 A였음,따라서 trait 변수는 제거하고 나중에 trait == 1이면 반드시 1로 제출\nidx = dataset[dataset.trait == 1].index\n_dt = dataset.drop(index=idx)\n\n\n_dt\n\n\n\n\n\n  \n    \n      \n      id\n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      SNP_06\n      SNP_07\n      SNP_08\n      SNP_09\n      SNP_10\n      SNP_11\n      SNP_12\n      SNP_13\n      SNP_14\n      SNP_15\n      class\n    \n  \n  \n    \n      0\n      TRAIN_000\n      2\n      G G\n      A G\n      A A\n      G A\n      C A\n      A A\n      A A\n      G G\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      1\n      TRAIN_001\n      2\n      A G\n      A G\n      C A\n      A A\n      A A\n      A G\n      A A\n      G A\n      A A\n      A G\n      A A\n      G A\n      G G\n      A A\n      A A\n      C\n    \n    \n      2\n      TRAIN_002\n      2\n      G G\n      G G\n      A A\n      G A\n      C C\n      G G\n      A A\n      G A\n      G A\n      A G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      4\n      TRAIN_004\n      2\n      G G\n      G G\n      C C\n      A A\n      C C\n      A A\n      A A\n      A A\n      A A\n      G G\n      A A\n      A A\n      A G\n      A A\n      G A\n      C\n    \n    \n      5\n      TRAIN_005\n      2\n      G G\n      G G\n      C A\n      A A\n      C C\n      A A\n      A A\n      G A\n      A A\n      G G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      432\n      TEST_170\n      2\n      A G\n      G G\n      C C\n      A A\n      C A\n      A G\n      A A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      G A\n      NaN\n    \n    \n      433\n      TEST_171\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      A G\n      A A\n      A A\n      A G\n      A A\n      G A\n      NaN\n    \n    \n      434\n      TEST_172\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      G G\n      A G\n      A A\n      A G\n      A A\n      G G\n      NaN\n    \n    \n      435\n      TEST_173\n      2\n      A G\n      G G\n      C A\n      G A\n      C C\n      G G\n      A A\n      G A\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n    \n      436\n      TEST_174\n      2\n      G G\n      G G\n      C C\n      G A\n      C A\n      A A\n      G A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n  \n\n317 rows × 18 columns\n\n\n\n\n#1 각각의 독립변수(검정에서는 class)별로 SNP_01의 특정값(예를 들면 GG)가 나오는 관측치 세어보기\n\n#컬럼,클래스 지정\nsnp_name = [col_name for col_name in _dt.columns if \"SNP\" in col_name]\nclass_name = [\"B\",\"C\"]\n\nsignif_col = []\nunsignif_col = []\nfor snp in snp_name:\n    _snp_unique = _dt.loc[:,snp].unique().tolist()\n    for unq_vl in _snp_unique:\n        _condition = (_dt.loc[:,snp] == unq_vl)\n        _data = _dt.loc[_condition,[snp,\"class\"]].dropna(axis=0).value_counts().droplevel(axis=0,level=0).copy()\n        _data_class = _data.index\n        for cl_name in class_name:\n            if cl_name not in _data_class:\n                #print(\"존재하지 않는 class : \",cl_name)\n                #print(\"존재하지 않는 클래스 추가후 df\")\n                _data = _data.append(pd.Series({cl_name:0}))\n\n        _data = _data[class_name]\n        #특정컬럼의 특정값에 대해서 카이제곱검정 수행\n        #예를 들어서 각각의 클래스 A,B,C에서 SNP_01의 A A값을 가지는 빈도가 같은지 다른지 수행\n        f_obs = _data.values.tolist()\n        p_value = chisquare(f_obs)[1].round(5)\n        if p_value < 0.05: #유의확률 0.01\n            #print(f\"{snp}={unq_vl}\")\n            #print(\"p_value :\",p_value)\n            name = snp+\"_\"+unq_vl\n            signif_col.append(name)\n        else:\n            name = snp+\"_\"+unq_vl\n            unsignif_col.append(name)\nlen(signif_col),len(unsignif_col)\n\n(27, 17)\n\n\n\nsignif_col\n\n['SNP_01_G G',\n 'SNP_01_A A',\n 'SNP_02_A G',\n 'SNP_02_G G',\n 'SNP_02_A A',\n 'SNP_03_C A',\n 'SNP_03_C C',\n 'SNP_04_G A',\n 'SNP_04_A A',\n 'SNP_04_G G',\n 'SNP_05_A A',\n 'SNP_05_C C',\n 'SNP_06_A G',\n 'SNP_07_A A',\n 'SNP_07_G A',\n 'SNP_08_G G',\n 'SNP_08_A A',\n 'SNP_09_G A',\n 'SNP_10_G G',\n 'SNP_10_A G',\n 'SNP_10_A A',\n 'SNP_11_A G',\n 'SNP_11_G G',\n 'SNP_13_A A',\n 'SNP_14_A A',\n 'SNP_14_C A',\n 'SNP_15_A A']\n\n\n\nunsignif_col\n\n['SNP_01_A G',\n 'SNP_03_A A',\n 'SNP_05_C A',\n 'SNP_06_A A',\n 'SNP_06_G G',\n 'SNP_08_G A',\n 'SNP_09_A A',\n 'SNP_09_G G',\n 'SNP_11_A A',\n 'SNP_12_A A',\n 'SNP_12_G A',\n 'SNP_12_G G',\n 'SNP_13_G G',\n 'SNP_13_A G',\n 'SNP_14_C C',\n 'SNP_15_G A',\n 'SNP_15_G G']\n\n\n\n\"\"\"\nimport scipy.stats as stats\nimport numpy as np\n  \n# Make a 3 x 3 table\ndataset = np.array([[13, 17, 11], [4, 6, 9],\n                    [20, 31, 42]])\n  \n# Finding Chi-squared test statistic,\n# sample size, and minimum of rows\n# and columns\nX2 = stats.chi2_contingency(dataset, correction=False)\nN = np.sum(dataset)\nminimum_dimension = min(dataset.shape)-1\nX2\n\"\"\"\n\n'\\nimport scipy.stats as stats\\nimport numpy as np\\n  \\n# Make a 3 x 3 table\\ndataset = np.array([[13, 17, 11], [4, 6, 9],\\n                    [20, 31, 42]])\\n  \\n# Finding Chi-squared test statistic,\\n# sample size, and minimum of rows\\n# and columns\\nX2 = stats.chi2_contingency(dataset, correction=False)\\nN = np.sum(dataset)\\nminimum_dimension = min(dataset.shape)-1\\nX2\\n'"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#add-column-delete-column",
    "href": "posts/open/Dakon competetion chisquare test.html#add-column-delete-column",
    "title": "Untitled",
    "section": "add column & delete column",
    "text": "add column & delete column\n\ndef create_col(dataset,col,value):\n    _t = []\n    for val in dataset[col] == value:\n        if val == True:\n            _t.append(1)\n        else:\n            _t.append(0)\n    \n    col_name_base = \"has\"+col[-2:]\n    value_name = \"\"\n    for chr in value:\n        if chr != \" \":\n            value_name+=chr\n    col_name = col_name_base+value_name\n    print(col_name)\n    dataset[col_name] = _t\n\n    return dataset\n\n\"\"\"\ndataset = create_col(dataset,\"SNP_01\",\"G G\")\ndataset = create_col(dataset,\"SNP_02\",\"A A\")\ndataset = create_col(dataset,\"SNP_03\",\"A A\")\ndataset = create_col(dataset,\"SNP_04\",\"G G\")\ndataset = create_col(dataset,\"SNP_05\",\"C C\")\ndataset = create_col(dataset,\"SNP_06\",\"A A\")\ndataset = create_col(dataset,\"SNP_07\",\"A A\")\ndataset = create_col(dataset,\"SNP_07\",\"G G\")\ndataset = create_col(dataset,\"SNP_08\",\"G G\")\ndataset = create_col(dataset,\"SNP_09\",\"A A\")\ndataset = create_col(dataset,\"SNP_09\",\"G G\")\ndataset = create_col(dataset,\"SNP_11\",\"A A\")\ndataset = create_col(dataset,\"SNP_12\",\"A A\")\ndataset = create_col(dataset,\"SNP_12\",\"G G\")\ndataset = create_col(dataset,\"SNP_13\",\"A A\")\ndataset = create_col(dataset,\"SNP_14\",\"A A\")\n\"\"\"\n#dataset = dataset.drop(columns = [\"SNP_03\",\"SNP_04\",\"SNP_05\",\"SNP_06\",\"SNP_07\",\"SNP_08\",\"SNP_09\",\"SNP_11\",\"SNP_12\",\"SNP_13\",\"SNP_14\"])\n\n'\\ndataset = create_col(dataset,\"SNP_01\",\"G G\")\\ndataset = create_col(dataset,\"SNP_02\",\"A A\")\\ndataset = create_col(dataset,\"SNP_03\",\"A A\")\\ndataset = create_col(dataset,\"SNP_04\",\"G G\")\\ndataset = create_col(dataset,\"SNP_05\",\"C C\")\\ndataset = create_col(dataset,\"SNP_06\",\"A A\")\\ndataset = create_col(dataset,\"SNP_07\",\"A A\")\\ndataset = create_col(dataset,\"SNP_07\",\"G G\")\\ndataset = create_col(dataset,\"SNP_08\",\"G G\")\\ndataset = create_col(dataset,\"SNP_09\",\"A A\")\\ndataset = create_col(dataset,\"SNP_09\",\"G G\")\\ndataset = create_col(dataset,\"SNP_11\",\"A A\")\\ndataset = create_col(dataset,\"SNP_12\",\"A A\")\\ndataset = create_col(dataset,\"SNP_12\",\"G G\")\\ndataset = create_col(dataset,\"SNP_13\",\"A A\")\\ndataset = create_col(dataset,\"SNP_14\",\"A A\")\\n'"
  },
  {
    "objectID": "posts/open/Dakon competetion chisquare test.html#encoding",
    "href": "posts/open/Dakon competetion chisquare test.html#encoding",
    "title": "Untitled",
    "section": "encoding",
    "text": "encoding\n\n_dataset = dataset\n_dataset\n\n\n\n\n\n  \n    \n      \n      id\n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      SNP_06\n      SNP_07\n      SNP_08\n      SNP_09\n      SNP_10\n      SNP_11\n      SNP_12\n      SNP_13\n      SNP_14\n      SNP_15\n      class\n    \n  \n  \n    \n      0\n      TRAIN_000\n      2\n      G G\n      A G\n      A A\n      G A\n      C A\n      A A\n      A A\n      G G\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      1\n      TRAIN_001\n      2\n      A G\n      A G\n      C A\n      A A\n      A A\n      A G\n      A A\n      G A\n      A A\n      A G\n      A A\n      G A\n      G G\n      A A\n      A A\n      C\n    \n    \n      2\n      TRAIN_002\n      2\n      G G\n      G G\n      A A\n      G A\n      C C\n      G G\n      A A\n      G A\n      G A\n      A G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      3\n      TRAIN_003\n      1\n      A A\n      G G\n      A A\n      G A\n      A A\n      G G\n      G G\n      A A\n      G G\n      A G\n      G G\n      G G\n      G G\n      A A\n      G G\n      A\n    \n    \n      4\n      TRAIN_004\n      2\n      G G\n      G G\n      C C\n      A A\n      C C\n      A A\n      A A\n      A A\n      A A\n      G G\n      A A\n      A A\n      A G\n      A A\n      G A\n      C\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      432\n      TEST_170\n      2\n      A G\n      G G\n      C C\n      A A\n      C A\n      A G\n      A A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      G A\n      NaN\n    \n    \n      433\n      TEST_171\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      A G\n      A A\n      A A\n      A G\n      A A\n      G A\n      NaN\n    \n    \n      434\n      TEST_172\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      G G\n      A G\n      A A\n      A G\n      A A\n      G G\n      NaN\n    \n    \n      435\n      TEST_173\n      2\n      A G\n      G G\n      C A\n      G A\n      C C\n      G G\n      A A\n      G A\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n    \n      436\n      TEST_174\n      2\n      G G\n      G G\n      C C\n      G A\n      C A\n      A A\n      G A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n  \n\n437 rows × 18 columns\n\n\n\n\nonehot-encoding trait != 1 (A클래스 빼고)\n\n_dt = _dataset.loc[_dataset.trait != 1,:].copy()\ncl = _dt[\"class\"]\n#print(cl)\none_hot_label = [col_name for col_name in _dt.columns if \"SNP\" in col_name]\nget_class = [\"id\"]+signif_col + [\"trait\",\"class\"]\ntrait_map = {1:0,2:1}\n\n\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\n_dt = pd.get_dummies(_dt,columns = one_hot_label)\n_dt[\"class\"] = cl.map(class_map)\ncond = ~pd.isna(_dt[\"class\"])\ntrain_ohe = _dt.loc[cond,:]\ntrain_ohe = train_ohe.loc[:,get_class]\ntrain_ohe[\"trait\"] = train_ohe[\"trait\"].map(trait_map)\ntrain_ohe[\"class\"] = train_ohe[\"class\"].astype(int)\n\ntest_ohe = _dt.loc[~cond,:][get_class]\ntest_ohe = test_ohe.drop(columns = \"class\")\ntest_ohe[\"trait\"] = test_ohe[\"trait\"].map(trait_map)\n\n\ntrain_id = train_ohe[\"id\"]\nX_train_ohe = train_ohe.drop(columns = [\"class\",\"id\"])\nY_train_ohe = train_ohe[\"class\"]\n\n\nX_train_ohe\n\n\n\n\n\n  \n    \n      \n      SNP_01_G G\n      SNP_01_A A\n      SNP_02_A G\n      SNP_02_G G\n      SNP_02_A A\n      SNP_03_C A\n      SNP_03_C C\n      SNP_04_G A\n      SNP_04_A A\n      SNP_04_G G\n      ...\n      SNP_10_G G\n      SNP_10_A G\n      SNP_10_A A\n      SNP_11_A G\n      SNP_11_G G\n      SNP_13_A A\n      SNP_14_A A\n      SNP_14_C A\n      SNP_15_A A\n      trait\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n      0\n      1\n      1\n    \n    \n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      ...\n      0\n      1\n      0\n      0\n      0\n      0\n      1\n      0\n      1\n      1\n    \n    \n      2\n      1\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n      0\n      0\n      ...\n      0\n      1\n      0\n      0\n      0\n      1\n      1\n      0\n      1\n      1\n    \n    \n      4\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      ...\n      1\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      1\n    \n    \n      5\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      1\n      0\n      ...\n      1\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      255\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      1\n      0\n      0\n      ...\n      1\n      0\n      0\n      0\n      1\n      1\n      1\n      0\n      0\n      1\n    \n    \n      256\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      1\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n      0\n      1\n      1\n    \n    \n      257\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n      0\n      1\n      1\n    \n    \n      258\n      1\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n      0\n      ...\n      0\n      1\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n    \n    \n      261\n      1\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n      ...\n      1\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      1\n    \n  \n\n193 rows × 28 columns\n\n\n\n\n\nlabel-encoding trait != 0 (A클래스 빼고)\n\n_dt = _dataset.loc[_dataset.trait != 1,:].copy()\ncl = _dt[\"class\"]\n#print(cl)\none_hot_label = [col_name for col_name in _dt.columns if \"SNP\" in col_name]\nget_class = [\"id\"]+signif_col + [\"trait\",\"class\"]\ntrait_map = {1:0,2:1}\n\n\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\n_dt = pd.get_dummies(_dt,columns = one_hot_label)\n_dt[\"class\"] = cl.map(class_map)\ncond = ~pd.isna(_dt[\"class\"])\ntrain_ohe = _dt.loc[cond,:]\ntrain_ohe = train_ohe.loc[:,get_class]\ntrain_ohe[\"trait\"] = train_ohe[\"trait\"].map(trait_map)\ntrain_ohe[\"class\"] = train_ohe[\"class\"].astype(int)\n\ntest_ohe = _dt.loc[~cond,:][get_class]\ntest_ohe = test_ohe.drop(columns = \"class\")\ntest_ohe[\"trait\"] = test_ohe[\"trait\"].map(trait_map)\n\n\n\nOne-hot encoding\n\n\"\"\"\n#one-hot encoding for distance base algorithm\ndataset_ohe = pd.get_dummies(_dataset,columns = _dataset.columns.drop(\"class\"),drop_first=True) #multicollinearity를 막기위한 drop_first 옵션\ntrain_ohe = dataset_ohe[:train_len].copy()\ntest_ohe = dataset_ohe[train_len:].copy().drop(columns=\"class\")\n\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\ntrain_ohe[\"class\"]=train_ohe[\"class\"].map(class_map).astype(int)\nX_train_ohe = train_ohe.drop(columns = \"class\")\nY_train_ohe = train_ohe[\"class\"]\n\"\"\"\n\n'\\n#one-hot encoding for distance base algorithm\\ndataset_ohe = pd.get_dummies(_dataset,columns = _dataset.columns.drop(\"class\"),drop_first=True) #multicollinearity를 막기위한 drop_first 옵션\\ntrain_ohe = dataset_ohe[:train_len].copy()\\ntest_ohe = dataset_ohe[train_len:].copy().drop(columns=\"class\")\\n\\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\\ntrain_ohe[\"class\"]=train_ohe[\"class\"].map(class_map).astype(int)\\nX_train_ohe = train_ohe.drop(columns = \"class\")\\nY_train_ohe = train_ohe[\"class\"]\\n'\n\n\n\n\nLabel encoding\n\n\"\"\"\nle_col = []\nfor col_name in dataset.columns.tolist():\n    if \"SNP\" in col_name:\n        le_col.append(col_name)\nle_col.append(\"trait\")\nfrom sklearn import preprocessing\nfor col in le_col:\n    le = preprocessing.LabelEncoder()\n    _col = dataset[col].tolist()\n    le.fit(_col)\n    dataset[col] = le.transform(_col)\ndataset\n\"\"\"\n\n'\\nle_col = []\\nfor col_name in dataset.columns.tolist():\\n    if \"SNP\" in col_name:\\n        le_col.append(col_name)\\nle_col.append(\"trait\")\\nfrom sklearn import preprocessing\\nfor col in le_col:\\n    le = preprocessing.LabelEncoder()\\n    _col = dataset[col].tolist()\\n    le.fit(_col)\\n    dataset[col] = le.transform(_col)\\ndataset\\n'\n\n\n\n\"\"\"\ntrain = dataset[:train_len].copy()\ntest = dataset[train_len:].copy().drop(columns=\"class\")\n\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\ntrain[\"class\"]=train[\"class\"].map(class_map).astype(int)\nX_train = train.drop(columns = \"class\")\nY_train = train[\"class\"]\n\"\"\"\n\n'\\ntrain = dataset[:train_len].copy()\\ntest = dataset[train_len:].copy().drop(columns=\"class\")\\n\\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\\ntrain[\"class\"]=train[\"class\"].map(class_map).astype(int)\\nX_train = train.drop(columns = \"class\")\\nY_train = train[\"class\"]\\n'"
  },
  {
    "objectID": "posts/open/Dakon competetion.html",
    "href": "posts/open/Dakon competetion.html",
    "title": "Untitled",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nimport os\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\ntest_path = \"C:/Users/22668/Desktop/github/sin-hoyeon/open/test.csv\"\ntrain_path = \"C:/Users/22668/Desktop/github/sin-hoyeon/open/train.csv\"\n\n\nclass CFG:\n    SEED = 42\n\n\ntrain = pd.read_csv(train_path).drop(columns = [\"id\"])\ntrain_len = len(train)\ntest = pd.read_csv(test_path)\nid_test = test[\"id\"]\ntest = pd.read_csv(test_path).drop(columns = [\"id\"])\n\n\ndataset = pd.concat([train,test],axis=0)\n\n\ndataset\n\n\n\n\n\n  \n    \n      \n      father\n      mother\n      gender\n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      SNP_06\n      SNP_07\n      SNP_08\n      SNP_09\n      SNP_10\n      SNP_11\n      SNP_12\n      SNP_13\n      SNP_14\n      SNP_15\n      class\n    \n  \n  \n    \n      0\n      0\n      0\n      0\n      2\n      G G\n      A G\n      A A\n      G A\n      C A\n      A A\n      A A\n      G G\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      1\n      0\n      0\n      0\n      2\n      A G\n      A G\n      C A\n      A A\n      A A\n      A G\n      A A\n      G A\n      A A\n      A G\n      A A\n      G A\n      G G\n      A A\n      A A\n      C\n    \n    \n      2\n      0\n      0\n      0\n      2\n      G G\n      G G\n      A A\n      G A\n      C C\n      G G\n      A A\n      G A\n      G A\n      A G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      3\n      0\n      0\n      0\n      1\n      A A\n      G G\n      A A\n      G A\n      A A\n      G G\n      G G\n      A A\n      G G\n      A G\n      G G\n      G G\n      G G\n      A A\n      G G\n      A\n    \n    \n      4\n      0\n      0\n      0\n      2\n      G G\n      G G\n      C C\n      A A\n      C C\n      A A\n      A A\n      A A\n      A A\n      G G\n      A A\n      A A\n      A G\n      A A\n      G A\n      C\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      170\n      0\n      0\n      0\n      2\n      A G\n      G G\n      C C\n      A A\n      C A\n      A G\n      A A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      G A\n      NaN\n    \n    \n      171\n      0\n      0\n      0\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      A G\n      A A\n      A A\n      A G\n      A A\n      G A\n      NaN\n    \n    \n      172\n      0\n      0\n      0\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      G G\n      A G\n      A A\n      A G\n      A A\n      G G\n      NaN\n    \n    \n      173\n      0\n      0\n      0\n      2\n      A G\n      G G\n      C A\n      G A\n      C C\n      G G\n      A A\n      G A\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n    \n      174\n      0\n      0\n      0\n      2\n      G G\n      G G\n      C C\n      G A\n      C A\n      A A\n      G A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n  \n\n437 rows × 20 columns"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#fathermothergender",
    "href": "posts/open/Dakon competetion.html#fathermothergender",
    "title": "Untitled",
    "section": "father,mother,gender",
    "text": "father,mother,gender\n\nfather,mother,gender = 0 => drop\n\n\ndataset = dataset.drop(columns = [\"father\",\"mother\",\"gender\"])\n\n\ndataset\n\n\n\n\n\n  \n    \n      \n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      SNP_06\n      SNP_07\n      SNP_08\n      SNP_09\n      SNP_10\n      SNP_11\n      SNP_12\n      SNP_13\n      SNP_14\n      SNP_15\n      class\n    \n  \n  \n    \n      0\n      2\n      G G\n      A G\n      A A\n      G A\n      C A\n      A A\n      A A\n      G G\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      1\n      2\n      A G\n      A G\n      C A\n      A A\n      A A\n      A G\n      A A\n      G A\n      A A\n      A G\n      A A\n      G A\n      G G\n      A A\n      A A\n      C\n    \n    \n      2\n      2\n      G G\n      G G\n      A A\n      G A\n      C C\n      G G\n      A A\n      G A\n      G A\n      A G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      3\n      1\n      A A\n      G G\n      A A\n      G A\n      A A\n      G G\n      G G\n      A A\n      G G\n      A G\n      G G\n      G G\n      G G\n      A A\n      G G\n      A\n    \n    \n      4\n      2\n      G G\n      G G\n      C C\n      A A\n      C C\n      A A\n      A A\n      A A\n      A A\n      G G\n      A A\n      A A\n      A G\n      A A\n      G A\n      C\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      170\n      2\n      A G\n      G G\n      C C\n      A A\n      C A\n      A G\n      A A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      G A\n      NaN\n    \n    \n      171\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      A G\n      A A\n      A A\n      A G\n      A A\n      G A\n      NaN\n    \n    \n      172\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      G G\n      A G\n      A A\n      A G\n      A A\n      G G\n      NaN\n    \n    \n      173\n      2\n      A G\n      G G\n      C A\n      G A\n      C C\n      G G\n      A A\n      G A\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n    \n      174\n      2\n      G G\n      G G\n      C C\n      G A\n      C A\n      A A\n      G A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n  \n\n437 rows × 17 columns"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_01",
    "href": "posts/open/Dakon competetion.html#snp_01",
    "title": "Untitled",
    "section": "SNP_01",
    "text": "SNP_01\n\nclass = B 인 경우, AA는 아예 없음 = > feature extraction hasGG 추가\n\n추후 고려사항 - class = A 인 경우, AA가 좀 높음 - class = B 인 경우, GG가 압도적으로 높음 - class = C 인 경우, GG가 좀 높음\n\ncol = \"SNP_01\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_02",
    "href": "posts/open/Dakon competetion.html#snp_02",
    "title": "Untitled",
    "section": "SNP_02",
    "text": "SNP_02\n\nclass = A인 경우, AA는 없음 => f.e has02AA\n\n추후 고려 - B,의 경우 AG->GG-AA 순 - C,의 경우 AG->GG->AA 순\n\ncol = \"SNP_02\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_03",
    "href": "posts/open/Dakon competetion.html#snp_03",
    "title": "Untitled",
    "section": "SNP_03",
    "text": "SNP_03\n\nA인 경우 , 무조건 AA만 존재 => feature extraction\n\n추후 고려 나머지는 뭐 대충 고르게\n\ncol = \"SNP_03\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_04",
    "href": "posts/open/Dakon competetion.html#snp_04",
    "title": "Untitled",
    "section": "SNP_04",
    "text": "SNP_04\n\nC인 경우 , GG는 없음 => feature extraction has04GG\n\n추후 고려 나머지는 뭐 대충 고르게 - class A인 경우,AA가 압도적으로 낮음 => feature extraction\n\ncol = \"SNP_04\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_05",
    "href": "posts/open/Dakon competetion.html#snp_05",
    "title": "Untitled",
    "section": "SNP_05",
    "text": "SNP_05\n\nclass = A인 경우, CC는 없음\n\n\ncol = \"SNP_05\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_06",
    "href": "posts/open/Dakon competetion.html#snp_06",
    "title": "Untitled",
    "section": "SNP_06",
    "text": "SNP_06\n\nclass = A인 경우, AA는 없음 => feature extraction has06AA\n\n\ncol = \"SNP_06\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_07",
    "href": "posts/open/Dakon competetion.html#snp_07",
    "title": "Untitled",
    "section": "SNP_07",
    "text": "SNP_07\n\nA의 경우 => AA는 없음 =>f.e has07AA\nB,C의 경우 => GG는 없음=>f.e has07GG\n\n\ncol = \"SNP_07\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_08",
    "href": "posts/open/Dakon competetion.html#snp_08",
    "title": "Untitled",
    "section": "SNP_08",
    "text": "SNP_08\n\nA의 경우 => GG는 없음 =>f.e has08GG\n\n\ncol = \"SNP_08\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_09",
    "href": "posts/open/Dakon competetion.html#snp_09",
    "title": "Untitled",
    "section": "SNP_09",
    "text": "SNP_09\n\nC의 경우 => 대부분이 AA이고 GA와 GG는 사실 없다고 봐도 무방=> f.e has09AA\nB의 경우 => GG는 거의 없음 => f.e has09GG\n\n앞선 경우들은 빈도수가 낮은 경우네는 따로 feature extraction을 안해줬는데 왜 여기서는 해? => 여기서는 낮은 것들의 빈도수가 1로 너무 낮음,그래서 여기는 함.\n\ncol = \"SNP_09\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\ndataset.loc[dataset[\"class\"] == \"B\",col].value_counts()\n\nA A    91\nG A    22\nG G     1\nName: SNP_09, dtype: int64\n\n\n\ndataset.loc[dataset[\"class\"] == \"C\",col].value_counts()\n\nA A    78\nG A     1\nName: SNP_09, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_10",
    "href": "posts/open/Dakon competetion.html#snp_10",
    "title": "Untitled",
    "section": "SNP_10",
    "text": "SNP_10\n\nA와 B에서 낮은값들이 있긴 한데 … 그래도 특이점 1인 정도는 아님\n\n\ncol = \"SNP_10\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\nx=dataset.loc[dataset[\"class\"] == \"B\",col]\nx.value_counts()\n\nG G    110\nA G      4\nName: SNP_10, dtype: int64\n\n\n\nx=dataset.loc[dataset[\"class\"] == \"A\",col]\nx.value_counts()\n\nA G    34\nA A    32\nG G     3\nName: SNP_10, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_11",
    "href": "posts/open/Dakon competetion.html#snp_11",
    "title": "Untitled",
    "section": "SNP_11",
    "text": "SNP_11\n\nA의 경우 => AA는 없음 =>f.e has11AA\n\n\ncol = \"SNP_11\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_12",
    "href": "posts/open/Dakon competetion.html#snp_12",
    "title": "Untitled",
    "section": "SNP_12",
    "text": "SNP_12\n\nA의 경우 => AA가 있는 관측치가 거의 없음,GG가 있는 관측치는 많음\nB,C의 경우 => GG가 있는 관측치가 거의 없음,AA가 있는 관측치는 많음\n\n=>f.e has12AA =>f.e has12GG\n\ncol = \"SNP_12\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\ndataset.loc[dataset[\"class\"] == \"A\",col].value_counts()\n\nG G    48\nG A    20\nA A     1\nName: SNP_12, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_13",
    "href": "posts/open/Dakon competetion.html#snp_13",
    "title": "Untitled",
    "section": "SNP_13",
    "text": "SNP_13\n\nA의 경우 => AA는 없음 => f.e has13AA\n\n\ncol = \"SNP_13\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\nx=dataset.loc[dataset[\"class\"] == \"A\",col]\nx.value_counts()\n\nG G    66\nA G     3\nName: SNP_13, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_14",
    "href": "posts/open/Dakon competetion.html#snp_14",
    "title": "Untitled",
    "section": "SNP_14",
    "text": "SNP_14\n\nB의 경우 => AA만 존재 =>f.e has14AA 를 추가해서 AA인것들의 계수를 결정하도록\nC의 경우 CC가 있긴 한데 .. 엄청낮긴함(그래도 1은 아니니까 f.e는 안함)\n\n\ncol = \"SNP_14\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")\n\n\n\n\n\nx=dataset.loc[dataset[\"class\"] == \"C\",col]\nx.value_counts()\n\nA A    60\nC A    17\nC C     2\nName: SNP_14, dtype: int64"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#snp_15",
    "href": "posts/open/Dakon competetion.html#snp_15",
    "title": "Untitled",
    "section": "SNP_15",
    "text": "SNP_15\n\n별다른 특징 없음\n\n\ncol = \"SNP_15\"\n\nplt.subplots(1,3,figsize=(20,5))\ni=1\nfor cl in [\"A\",\"B\",\"C\"]:\n    plt.subplot(1,3,i)\n    plt.title(\"class = {}\".format(cl))\n    sns.countplot(x=dataset.loc[dataset[\"class\"] == cl,col])\n    i+=1\n#sns.countplot(dataset[dataset[\"class\"] == \"A\"],x=\"SNP_01\")"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#class별-관측치의-숫자",
    "href": "posts/open/Dakon competetion.html#class별-관측치의-숫자",
    "title": "Untitled",
    "section": "class별 관측치의 숫자",
    "text": "class별 관측치의 숫자\n\nclass imbalance? => No\n\n\nx = dataset[\"class\"].value_counts().index\ny = dataset[\"class\"].value_counts().values\nplt.bar(x,y)\n\n<BarContainer object of 3 artists>"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#one-hot-encoding",
    "href": "posts/open/Dakon competetion.html#one-hot-encoding",
    "title": "Untitled",
    "section": "One-hot encoding",
    "text": "One-hot encoding\n\n#one-hot encoding for distance base algorithm\ndataset_ohe = pd.get_dummies(dataset,columns = dataset.columns.drop(\"class\"),drop_first=True) #multicollinearity를 막기위한 drop_first 옵션\ntrain_ohe = dataset_ohe[:train_len].copy()\ntest_ohe = dataset_ohe[train_len:].copy().drop(columns=\"class\")\n\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\ntrain_ohe[\"class\"]=train_ohe[\"class\"].map(class_map).astype(int)\nX_train_ohe = train_ohe.drop(columns = \"class\")\nY_train_ohe = train_ohe[\"class\"]\n\n\nX_train_ohe\n\n\n\n\n\n  \n    \n      \n      trait_1\n      SNP_01_1\n      SNP_01_2\n      SNP_02_1\n      SNP_02_2\n      SNP_03_1\n      SNP_03_2\n      SNP_04_1\n      SNP_04_2\n      SNP_05_1\n      ...\n      has07AA_1\n      has07GG_1\n      has08GG_1\n      has09AA_1\n      has09GG_1\n      has11AA_1\n      has12AA_1\n      has12GG_1\n      has13AA_1\n      has14AA_1\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n      1\n      0\n      0\n      0\n      1\n      0\n      1\n      ...\n      1\n      0\n      1\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n    \n    \n      1\n      1\n      1\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n      1\n    \n    \n      2\n      1\n      0\n      1\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      ...\n      1\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      1\n      1\n    \n    \n      3\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      ...\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      1\n    \n    \n      4\n      1\n      0\n      1\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n      0\n      0\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      257\n      1\n      1\n      0\n      1\n      0\n      0\n      0\n      1\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      1\n      1\n    \n    \n      258\n      1\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n    \n    \n      259\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      ...\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n    \n    \n      260\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      ...\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      261\n      1\n      0\n      1\n      1\n      0\n      1\n      0\n      0\n      1\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n      0\n      0\n      1\n    \n  \n\n262 rows × 47 columns"
  },
  {
    "objectID": "posts/open/Dakon competetion.html#label-encoding",
    "href": "posts/open/Dakon competetion.html#label-encoding",
    "title": "Untitled",
    "section": "Label encoding",
    "text": "Label encoding\n\nle_col = []\nfor col_name in dataset.columns.tolist():\n    if \"SNP\" in col_name:\n        le_col.append(col_name)\nle_col.append(\"trait\")\nle_col\n\n['SNP_01',\n 'SNP_02',\n 'SNP_03',\n 'SNP_04',\n 'SNP_05',\n 'SNP_06',\n 'SNP_07',\n 'SNP_08',\n 'SNP_09',\n 'SNP_10',\n 'SNP_11',\n 'SNP_12',\n 'SNP_13',\n 'SNP_14',\n 'SNP_15',\n 'trait']\n\n\n\nfrom sklearn import preprocessing\nfor col in le_col:\n    le = preprocessing.LabelEncoder()\n    _col = dataset[col].tolist()\n    le.fit(_col)\n    dataset[col] = le.transform(_col)\ndataset\n\n\n\n\n\n  \n    \n      \n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      SNP_06\n      SNP_07\n      SNP_08\n      SNP_09\n      ...\n      has07AA\n      has07GG\n      has08GG\n      has09AA\n      has09GG\n      has11AA\n      has12AA\n      has12GG\n      has13AA\n      has14AA\n    \n  \n  \n    \n      0\n      1\n      2\n      1\n      0\n      1\n      1\n      0\n      0\n      2\n      0\n      ...\n      1\n      0\n      1\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n    \n    \n      1\n      1\n      1\n      1\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n      1\n    \n    \n      2\n      1\n      2\n      2\n      0\n      1\n      2\n      2\n      0\n      1\n      1\n      ...\n      1\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      1\n      1\n    \n    \n      3\n      0\n      0\n      2\n      0\n      1\n      0\n      2\n      2\n      0\n      2\n      ...\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      1\n    \n    \n      4\n      1\n      2\n      2\n      2\n      0\n      2\n      0\n      0\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n      0\n      0\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      170\n      1\n      1\n      2\n      2\n      0\n      1\n      1\n      0\n      2\n      0\n      ...\n      1\n      0\n      1\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n    \n    \n      171\n      1\n      2\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n      0\n      0\n      1\n    \n    \n      172\n      1\n      2\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n    \n    \n      173\n      1\n      1\n      2\n      1\n      1\n      2\n      2\n      0\n      1\n      0\n      ...\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n    \n    \n      174\n      1\n      2\n      2\n      2\n      1\n      1\n      0\n      1\n      2\n      0\n      ...\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n      0\n      1\n      1\n    \n  \n\n437 rows × 33 columns\n\n\n\n\ntrain = dataset[:train_len].copy()\ntest = dataset[train_len:].copy().drop(columns=\"class\")\n\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\ntrain[\"class\"]=train[\"class\"].map(class_map).astype(int)\nX_train = train.drop(columns = \"class\")\nY_train = train[\"class\"]\n\n\n#원핫인코딩 vs 레이블인코딩\nlen(X_train_ohe.columns),len(X_train.columns)\n\n(47, 32)\n\n\n\nlen(Y_train),len(Y_train_ohe)\n\n(262, 262)"
  },
  {
    "objectID": "posts/open/Dakon competition modeling.html",
    "href": "posts/open/Dakon competition modeling.html",
    "title": "HIHO",
    "section": "",
    "text": "import torch.nn as nn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nimport os\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nimport torch\ntest_path = \"./test.csv\"\ntrain_path = \"./train.csv\"\n\n\n# %pip install plotly (jupyter notebook)\nfrom plotly.offline import iplot\nimport plotly.graph_objs as go\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n#pio.renderers.default = 'iframe_connected'\n#pio.renderers.default = \"vscode\"\npio.renderers.default = \"plotly_mimetype+notebook\""
  },
  {
    "objectID": "posts/open/Dakon competition modeling.html#탐지한-이상치-제외",
    "href": "posts/open/Dakon competition modeling.html#탐지한-이상치-제외",
    "title": "HIHO",
    "section": "탐지한 이상치 제외",
    "text": "탐지한 이상치 제외\n\noutliers = pd.read_csv(\"./outlierdetect.csv\").drop(columns = \"Unnamed: 0\")\nnormal_index = ~outliers.isoutlier\n\n\nX_train_ohe = X_train_ohe[normal_index];Y_train_ohe = Y_train_ohe[normal_index]\n\n\nX_train_ohe.shape\n\ntorch.Size([243, 47])"
  },
  {
    "objectID": "posts/open/Dakon competition torch.html",
    "href": "posts/open/Dakon competition torch.html",
    "title": "Untitled",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nimport os\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nimport torch\ntest_path = \"./test.csv\"\ntrain_path = \"./train.csv\"\n\n\ntrain = pd.read_csv(train_path).drop(columns = [\"id\"])\ntrain_len = len(train)\ntest = pd.read_csv(test_path)\nid_test = test[\"id\"]\ntest = pd.read_csv(test_path).drop(columns = [\"id\"])\n\n\ndataset = pd.concat([train,test],axis=0)\ndataset = dataset.drop(columns = [\"father\",\"mother\",\"gender\"])\n\n\ndataset\n\n\n\n\n\n  \n    \n      \n      trait\n      SNP_01\n      SNP_02\n      SNP_03\n      SNP_04\n      SNP_05\n      SNP_06\n      SNP_07\n      SNP_08\n      SNP_09\n      SNP_10\n      SNP_11\n      SNP_12\n      SNP_13\n      SNP_14\n      SNP_15\n      class\n    \n  \n  \n    \n      0\n      2\n      G G\n      A G\n      A A\n      G A\n      C A\n      A A\n      A A\n      G G\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      1\n      2\n      A G\n      A G\n      C A\n      A A\n      A A\n      A G\n      A A\n      G A\n      A A\n      A G\n      A A\n      G A\n      G G\n      A A\n      A A\n      C\n    \n    \n      2\n      2\n      G G\n      G G\n      A A\n      G A\n      C C\n      G G\n      A A\n      G A\n      G A\n      A G\n      A A\n      A A\n      A A\n      A A\n      A A\n      B\n    \n    \n      3\n      1\n      A A\n      G G\n      A A\n      G A\n      A A\n      G G\n      G G\n      A A\n      G G\n      A G\n      G G\n      G G\n      G G\n      A A\n      G G\n      A\n    \n    \n      4\n      2\n      G G\n      G G\n      C C\n      A A\n      C C\n      A A\n      A A\n      A A\n      A A\n      G G\n      A A\n      A A\n      A G\n      A A\n      G A\n      C\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      170\n      2\n      A G\n      G G\n      C C\n      A A\n      C A\n      A G\n      A A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      G A\n      NaN\n    \n    \n      171\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      A G\n      A A\n      A A\n      A G\n      A A\n      G A\n      NaN\n    \n    \n      172\n      2\n      G G\n      A A\n      A A\n      A A\n      C A\n      A G\n      A A\n      A A\n      A A\n      G G\n      A G\n      A A\n      A G\n      A A\n      G G\n      NaN\n    \n    \n      173\n      2\n      A G\n      G G\n      C A\n      G A\n      C C\n      G G\n      A A\n      G A\n      A A\n      G G\n      A G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n    \n      174\n      2\n      G G\n      G G\n      C C\n      G A\n      C A\n      A A\n      G A\n      G G\n      A A\n      G G\n      G G\n      A A\n      A A\n      A A\n      A A\n      NaN\n    \n  \n\n437 rows × 17 columns\n\n\n\n\n_t = []\nfor val in dataset.SNP_01 == \"G G\":\n    if val == True:\n        _t.append(1)\n    else:\n        _t.append(0)\ndataset[\"has01GG\"] = _t\n\n_t = []\nfor val in dataset.SNP_02 == \"A A\":\n    if val == True:\n        _t.append(1)\n    else:\n        _t.append(0)\ndataset[\"has02AA\"] = _t\n\n\ndef create_col(dataset,col,value):\n    _t = []\n    for val in dataset[col] == value:\n        if val == True:\n            _t.append(1)\n        else:\n            _t.append(0)\n    \n    col_name_base = \"has\"+col[-2:]\n    value_name = \"\"\n    for chr in value:\n        if chr != \" \":\n            value_name+=chr\n    col_name = col_name_base+value_name\n    #print(col_name)\n    dataset[col_name] = _t\n\n    return dataset\n\ndataset = create_col(dataset,\"SNP_03\",\"A A\")\ndataset = create_col(dataset,\"SNP_04\",\"G G\")\ndataset = create_col(dataset,\"SNP_05\",\"C C\")\ndataset = create_col(dataset,\"SNP_06\",\"A A\")\ndataset = create_col(dataset,\"SNP_07\",\"A A\")\ndataset = create_col(dataset,\"SNP_07\",\"G G\")\ndataset = create_col(dataset,\"SNP_08\",\"G G\")\n\ndataset = create_col(dataset,\"SNP_09\",\"A A\")\ndataset = create_col(dataset,\"SNP_09\",\"G G\")\ndataset = create_col(dataset,\"SNP_11\",\"A A\")\n\ndataset = create_col(dataset,\"SNP_12\",\"A A\")\ndataset = create_col(dataset,\"SNP_12\",\"G G\")\n\ndataset = create_col(dataset,\"SNP_13\",\"A A\")\ndataset = create_col(dataset,\"SNP_14\",\"A A\")\n\n\n#one-hot encoding for distance base algorithm\ndataset_ohe = pd.get_dummies(dataset,columns = dataset.columns.drop(\"class\"),drop_first=True) #multicollinearity를 막기위한 drop_first 옵션\ntrain_ohe = dataset_ohe[:train_len].copy()\ntest_ohe = dataset_ohe[train_len:].copy().drop(columns=\"class\")\n\nclass_map = {\"A\":0,\"B\":1,\"C\":2}\ntrain_ohe[\"class\"]=train_ohe[\"class\"].map(class_map).astype(int)\nX_train_ohe = train_ohe.drop(columns = \"class\")\nY_train_ohe = train_ohe[\"class\"]\n\n\nimport torch\nimport torch.nn as nn\n\n\nX_train_ohe = torch.from_numpy(X_train_ohe.values).float()\n#y_train_ohe = torch.from_numpy(pd.get_dummies(Y_train_ohe).values).float()\nY_train_ohe = torch.from_numpy(Y_train_ohe.values).long()\n\n\nclass mynet(nn.Module):\n    def __init__(self,in_features,dropout_p,l1_out=64):\n        super().__init__()\n        self.linr1 = torch.nn.Linear(in_features,l1_out)\n        self.relu1 = torch.nn.ReLU()\n        self.d1 = torch.nn.Dropout(p=dropout_p)\n        self.b1 = torch.nn.BatchNorm1d(l1_out)\n        # 256\n        \n        self.linr2 = torch.nn.Linear(l1_out,l1_out//2)\n        self.relu2 = torch.nn.ReLU()\n        self.d2 = torch.nn.Dropout(p=dropout_p)\n        self.b2 = torch.nn.BatchNorm1d(l1_out//2)\n        # 128\n\n        self.linr3 = torch.nn.Linear(l1_out//2,l1_out//4)\n        self.relu3 = torch.nn.ReLU()\n        self.d3 = torch.nn.Dropout(p=dropout_p)\n        self.b3 = torch.nn.BatchNorm1d(l1_out//4)\n        # 64\n        self.linr4 = torch.nn.Linear(l1_out//4,l1_out//8)\n        self.relu4 = torch.nn.ReLU()\n        self.d4 = torch.nn.Dropout(p=dropout_p)\n        self.b4 = torch.nn.BatchNorm1d(l1_out//8)\n        # 32\n        self.linr5 = torch.nn.Linear(l1_out//8,l1_out//16)\n        self.relu5 = torch.nn.ReLU()\n        self.d5 = torch.nn.Dropout(p=dropout_p)\n        self.b5 = torch.nn.BatchNorm1d(l1_out//16)\n        #16\n        self.linr6 = torch.nn.Linear(l1_out//16,3)\n\n    def forward(self,x):\n        out = self.b1(self.d1(self.relu1(self.linr1(x))))\n        out = self.b2(self.d2(self.relu2(self.linr2(out))))\n        out = self.b3(self.d3(self.relu3(self.linr3(out))))\n        out = self.b4(self.d4(self.relu4(self.linr4(out))))\n        out = self.b5(self.d5(self.relu5(self.linr5(out))))\n        out = self.linr6(out)\n        #out = self.b3(self.d3(self.relu3(self.linr3(x))))\n        return out\n\n\nfrom sklearn.model_selection import StratifiedKFold\nimport random\nepochs_list = [i for i in range(1400,2000,20)]\nweight_decay = np.linspace(0.001,0.0001,500).tolist()\nlr = np.linspace(1e-2,1e-5,500).tolist()\nhidden_nodes = [i for i in range(1300,1800)]\ndropout_p = np.linspace(0.6,0.8,1000).tolist()\nrs = [i for i in range(0,500)]\n\n\ndef dl_cv(epochs,weight_decay,learning_rate,hidden1_nodes,dropout_p,rs):\n\n    try_number=0\n    skf = StratifiedKFold(n_splits=5,shuffle=True)\n    skf.get_n_splits(X_train_ohe,Y_train_ohe)\n    \n    while True:\n        try_number+=1\n        print(f'try:{try_number}...')\n        train_accs = []\n        val_accs = []\n        hdly1 = random.sample(hidden1_nodes,1)[0]\n        lr = random.sample(learning_rate,1)[0]\n        wght_decay = random.sample(weight_decay,1)[0]\n        epoch = random.sample(epochs,1)[0]\n        drop_p = random.sample(dropout_p,1)[0]\n        r_seed = random.sample(rs,1)[0]\n        print(f'lr:{lr} wght_decay:{wght_decay} epochs:{epoch} hidden_l1nodes:{hdly1} dropout_prob:{drop_p}')\n        for train_index,valid_index in skf.split(X_train_ohe,Y_train_ohe): \n            torch.manual_seed(r_seed)\n            net = mynet(47,drop_p,l1_out=hdly1)\n            optimizer = torch.optim.Adam(net.parameters(),lr=lr,weight_decay = wght_decay)        \n            loss_fn = torch.nn.CrossEntropyLoss()\n            #KFold\n            train_index = train_index.tolist();valid_index = valid_index.tolist()\n            X_tr = X_train_ohe[train_index,:];y_tr = Y_train_ohe[train_index]\n            X_tst = X_train_ohe[valid_index,:];y_valid = Y_train_ohe[valid_index]\n\n            #fitting\n            for ep in range(epoch):\n                net.train()\n                #1 yhat\n                yhat = net(X_tr)\n                #2 loss\n                loss = loss_fn(yhat,y_tr)\n                if ep % 50 == 0:\n                    pass\n                    #print(loss)\n                #3 derivative\n                loss.backward()\n                #4 update\n                optimizer.step()\n                optimizer.zero_grad()\n            train_yhat = torch.argmax(net(X_tr),dim=1)\n            train_acc = torch.mean((train_yhat==y_tr).float())\n            print(\"trainacc : \",train_acc)\n            train_accs.append(train_acc)\n            net.eval()\n            with torch.no_grad():\n                val_yhat = torch.argmax(net(X_tst),dim=1)\n                val_acc = torch.mean((val_yhat == y_valid).float()).tolist()\n                print(\"validacc : \",val_acc)\n                val_accs.append(val_acc)\n            if val_acc < 0.97:\n                break\n\n        valid_accuracy = torch.mean(torch.tensor(val_accs))\n        print(f\"K-Fold train accuracy {torch.mean(torch.tensor(train_accs))}\")\n        print(f\"K-Fold valid accuracy {torch.mean(torch.tensor(val_accs))}\")\n        print(\"==========================================================\")\n        if valid_accuracy > 0.99:\n            path = \"./model{}.pth\".format(try_number)\n            torch.save(net,path)\n\n\nt = dl_cv(epochs_list,weight_decay,lr,hidden_nodes,dropout_p,rs)\n\ntry:1...\nlr:0.0039939879759519036 wght_decay:0.00039218436873747497 epochs:1400 hidden_l1nodes:1433 dropout_prob:0.6748748748748749\n\n\nKeyboardInterrupt: \n\n\n\nAssemble\n\ntest_ohe = torch.from_numpy(test_ohe.values).float()\n\n\nimport os\npath = \"C:/Users/22668/Desktop/새 폴더\"\nmodels = []\nfor model in os.listdir(path):\n    md_path = os.path.join(path,model)\n    models.append(torch.load(md_path))\n\n\nassemble = torch.zeros(test_ohe.shape[0],3)\nassemble.shape\n\ntorch.Size([175, 3])\n\n\n\nsoft = torch.nn.Softmax(dim=1)\n\n\nfor model in models:\n    net = model\n    yhat = soft(model(test_ohe))\n    assemble +=yhat\n\n\ntest_predict = torch.argmax(assemble,dim=1)\nresult = pd.concat([pd.Series(id_test),pd.Series(test_predict)],axis=1)\nresult.columns = [\"id\",\"class\"]\nclass_map_inv = {0:\"A\",1:\"B\",2:\"C\"}\nresult[\"class\"] = result[\"class\"].map(class_map_inv)\n\n\nresult\n\n\n\n\n\n  \n    \n      \n      id\n      class\n    \n  \n  \n    \n      0\n      TEST_000\n      A\n    \n    \n      1\n      TEST_001\n      B\n    \n    \n      2\n      TEST_002\n      C\n    \n    \n      3\n      TEST_003\n      B\n    \n    \n      4\n      TEST_004\n      A\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      170\n      TEST_170\n      B\n    \n    \n      171\n      TEST_171\n      C\n    \n    \n      172\n      TEST_172\n      C\n    \n    \n      173\n      TEST_173\n      B\n    \n    \n      174\n      TEST_174\n      B\n    \n  \n\n175 rows × 2 columns\n\n\n\n\nresult.to_csv(\"./submission_dl.csv\",index=False)"
  },
  {
    "objectID": "posts/paper study/batchnormalization.html",
    "href": "posts/paper study/batchnormalization.html",
    "title": "Batch Normalization(작성중)",
    "section": "",
    "text": "Problem setting\nDeep Neural Network는 training중에 파라미터가 계속해서 학습되고 minibatch 각각의 분포가 다르기때문에 hidden layer에 입력되는 input data의 분포가 계속해서 변화(internal covariate shift)한다. 또한 hidden layer의 수가 많은 Deep nueral network에서는 여러번의 파라미터 연산이 반복되기 때문에 깊이 위치하는 hidden layer일수록 이전에 학습했던 input의 분포와 많이 다른 분포를 가진 데이터가 입력된다.이는 크게 두 가지의 문제를 가진다.\n\n레이어의 파라미터 학습이 어려움\nGradient vanishing or exploding\n\n첫 번째는 학습하는데 어려움을 가진다는 것이다. 만약 input data의 분포가 고정되어있다면 그에 맞는 파라미터를 계속해서 학습하며 결과적으로 layer의 파라미터는 어떠한 값으로 수렴할 것이다.그러나 분포가 internal covariate shift가 (학습되는 파라미터로 인해)일어난다면 계속해서 새로운 분포에 맞춰서 파라미터를 수정해야 하기 때문에 학습하는데 어려움이 있다. 논문에서는 이를 좀 다른방식으로 설명하는데 training 셋의 분포와 testset의 분포가 같으면 학습이 잘되고 다르다면 학습이 안되는 것과 유사하다고 한다.\n두 번째는 Gradient vanishing 또는 exploding이다.\n\nimport matplotlib.pyplot as plt\nimport torch\nplt.figure(figsize=(10,5))\nsig = torch.nn.Sigmoid()\nx = torch.linspace(-20,20,50)\nz = sig(x)\npoint_x = torch.tensor(10)\npoint_z = sig(point_x)\nplt.plot(x,z)\nplt.scatter(point_x,point_z,s=80,color = \"red\")\nplt.axvline(point_x,color=\"black\",linestyle=\"--\")\n\n<matplotlib.lines.Line2D at 0x1f70973fac0>\n\n\n\n\n\ninput의 분포의 변화로 인해 임의의 노드에서 시그모이드(\\(g\\))의 input \\(x = Wu + b\\)라고 가정해보자. 만약 \\(|x|\\)가 너무 커서 saturation regime에 존재한다면 \\(\\frac{\\partial{g}}{\\partial{x}} \\approx 0\\)이며 기울기가 vanishing되고 (이는 backpropagation되므로)파라미터의 업데이트가 일어나지 않게 된다.\n위와 같은 문제점을 해결하기 위해 크게 다음과 같은 2가지의 방법이 시도되어왔다.\n\nlower learning rate => training time의 상승\ncareful parameter initialization\n\n위의 방법은 internal covariate shift를 어느정도 해결하긴 하지만 단점도 존재한다.(학습시간의 상승 등등 …)\n논문에서는 internal covariate shift를 해결하기 위해 normalization for each training mini-batch(Batch Normalization)을 수행한다.\n\n\nNormalization via Mini-Batch Statistics\n\n먼저 notation과 내가 헷갈렸던 점을 잠깐 짚고 넘어간다.\n\n논문을 기준으로 BN-layer는 parameter가 존재하는 FC-layer나 conv-layer와 activation function(layer)사이에 존재한다.(그러나 이는 비교적 자유로우며 후에 다시 나온다.)\n\\(\\mathcal{B} = \\{x_{1...m}\\}\\)는 data set에서 m개의 datapoint를 네트워크에 입력하면 어떤 hiddenlayer에 존재하는 임의의 노드 하나에서 activation function(layer)을 통과하기 전 m개의 값이 존재하는데 그 값들을 지칭한다. 그 사이의 값을 \\(x\\)라고 하면 \\(x_{1...m}\\)이 된다.\n\\(\\mu_{\\mathcal{B}}\\)는 minibatch를 구성하는 datapoint 각각을 네트워크에 입력하여 얻은 모든 \\(x\\)에 대한 평균을 의미한다.크기가 \\(m\\)인 minibatch에 대하여 \\(x_1,\\dots,x_m\\)의 평균이다.\n\\(\\sigma^2_{\\mathcal{B}}\\)는 마찬가지로 minibatch여 얻은 \\(x\\)값들의 분산이다.\n\\(\\hat{x_i}\\)는 minibatch에서 i-th datapoint에 위의 연산을 통해 얻은 값이다. \\(\\mu_{\\mathcal{B}}\\)와 \\(\\sigma^2_{\\mathcal{B}}\\)를 사용하므로 minibatch에서 계산한 모든\\(x\\)가 사용된다.\n\\(\\hat{y_i}\\)는 learnable parameter인 \\(\\gamma,\\beta\\)를 추가한 값이다.\n\n평균~normalizae까지 살펴보면 minibatch를 하나의 단위로하여 activation function의 input인 \\(x\\)를 normalization하는 것을 의미한다. Problem setting에서 internal covariate shift가 일어나면서 나타나는 두 가지의 단점을 설명했다. normalization까지의 과정은 결국 normal gaussian distribution으로 바꿔서 activation function으로 입력되는 input의 distribution을 가능한 비슷하게 하고자 하는 것이다.\n여기서 한 가지 중요한 사실은 normalization만 수행하면 network의 표현력을 감소시킨다는 것이다. sigmoid함수를 한 가지 예시로 들어보자. normalization으로 input data의 분포가 normal gaussian distribution가 되었다고 생각해보면 대부분 sigmoid의 linear한 영역에 존재할 것이다. 따라서 nonlinearity를 잃어버리게 된며 이는 네트워크의 표현력을 감소시키므로 좋지 않다.(linearity + nonlinearity는 DNN은 높은 표현력을 가짐을 기억하자) 그러므로, 이러한 점을 막기위해 여기에 추가적으로 학습이 가능한 파라미터 \\(\\gamma\\)를 곱해주고 \\(\\beta\\)를 더해줌으로서 optimal에 다가갈 수 있도록 분포를 학습을 통하여 shifting,scaling하여 network의 표현력을 유지한다.\n예를 들어 학습된 \\(\\gamma\\),\\(\\beta\\)는 다음과 같을 것이다. (nonlinearity를 유지하는 것이 optimal한 경우)  \\[\\gamma \\approx \\sqrt{var[x]},\\beta \\approx \\mathbb{E}[x] \\rightarrow \\hat{x_i}\\approx x_i  \\] (linearity를 얻는 것이 optimal한 경우) \\[\\gamma \\approx 1,\\beta \\approx 0 \\rightarrow \\hat{x_i} \\approx \\frac{x_i-\\mu_\\mathcal{B}}{\\sqrt{\\sigma_\\mathcal{B}^2-\\epsilon}}\\]\n정리하자면 BatchNormalization은 Batch단위의 normalization,learnable parameter를 추가하여internal covariate shift를 막고 fixed된 distribution을 만듬과 동시에 nonlinearity를 유지함으로서 gradient vanishing(exploding),학습의 어려움,표현력의 감소와 같은 문제를 해결했다고 할 수 있다.\n\n\nTraining and Inference with Batch-Normalized Networks\ntraining에서는 minibatch단위로 평균,분산을 구하여 normalization할 수 있지만 test에서는 이와는 다르게 minibatch단위로 data가 입력되지 않으며 또한 입력되는 데이터만 사용하여 값을 예측하길 원한다. 따라서 training에서 각각의 배치들로부터 얻은 평균들과 분산들을 저장해놓고 test에서는 이 값들로 다시 평균을 취하여 normalization을 한다. 이때 단순한 평균을 취하는 것이 아니라 parameter가 어느정도 학습된 상태에서 얻어진 minibatch들의 데이터를 더 많이 고려하기 위해서 movingaverage나 exponentialaverage를 사용한다. movingaverage는 학습단계에서 얻어진 값(평균,분산)의 일부를 직접 지정하여 평균을 구하고 exponentialaverage는 어느정도 안정된 상태의 값들에 높은 가중치를 부여하여 평균,분산을 구한다.\n\\[\\begin{aligned}\n&\\hat{x} = \\frac{x - \\mathbb{E}[x]}{\\text{Var}[x] + \\epsilon}\\\\\n&y = \\frac{\\gamma}{\\sqrt{\\text{var}[x] + \\epsilon}}\\cdot x + (\\beta - \\frac{\\gamma\\mathbb{E}[x]}{\\sqrt{\\text{Var}[x] + \\epsilon}})\\\\\n&\\text{where }E[x] = E_\\mathcal{B}[\\mu_\\mathcal{B}],\\text{Var}[x] = \\frac{m}{m-1}E_\\mathcal{B}[\\sigma_\\mathcal{B}^2]\n\\end{aligned}\\]\n\\(\\frac{m}{m-1}\\)은 unbiased estimate를 위하여 곱해진 값이며 \\(E_{\\mathcal{B}}\\)는 moving average 또는 exponential average를 의미한다. test에서의 normalization은 단순히 linear transform으로 볼 수 있는데 이는 평균과 분산을 구하는 것이 아닌 training에서 구해놓은 값을 단순히 averaging한 고정된(fixed)값을 활용하기 때문이다.\n\n\nIntroduction\nSGD는 간단하고 효율적인 알고리즘이지만 그 자체로는 상당히 민감하고 까다로운 알고리즘이며 그 이유는 다음과 같다.\n\nrequires care ful tuning of hyper-parameters (specifically the learning rate,initial values for the parameters)\nThe inputs to each layer are affected by the parameters of all preceeding layers => small changing to the network => amplification of gradient(vanish or slope)\n\nSGD로 최적화 하면 임의의 layer(sub-network)으로 들어가는 inputs의 distribution은 계속해서 변화하며 이는 각각의 레이어에 존재하는 파라미터를 각각의 입력들의 분포에 맞게 다시 학습해야 함을 의미한다.\n만약 각 레이어에 들어가는 input의 분포가 고정되어 있다면 어떨까? 크게 다음과 같은 이점을 가진다고 논문에서는 설명한다. - 입력의 분포가 변화하는 것에 대하여 파라미터를 재조정 할 필요가 없다.(따라서 유리하다.) - nonlinearity의 inputs이 saturated regime에 gradient vanish가 되는 현상을 막아준다. => 이는 batchnormalization을 추가하면 학습시간이 덜 들어가는 이유이다.\n또한 fixed distribution은\n\nallows us to use much higer learning rates\nless careful about initilization\nacts as a regularizaer\nin some cases eliminating the need for dropout"
  },
  {
    "objectID": "posts/paper study/DQN review.html",
    "href": "posts/paper study/DQN review.html",
    "title": "DQN review",
    "section": "",
    "text": "개요\n\n기존의 딥러닝과 강화학습은 그림의 왼쪽과 같이 공통분모가 거의 없는 분야였습니다. 그러나 2013년 구글딥마인드에서 발표한 D\\(Q\\)N논문에서는 강화학습의 한 분야인 \\(Q\\)-learning에 딥러닝을 접목시켰고 그 후 계속해서 발전하여 거의 모든 강화학습논문에는 딥러닝이 사용된다고 합니다. 따라서 이제는 오른쪽과 같이 강화학습도 거의 딥러닝의 하나의 분야로 자리잡았습니다.\n\n\n\\(Q\\)-learning\n\\(Q\\)-learning은 \\(Q\\)값을 학습하는 알고리즘으로 그리드형식을 가진 문제에서 활용될 수 있습니다. 강화학습에서 주체(agent)는 현재의 상태(state)를 관찰하여 어떠한 행동(action)이 가장 큰 보상(reward)를 가져다주는지 학습하며 \\(Q\\)-learning에서 이러한 학습의 대상은 \\(Q\\)입니다.\n\n위의 그림은 학습이 끝난 \\(Q\\)값의 예시입니다.(실제로 맞는 수치는 아님)\\(Q\\)-learning 알고리즘에서 agent는 greedy action을 취합니다. 따라서 agent가 격자의 시작지점에 들어가게 된다면 greedy action을 통해 가장 큰 \\(Q\\)값이 있는 방향으로 이동하여 시작부터 종료지점까지 일직선으로 가장빠르게 이동합니다. 위와 같은 그리드에서는 더 빠르게 가거나 리워드도 더 좋은 곳은 없으므로 적절하게 학습이 끝났다는 것을 알 수 있습니다.\n\n\n\\(Q\\)-update\n\\[ Q(s_t,a_t) = (1-\\alpha)Q(s_t,a_t) + \\alpha(R_t + \\gamma \\underset{a_{t+1}}{\\text{argmax}}Q(s_{t+1},a_{t+1}))\\]\n\\(Q\\)-learning에서는 위와 같은 수식으로 각각의 \\(Q\\)를 업데이트합니다. 여기서 중요한점은 \\(Q\\)가 state와 action의 함수라는 점입니다. 위와 같은 길찾기 문제의 경우 그렇게 state(25개)가 많지는 않습니다.그러나 Atari 벽돌깨기 게임과 같은 경우, 움직이는 주체인 가로막대바 위치,벽돌의 갯수,깨진위치,공이 날아오는 각도 등등 … 매우 많은 state가 가능하고 어떤방향으로 공을 날릴지에 대한 action도 수없이 많이 가능합니다. 기존의 방식으로 Q를 업데이트 하기위해서는 이러한 수많은 조합에 대하여 state와 action을 기억해놓고 업데이트 해야합니다. 이러한 방식은 컴퓨터의 메모리에 부담을 주고 exploration(탐험)하는데 걸리는 시간을 더 오래 만듭니다.\nDeep-\\(Q\\)-learning에서는 DNN을 통해 함수로서 \\(Q\\)값을 저장하여 위와 같은 단점을 줄입니다. 또한 loss function을 정의하고 gradient desent를 사용하여 새롭게 Q값을 업데이트 합니다.\n\n\n\n그림출처 : 이것저것 테크 블로그"
  },
  {
    "objectID": "posts/paper study/DQN.html",
    "href": "posts/paper study/DQN.html",
    "title": "DQN",
    "section": "",
    "text": "당시 neural network가 발전함에 따라서 RL에도 그대로 DL을 적용하고자 시도함\n그러나 여러가지 문제점이 많이 존재\n\nThe delay between actions and resulting rewards, which can be thousands of timesteps long, seems particularly daunting when compared to the direct association between inputs and targets found in supervised learning.  => 강화학습은 보상을 기반으로 학습을 하나 보상을 받는 시점이 정해지지 않음. 이는 딥러닝과는 다름\nAnother issue is that most deep learning algorithms assume the data samples to be independent, while in reinforcement learning one typically encounters sequences of highly correlated states. => 딥러닝은 변수들이 독립임을 가정하지만 강화학습에서 해결하고자 하는 데이터(시퀀스)가 높은 상관성을 가진채로 존재함\nFurthermore, in RL the data distribution changes as the algorithm learns new behaviours, which can be problematic for deep learning methods that assume a ﬁxed underlying distribution. => 딥러닝은 fixed underlying function(확률분포)를 가정하지만 강화학습의 경우 distribution이 변화함.\n\n논문에서는 위와 같은 문제점들을 극복하여 neural network를 RL(Q-learning)에 적용"
  },
  {
    "objectID": "posts/paper study/DQN.html#experience-replay",
    "href": "posts/paper study/DQN.html#experience-replay",
    "title": "DQN",
    "section": " experience replay",
    "text": "experience replay\n\nstore the agent’s experiences at each time-step, et = (st , at , rt , st+1 ) in a data-set D = e1 , …, eN\nDuring the inner loop of the algorithm, we apply Q-learning updates, or minibatch updates, to samples of experience, e ∼ D, drawn at random from the pool of stored samples.\nAfter performing experience replay, the agent selects and executes an action according to an -greedy policy."
  },
  {
    "objectID": "posts/paper study/DQN.html#algorithm",
    "href": "posts/paper study/DQN.html#algorithm",
    "title": "DQN",
    "section": " algorithm",
    "text": "algorithm"
  },
  {
    "objectID": "posts/Probability&Statistics/categori distribution.html",
    "href": "posts/Probability&Statistics/categori distribution.html",
    "title": "카테고리 분포",
    "section": "",
    "text": "카테고리 분포에 대한 정리\n\n카테고리 분포\n카테고리분포는 시행의 한번의 시행(또는 실험)으로부터 나올 수 있는 사건이 K개인 확률분포를 모델링할때 쓰이며 다음과 같습니다.\n\\[\\begin{aligned}\n&Cat({\\bf{x};\\bf{\\mu}}) =\n\\begin{cases}\n\\mu_1\\, (\\text{if } x = (1,0,0,0,\\dots,1)) \\\\\n\\mu_2\\, (\\text{if } x = (0,1,0,0,\\dots,1)) \\\\\n\\mu_3\\, (\\text{if } x = (0,0,1,0,\\dots,1)) \\\\\n\\vdots \\\\\n\\mu_k\\, (\\text{if } x = (0,0,0,0,\\dots,1)) \\\\\n\\end{cases}\n\\\\\n&\\text{where, }x = (x_1,x_2,\\dots,x_K),\\mu = (\\mu_1,\\mu_2,\\dots,\\mu_k)\n\\end{aligned}\\]\n카테고리분포의 변수\\(\\bf{X}\\)는 K개의 원소를 가지는 원핫인코딩(one-hot encoded)된 벡터이며 각원소는 indicate number(어떤 클래스에 속하는지 나타내는)인 1또는0입니다. 모수(벡터)\\(\\mu\\)도 K개의 원소를 가지며 각각의 원소는 카테고리 확률분포로부터 대응하는 결과값(원핫벡터)에 대한 확률입니다. 즉,각각의 원핫벡터가 표본추출될 가능성(확률)을 알려줍니다.\n위와 같은 사실로부터 다음과 같은 4가지의 제약조건이 존재합니다.\n\n\\(\\mu_i\\)는 원핫벡터가 나올 확률입니다.\n\n\\[0\\leq\\mu_i\\leq1\\]\n\n확률의 합은 1입니다.\n\n\\[\\sum_{i=1}^{K}\\mu_i = 1\\]\n\n원핫벡터의 각 원소는 indicate number인 1또는 0입니다.\n\n\\[\\begin{aligned}\nx_i =\n\\begin{cases}\n0\\\\\n1\n\\end{cases}\n\\end{aligned}\\]\n\n원핫벡터의 모든 원소의 합은 1입니다. \\[\\sum_{i=1}^{K}x_i = 1\\]"
  },
  {
    "objectID": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html",
    "href": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html",
    "title": "MLE & MAP (작성중)",
    "section": "",
    "text": "HYEONGMIN LEE’S WEBSITE - MLE & MAP를 공부하고 정리한 글입니다."
  },
  {
    "objectID": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#problem-setting",
    "href": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#problem-setting",
    "title": "MLE & MAP (작성중)",
    "section": "Problem Setting",
    "text": "Problem Setting\n실제 \\(N\\)명의 사람들로부터 키(\\(x\\))와 몸무게(\\(t\\))를 조사한 다음과 같은 data set \\(D\\)를 가지고 있다고 해보자.\n\\[ D = \\{(x_1,t_1),(x_2,t_2,),\\dots,(x_N,t_N)\\}\\]\n키로 몸무게를 예측하는 모형을 만들고자 한다. 어떻게 만들 수 있을까?"
  },
  {
    "objectID": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#modeling",
    "href": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#modeling",
    "title": "MLE & MAP (작성중)",
    "section": " Modeling ",
    "text": "Modeling \n가장 단순한 접근은 키(\\(x\\))를 입력으로 하고 몸무게(\\(t\\))를 출력하는 함수\\(y(x|\\theta)\\)를 만드는 것이다.\n\\[t = y(x|\\theta)\\]\n\n\\(\\theta\\)는 함수의 parameter를 나타낸다.\n\n파라미터\\(\\theta\\)를 학습하여 키-몸무게 사이의 관계를 표현하는 거의 완벽하게 표현하는 함수를 얻었다고 해보자. 그렇다면 키\\(x\\)를 입력으로 하여 몸무게에 대한 예측값 \\(t\\)하나를 얻을 수 있다. 예를 들어 키가 175cm인 사람의 몸무게가 함수를 통하여 얻은 예측값이 72kg이라고 하자. 이 결과를 말로하면 “키가 175cm인 사람의 몸무게는 72kg이야.”라고 하는 것과 같다.\n이렇게 키\\(x\\)에 대해서 몸무게에 대한 하나의 예측값\\(y\\)를 하나만 돌려주는 방법은 옳을까? 결론적으로 말하면 그렇지 않다. 왜냐하면 실제 data의 형태는 키\\(x\\)에 대해 하나의 몸무게\\(t\\)만을 가지지 않기이다. 예를 들자면 \\((175,62),(175,72),(175,83),(175,88)\\dots\\)등등 다양한 키-몸무게 다양한 조합이 가능하지만 함수로 표현할 경우 하나의 입력은 하나의 출력에만 mapping되며 이 밖에 나올 수 있는 다른 값들에 대한 설명은 전혀 하지 않기 때문이다. 그렇다면 어떠한 방법이 더 좋을까? 키가 175cm인 사람의 몸무게는 아마도 72kg 꺼야 정도의 말을 할 수 있다면 가장 좋을 것이다.\n이러한 해석은 키가 175cm인 사람에 대해서 몸무게에 대한 예측이 거의 72kg이라고 확신하지만 이와 동시에 몸무게의 예측값이 불확실하며 키가 동일하다 할지라도 어느정도는 랜덤하다는 것을 내포한다.이렇게 불확실하며 랜덤한 가지는 값은 randomvariable라고 하며 문제에서 몸무게\\(t\\)를 random-variable로 취급하면 위와 같은 해석이 가능하다. 예를들어 키가 \\(x\\)인 사람의 몸무게\\(t\\)가 randomvariable이며 다음과 같은 정규분포를 따른다고 가정하자.\n\\[\\begin{aligned}\n&t\\sim\\mathcal{N}(y(x|\\theta),\\sigma^2) \\\\\n&\\longleftrightarrow p(t|x,\\theta,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}(\\frac{-(t-y(x|\\theta))^2}{2\\sigma^2})\n\\end{aligned}\\]\n위와 같다면 \\(y(x|\\theta)\\)에사 가장 높은 확률을 가지는 정규분포이므로 “키가 \\(x\\)인 사람의 몸무게\\(t\\)는 아마도 \\(y(x|\\theta)\\)일꺼야”라는 것을 의미하며 또한 다른 값들에 대한 확률들도 어느정도 담고 있으므로 \\(t\\)가 불확실하며 랜덤하다는 것도 확실하게 표현함을 알 수 있다.\n여기서 \\(\\sigma^2\\)는 우리가 한 예측에 대해서 얼마나 불확실인지를 나타내는 정도이다. \\(\\sigma^2\\)가 커서 확률분포의 변동이 크다면 모든 값에 대하여 일정한 확률을 부여하므로 예측값 \\(t\\)에 대한 확신이 없다는 것이고 변동이 작다면 어떤 특정 값에만 확률을 몰아서 부여한 것이므로 예측값\\(t\\)에 대한 확신이 크다는 것이다\n예를 들어 \\(x = 175,\\,y(x|\\theta) = 72,\\,t\\sim\\mathcal{N}(72,\\sigma^2)\\)인 두 개의 정규분포를 따른다면 모양은 다음과 같다.\n\n\n<matplotlib.legend.Legend at 0x19bf519daf0>\n\n\n\n\n\n이와 같이 키\\(x=175\\)에 일때 몸무게\\(t\\)는 randomvariable이며 평균이72 확률이 가장 높으므로 키가 175cm인 사람의 몸무게는 아마도 72kg 꺼야라는 말을 할 수 있으며 또한 다른 값으로 나올 확률도 빠짐없이 표현되어 있으므로 이와 같은 몸무게\\(t\\)는 확률변수로 표현하는 적절하다. 또한 빨간색 그래프는 파란색그래프보다 \\(\\sigma^2\\)가 더 크며 \\(t=72\\)에서 더 높은 확률을 부여하므로 예측에 대한 확신이 더 크다는 것을 나타낸다.\n지금까지 몸무게 \\(t\\)를 randomvariable이며 확률분포 \\(\\mathcal{N}(y(x|\\theta),\\sigma^2)\\)를 따른다고 하였다. 예시에서는 확률분포를 parameter를 가정하고 그래프를 그려서 비교했지만 실제로는 확률분포의 종류도 모르거니와 확률분포의 parameter도 모르기에 위와 같은 해석을 할 수 없다. 그러므로 여기서부터는 확률분포를 추정하는 것에 관한 얘기를 해보고자 한다."
  },
  {
    "objectID": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#maximum-likelyhood-estimation",
    "href": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#maximum-likelyhood-estimation",
    "title": "MLE & MAP (작성중)",
    "section": "Maximum Likelyhood Estimation",
    "text": "Maximum Likelyhood Estimation\n주어진 데이터에 맞는 확률분포는 어떻게 결정할 수 있을까? 크게 두 단계로 나뉜다. - 확률분포의 종류 결정 - 확률분포의 파라미터 추정\n확률분포의 종류를 결정하는 일은 문제마다 다르다. 위에서 예시로 들었던 몸무게와 같은 연속적인 확률변수일 경우 연속확률분포 중 하나를 가정하고 이산확률변수일 경우 이산확률분포 중 하나를 가정한다. 위의 문제에서는 정규분포를 몸무게\\(t\\)의 분포로 가정했다. 그러나 이는 문제에 따라 다르며 문제에 맞는 적절한 확률분포를 먼저 가정해야 한다.\n확률분포를 가정했다면 다음은 확률분포의 parameter를 구하면 된다.(추정한다고 말한다.)parameter를 추정할 경우 우리는 확률분포에 대한 완전한 식을 얻을 수 있으며 따라서 확률분포로부터 여러가지 정보를 얻을 수 있다. 여기서는 MLE를 통해서 확률분포의 파라미터를 추정한다.\n앞선 문제를 풀기전에 앞서서 간단한 예시로 예를 MLE에 대한 감을 잡아보자.예를 들어 대한민국 20대 남성들 중 한명의 키를 골라서 얻은 data set \\(D = \\{65\\}\\)가 주어졌다고 가정 해보자. 분포의 모양은 먼저 정규분포로 가정한다.\n\n\n<matplotlib.legend.Legend at 0x19bf1d77f10>\n\n\n\n\n\n평균만 다른 정규분포 3개를 고려해보자. 이 중 어떤 분포에서 \\(D\\)가 나왔을까? 주어진 3개의 분포중에는 \\(\\mu=63\\)인 파랑색에 해당하는 분포에서 \\(D=\\{65\\}\\)를 나왔을 가능성이 가장 크다. 왜냐하면 파랑색 확률분포에서 dataset에 속한 하나의 datapoint가 나올 확률이 가장 크기때문이다. 그러므로 3개의 정규분포중에서는 \\(\\mu =63\\)인 경우가 \\(D\\)에 가장 적합하다고 할 수 있으며 그 다음은 보라색 그 다음은 초록색 분포의 모수가 적합하다.\n이번에는 2개의 관측치가 존재하는 data set \\(D = \\{62,65\\}\\)가 주어졌다고 가정 해보자.\n\n\n<matplotlib.legend.Legend at 0x19bf7255e80>\n\n\n\n\n\n어떤 확률분포에서 \\(D=\\{62,65\\}\\)가 나왔을까? 마찬가지로 파랑색 분포가 주어진 분포중에서는 가장 가능성이 커보이는데 왜냐하면 마찬가지로 dataset에 속한 2개의 각각의 datapoint를 얻을 확률이 가장 커보이기 때문이다. 그러므로 위와 동일하게 3개의 정규분포중에서는 \\(\\mu =63\\)인 경우가 \\(D\\)에 가장 적합하다고 할 수 있으며 이번에는 초록색,보라색 순서로 모수가 적합하다.\n이번에는 크기가 \\(N\\)인 \\(D\\)가 주어져있다고 가정해보자.\n\n\n\n\n\n\n그래프는 크기가 30인data set이지만 N이라고 보자..!\n\n이번에도 어떤 확률분포에서 \\(D\\)가 나왔을지 한번 구분해보자. 그러나 이전에는 \\(D\\)의 크기가 1또는 2여서 직관적으로 보였지만 이번에는 데이터가 너무 많기 때문에 바로 보이지 않는다.\n그러나 이전에 했던 과정들 중에서 \\(D\\)에 있는 각각의 datapoint를 취할 확률을 모두 고려한뒤에 그 값이 가장 큰 parameter를 주어진 \\(D\\)에 가장 적합한 parameter 로 결정했었는데 이 사실은 그대로 사용할 수 있다. 왜냐하면 사실 각각의 datapoint를 모두 취할 확률은 결합확률이기 때문이다. 또한 각각의 datapoint는 모두 독립적이며 동일한 분포로부터 뽑힌 값이기 때문에 결합확률은 각 datapoin를 모두 동시에 취할 확률이다.\n\\[\\begin{align}\np(D|\\theta) &= p_{X_1,X_2,\\dots,X_N}(x_1,x_2,\\dots,x_N;\\theta) \\\\\n&= p_{X_1}(x_1|\\theta)\\cdot p_{X_2}(x_2|\\theta)\\dots  \\cdot p_{X_N}(x_N|\\theta) \\\\\n&= \\prod_{i=1}^{N}p_{X_i}(x_i;\\theta)\n\\end{align}\\]\n\n\\(\\theta\\)는 parameter를 의미한다. 정규분포의 parameter이므로 \\(\\mu,\\sigma^2\\)라 생각하면 된다.\n결합확률은 likelyhood라고도 한다.\n\n그러므로 3개의 서로다른 \\(\\theta\\)에 대한 확률분포에 대하여 모두 likelyhood를 구한뒤 그 중 가장 큰 값을 parameter로 하면 된다. 그런데 사실 우리의 비교 대상은 단 3개의 \\(\\theta\\)가 아니다. 가능한 모든 확률분포 즉 가능한 모든 \\(\\theta\\)에 대하여 likelyhood의 가장 큰 값을 구해야 한다. 그러므로 \\(\\theta\\)를 변수로 생각하여 likelyhood를 가장크게 하는 \\(\\theta\\)를 찾는다. 따라서 maximum likelyhood estimation이며 이를 통하여 나온 parameter \\(\\theta\\)에 대한 추정량은 다음과 같다.\n\\[\\begin{aligned}\n\\hat{\\theta}_{MLE} &= \\underset{\\theta}{\\text{argmax}}\\,p_{X_1,X_2,\\dots,X_n}(x_1,x_2 \\dots x_n|\\theta) \\\\\n&=  \\underset{\\theta}{\\text{argmax}}\\,p_{X_1,X_2,\\dots,X_n}(x_1,x_2,\\dots,x_n|\\theta) \\\\\n&= \\underset{\\theta}{\\text{argmax}}\\,\\prod_{i=1}^{N}p_{X_i}(x_i;\\theta)\n\\end{aligned}\\]\n정리하자면 결국 MLE는 파라미터를 추정하는 방법으로 likelyhood(\\(D\\)에 있는 각각의 datapoint가 모두 나올 확률)를 최대화하는 파라미터\\(\\theta\\)를 추정량으로 한다는 것이다.\n이제 기존문제로 돌아가보자. 우리에게 주어진 data set \\(D\\)는 다음과 같았으며 정규분포로 몸무게는 \\(t\\)로 가정했었다.\n\\[\\begin{aligned}\n&D = \\{(x_1,t_1),(x_2,t_2,),\\dots,(x_N,t_N)\\} \\\\\n&t\\sim\\mathcal{N}(y(x|\\theta),\\sigma^2) \\\\\n&\\longleftrightarrow p(t|x,\\theta,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}(\\frac{-(t-y(x|\\theta))^2}{2\\sigma^2})\n\\end{aligned}\\]\n\\(D\\)에 있는 각각의 datapoint를 모두 나올 확률은 키가 \\(x_1\\)일 때 실제 몸무게가 \\(t_1\\)이고, 키가 \\(x_2\\)일 때 실제 몸무게가 \\(t_2\\)이고, \\(x_N\\)일 때 실제 몸무게가 \\(t_N\\)일 확률과 같다.\n\\[\\begin{aligned}\np(D|\\theta) &= p(t_1,t_2,\\dots,t_N|X,\\theta,\\sigma^2) \\\\\n&= \\prod_{n=1}^Np(t_i|x_i,\\theta,\\sigma^2) \\\\\n&= \\prod_{n=1}^N\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}(\\frac{-(t_i-y(x_i|\\theta))^2}{2\\sigma^2})\n\\end{aligned}\\]\nMLE는 likelyhood를 최대화 하는 파라미터를 구하는 방법이므로 \\(\\theta\\)는 다음과 같다.\n\\[\\begin{aligned}\n\\hat{\\theta}_{MLE} = \\underset{w}{\\text{argmax}}&\\prod_{n=1}^N\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}(\\frac{-(t_i-y(x_i|\\theta))^2}{2\\sigma^2})\n\\end{aligned}\\]\n위의 식으로부터 직접 최대화 하는 \\(\\theta\\)를 찾기는 어려우므로 likelyhood에 \\(-\\text{ln}\\)를 곱해준 NLL을 사용한다. \\(\\text{ln}\\)함수는 곱해도 최댓값(또는 최솟값)의 위치가 변하지 않으며 곱셈연산을 덧셈연산으로 바꿔 계산을 간단하게 해준다. 또한 -를 곱해줌으로서 최소지점을 찾는 문제로 바뀌게 된다.\n\\[\\begin{aligned}\n\\hat{\\theta}_{MLE} &= \\underset{w}{\\text{argmin}}-\\text{ln}\\prod_{n=1}^N\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}(\\frac{-(t_i-y(x_i|\\theta))^2}{2\\sigma^2})\\\\\n&= \\underset{w}{\\text{argmin}}-\\sum_{n=1}^N\\text{ln}\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}(\\frac{-(t_i-y(x_i|\\theta))^2}{2\\sigma^2}) \\\\\n&= \\underset{w}{\\text{argmin}}-\\sum_{n=1}^{N}\\bigg[\\text{ln}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} + \\text{ln}\\,\\text{exp}(\\frac{-(t_i-y(x_i|\\theta))^2}\n{2\\sigma^2})\\bigg]\\\\\n&= \\underset{w}{\\text{argmin}}-\\sum_{n=1}^{N}\\bigg[\\text{ln}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} - \\frac{(t_i-y(x_i|\\theta))^2}{2\\sigma^2}\\bigg]\n\\end{aligned}\\]\n여기서 \\(\\theta\\)의 관점에서 상수(\\(\\pi,\\sigma^2\\))를 제거하고 보면 다음과 같다.\n\\[\\begin{aligned}\n\\hat{\\theta}_{MLE} = \\underset{w}{\\text{argmin}}\\sum_{n=1}^{N}(t_i-y(x_i|\\theta))^2\n\\end{aligned}\\]\n어디선가 많이 본 식인데 바로 L2 Loss이다. 이렇게 datapoint가 정규분포를 따른다고 가정하고 MLE를 통해 L2 Loss를 나옴을 밝힘으로써 회귀문제에서 L2 Loss를 왜 사용하는지 그 이유를 설명할 수 있고 역으로 회귀문제에서 L2 Loss를 사용한다면 datapoint가 정규분포를 따른다고 가정하고 MLE를 통해서 파라미터를 구하는 것이겠구나 하고 알 수 있다.\n참고적으로 classification에서는 datapoint가 베르누이분포를 따른다고 가정한다면 binary cross entropy loss를 얻을 수 있다고 한다.\n간단정리 - Dataset이 어떠한 확률분포를 따르는지 결정하기 위해서는 parameter를 구해야 한다. - MLE은 Likelyhood를 가장 크게 만드는 parameter를 찾고 그 값을 parameter에 대한 추정량으로 한다."
  },
  {
    "objectID": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#maximum-a-posterior",
    "href": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#maximum-a-posterior",
    "title": "MLE & MAP (작성중)",
    "section": "Maximum a Posterior",
    "text": "Maximum a Posterior\nMLE는 likelyhood인 \\(p(D|\\theta)\\)를 maximize하는 \\(\\theta\\)를 구하였다. MAP는 반대로 posterior인 \\(p(\\theta|D)\\)를 maximize하는 \\(\\theta\\)를 구한다. 한마디로 설명하자면 주어진 데이터셋 \\(D\\)에 확률이 가장 큰 \\(\\theta\\)를 선택하는 방식이라고 할 수 있다.\nMLE대신 MAP를 통해 파라미터를 구함으로써 얻을 수 있는 장점은 뭘까? 먼저 posterior를 bayes rule에 의해서 적어보면 다음과 같다.\n\\[\\begin{aligned}\n&p(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)}{p(D)} \\propto p(\\theta|D)p(\\theta)\\\\\n&\\text{where }  \\\\\n&\n\\begin{aligned}\n&p(\\theta|D) : \\text{posterior}\\\\\n&p(D|\\theta) : \\text{likelyhood}\\\\\n&p(\\theta)   : \\text{prior} \\\\\n&p(D) : \\text{normalization constant}\n&\\end{aligned}\n\\end{aligned}\\]\n주목할 점은 posterior에는 우리가 정할 수 있는 prior가 포함되어 있다는 것이다. 따라서 prior를 통하여 가지고 있는 사전지식을 posterior에 충분히 반영할 수 있고 사전지식이 없다고 할지라도 prior를 통해 overfitting을 방지할 수 있다. overfitting은 \\(|\\theta|\\)가 커서 신경망의 표현력이 과할 경우 일어나는 현상이므로 prior에 평균이 0인 분포를 가정해준다면 우리는 posterior를 통해서 비교적 작은 크기를 갖는 \\(\\theta\\)를 얻을 수 있다.\n여기서는 \\(\\theta\\)가 정규분포를 따른다고 가정하고 overfitting을 막아주는 L2 Regularization(weight decay)를 유도해보자.\n\\[\\begin{aligned}\n\\hat{\\theta}_{MAP} &= \\underset{\\theta}{\\text{argmax}}\\,P(\\theta|D) \\\\\n&= \\underset{\\theta}{\\text{argmax}}\\,p(\\theta|D)p(\\theta)\\\\\n&= \\underset{\\theta}{\\text{argmax}}\\,\\text{ln}\\,p(\\theta|D)p(\\theta)\\\\\n&= \\underset{\\theta}{\\text{argmax}}\\,\\text{ln}\\,p(\\theta|D) + \\text{ln}\\,p(\\theta)\\\\\n&= \\underset{\\theta}{\\text{argmin}}\\, -\\text{ln}\\,p(\\theta|D) - \\text{ln}\\,p(\\theta)\n\\end{aligned}\\]\n여기서 \\(-\\text{ln}p(\\theta|D)\\)는 MLE에서의 negative log likelyhood와 같으며 \\(\\text{ln}p(\\theta)\\)는 우리가 정하는 prior에 의한 값이다. \\(\\theta\\)에 대한 prior가 정규분포를 따른다고 가정하고 구해보면 다음과 같다.\n\\[\\begin{aligned}\n&\\theta \\sim \\mathcal{N}(\\theta|0,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}(-\\frac{\\theta^2}{2\\sigma^2_\\theta})\\\\\n&-\\text{ln}p(\\theta) = -\\text{ln}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} + \\frac{\\theta^2}{2\\sigma^2_{\\theta}}\n\\end{aligned}\\]\n상수값을 제거하고 대입하면 MAP를 통해 구한 parameter는 다음과 같다.\n\\[\\begin{aligned}\n\\hat{\\theta}_{MAP} &= \\underset{\\theta}{\\text{argmin}}\\sum_{i=1}^{N}(t - y(x_i|w))^2 + \\frac{w^2}{2\\sigma_{\\theta}^2}\\\\\n&= \\underset{\\theta}{\\text{argmin}}\\sum_{i=1}^{N}(t - y(x_i|w))^2 + \\alpha w^2 \\quad(\\alpha = \\frac{1}{2\\sigma^2})\n\n\\end{aligned}\\]\n이 또한 어디선가 많이 본 식이며 바로 L2 Loss에 L2 Regularization을 추가한 것이다. 이와 같이 parameter의 prior가 정규분포라고 가정하고 MAP를 통해 loss function을 구한다면 우리가 사용하고자 하는 모델의 loss function에서 regularization term이 왜 저렇게 나오는가를 설명할 수 있다. 또한 역으로 L2 Regularization term이 포함된 loss function을 사용한다면 paraemter에 대한 prior를 정규분포임로 가정했음을 알 수 있다."
  },
  {
    "objectID": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#베이즈-정리에서-바라본-mle",
    "href": "posts/Probability&Statistics/Maximum likelyhood estimation/MLE.html#베이즈-정리에서-바라본-mle",
    "title": "MLE & MAP (작성중)",
    "section": "베이즈 정리에서 바라본 MLE",
    "text": "베이즈 정리에서 바라본 MLE\n\\(D=(t_1,t_2,\\dots,t_n)\\)는 샘플(데이터셋), \\(\\theta\\)는 우리가 알고싶은 확률분포의 모수라고 합시다. 베이즈정리는 증거 또는 조건이 주어지기 전의 사전확률 \\(p(D)\\)와 주어진 후의 사후확률 \\(p(\\theta|D)\\)사이의 관계를 알려줍니다.\n여기서 사후확률은 \\(\\theta\\)에 대한 확률분포로 데이터(샘플)이 주어질때 확률분포의 임의의 모수\\(\\theta\\)가 얼마나 가능한지 또는 불확실한지 그 정도를 알려주는 확률을 함숫값으로 가지는 확률함수입니다. 그러므로 사후확률을 최대로 하는 모수\\(\\theta\\)가 데이터셋이 주어져있을 때 가장 확률이 높은,가능성이 높은 모수이므로 그때의 값을 확률분포의 모수로 추정하면 됩니다.\n문제는 왼쪽의 확률분포는 바로 알기가 쉽지 않다는 점입니다. 따라서 베이즈정리를 통하여 우변의 식을 최대화 하는 값을 구합니다. 우변의 식에서 분모는 주어진 데이터에 의하여 고정된 상수(normalization constant라고 합니다)입니다. 그러므로 최댓값을 구하는데 영향을 주지 않습니다. 우리는 분자에 있는 \\(p(D|\\theta)p(\\theta)\\)를 최대화하는 \\(\\theta\\)를 찾으면 됩니다.\n여기서 \\(p(D|\\theta)\\)를 가능도(likelyhood)라 합니다. MLE에서는 분자에서 가능도만 최대로 하는 \\(\\theta\\)를 구합니다. MAP라는 다른 방법은 분자에 있는 \\(p(D|\\theta)p(\\theta)\\)를 최대화 하는 \\(\\theta\\)를 구한다고 합니다.\n가능도함수를 최대로 하는 모숫값은 175.75입니다. 따라서 MLE에 의한 모수에 대한 추정값은 175.75입니다. \\[\\hat{\\theta}_{MLE} = 175.75\\]\n링크1(random sample vs random variable) 링크2(추정,추정량,추정값) 링크3(mle) 링크4(mle)"
  },
  {
    "objectID": "posts/Probability&Statistics/notation.html",
    "href": "posts/Probability&Statistics/notation.html",
    "title": "확률분포에서 ;와|의 사용",
    "section": "",
    "text": "확률분포에서 ;와|에 관한 notation 정리\n\n;의 사용\n; 함수에서 특정 변수를 고정시켜놓을때 사용할 수 있다. 다음과 같은 이변수함수를 생각해보자 \\[f(x,y)\\] 독립변수 x와 y를 갖는 함수이며 두 변수 모두에 대해서 미분가능하다. 여기서 변수 y가 어떤 어떤 값으로 고정된것이 알려지거나 또는 고정된상황을 가정한 후 x에 대해서만 관심이 있다고 해보자(미분,극한등을 아마도?취하고 싶다..아마도…) 이때는 이변수함수로 표기하는것이 아닌 일변수함수로 표기해야한다. 그때는 다음과 같이 표기하면 된다.\n\\[\nf(x;y)\n\\]\n이렇게 표기하면 y값은 이제 어떤 값으로 이미 설정(setting)되거나 고정(fixed)되어있음을 의미한다. 비슷하게 그냥 고정된 파라미터가 이 다음에도 올 수 있다. 베르누이분포의 확률질량함수는 다음과 같다.\n\\[f_X(x;p) = p^x(1-p)^{1-x}\\]\nsetting,fixed된 파라미터인 p를 ;다음에 표시했다.\n\n\n|의 사용\n|는 given that,if이라는 의미이며 |의 다음에는 보통 먼저 깔고가거나 주어지는 전제,상황,조건,증거 등이 나온다. 확률,통계 분야에서만 쓰이며 조건부 확률이나,베이지안에서 많이 쓰이는 기호라고 한다. 중요한 점은 특히 |다음에 오는 상황,조건,증거와 같은 것들은 어떤 관점이냐에 따라서 상수나 확률변수의 관점으로 생각될 수 있다는 것이다. 특히 베이지안에서는 확률변수로 생각한다.\n조건부 확률분포(조건부확률밀도함수,조건부 확률함수)는 다음과 같다. \\[\np_{X|Y}(x|y) = \\frac{p_{XY}(x,y)}{p_Y(y)}\\\\\np_{X|Y}(y|x) = \\frac{p_{XY}(x,y)}{p_X(x)}\n\\]  가장 윗식을 해석해보면 다음과 같다. - 좌변 : 확률변수 Y가 주어진(given)상황에서 확률변수X의 확률(또는 확률밀도)를 나타내는 함수이며 시행으로부터 확률변수 X가 취할 수 있는 값 x를 입력으로 받는다. 조건부 확률분포에서 Y의 값은 y로 주어져 있다고 가정하므로 입력하는 변수가 아니다. 따라서 확률변수 Y는 변수가 아니라 모수(parameter)이다. - 우변 : 조건부확률분포 공식.\n##  결론 ; vs |\n\\[p_{\\theta}(x) = p(x;\\theta) = p(x|\\theta)\\]  ;는 수학의 모든 분야에서 쓰이지만 |는 확률통계분야에서만 쓰인다. ;다음에는 이미 설정되거나 고정된 값이 나오며 |다음에는 먼저 주어지는 조건이 나온다. 근데 ;를 많이 쓰지 않고 |뒤에 그냥 고정된 값을 써버리는 경우가 많다. 이는 지양해야 할 표현이다.\n참고링크 링크1(;의 사용법) 링크2(조건부확률분포) 링크3(표기법의 혼용)"
  },
  {
    "objectID": "posts/Probability&Statistics/sample space and random variable.html",
    "href": "posts/Probability&Statistics/sample space and random variable.html",
    "title": "확률론 용어정리",
    "section": "",
    "text": "Experiment and trial\n가능한 결과들이 미리 정해져있고 무한히 반복가능한 과정을 확률실험(experiment) 또는 시행(trial)이라고 합니다.\n\n\nsample space & event\n어떤 임의의 시행을 가정해본다고 합시다. 시행으로부터 나올 수 있는 모든 결과들의 집합을 우리는 표본공간(sample space)라고 합니다. 사건은 표본공간이라는 집합의 부분집합입니다. 여러개의 원소(결과)들이 모여서 하나의 사건이 될 수 있으며 단 하나의 원소로도 사건이 될 수 있습니다. 시행의 결과가 어떠한 사건(부분집합)에 속하는 경우 우리는 “~인 사건이 발생했다!”라고 표현합니다.\n\n\nrandom variable\n확률변수는 확률실험 또는 시행으로부터 나올 수 있는 결과를 대신 나타내는 변수입니다. 시행을 하기전까지는 그 값이 정해지지 않고 확률분포만 존재하며 시행을 하면 확률분포에 의해서 결과가 정해지고 실수가 부여됩니다. 수학적으로는 표본공간의 원소를 정의역으로 하여 실수를 대응시키는 “함수”입니다.\n\n\nprobability distribution(function)\n확률분포(확률함수)란 확률변수가 취할 수 있는 실수값에 각각의 실수를 취할 가능성인 확률 또는 확률밀도를 대응시키는 함수입니다.\n\n\n예시\n동전을 두번 던지는 시행을 3번 반복하여 크기가 3인 표본을 얻었다고 가정해봅시다. 동전의 앞면을 H(head)라 하고 뒷면을 T(tail)이라고 할 때 표본공간은 다음과 같습니다.\n\\[\\Omega = \\{HH,HT,TH,TT\\}\\]\n표본공간에 있는 결과들 중에서 동전의 앞면이 1개라도 있는 경우 사건A 동전의 앞면이 하나도 없는 경우를 사건B라 합시다. 사건A와 B는 다음과 같습니다.\n\\[A = \\{HH,HT,TH\\},B=\\{TT\\}\\]\n\\(X_1,X_2,X_3\\)는 각각 첫번째 두번째 세번째 시행의 결과를 나타내는 변수이며 확률분포는 다음과 같다고 합시다.\n\n\n\n                                                \n\n\n위의 확률분포를 반영하여 시행의 결과가 결정됩니다. 시행으로부터 얻은 표본은 \\((1,1,0)\\)이며 \\(X_1 = 1 ,X_2 =1 ,X_3 =0\\) 입니다. 시행의 결과 얻은 실제로 관찰된 표본은 \\((x_1,x_2,x_3)\\) 이런식으로 각각의 원소를 소문자인 미지수로 표현할 수도 있습니다.\n\n\ni.i.d & randomsample & realization\n위의 동전던지기 실험에서 각각의 확률변수는 이전에 던진 결과가 이후에 던지는 결과에 영향을 미치지 않고(즉,확률분포에 영향을 미치지 않고) 동일한 분포를 따르는 확률분포였습니다. 이와 여러개의 확률변수가 서로간에 독립이며 동일한 분포를 따르는 확률변수들을 Independent and identically distributed random variables라고 합니다. 위의 분포는 베르누이 분포를 따르므로 다음과 같이 표현할 수 있습니다.\n\\[X_1,X_2,X_3 \\overset{i.i.d}{\\sim} \\text{Bernoulli(p = 0.7)}\\]\nrandomsample은 i.i.d인 여러개의 확률변수의 모음입니다. \\(X1,X2,X3\\)를 말합니다.\nrealization은 관찰된 결과 각각을 말합니다. \\(x1\\)도 realization \\(x2\\)도 realization \\(x3\\)도? 모두 realization입니다. \\(x1,x2,x3\\)를 모아서 확률변수 \\(X_1,X_2,X_3\\)의 realizations이라고 합니다.\n\n\n참고자료\nwikipedia - Experiment (probability theory) StackExchange - What is the difference between random variable and random sample? wikipedia - i.i.d 정보통신기술용어해설"
  },
  {
    "objectID": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html",
    "href": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html",
    "title": "파이썬 - 변수,할당문,인터닝",
    "section": "",
    "text": "파이썬 변수,할당문,인터닝\n전북대학교 최규빈 교수님의 딥러닝 deepcopy-shallowcopy 특강 중,변수와 할당문 부분을 재구성한 글입니다."
  },
  {
    "objectID": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#파이썬에서의-변수",
    "href": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#파이썬에서의-변수",
    "title": "파이썬 - 변수,할당문,인터닝",
    "section": "파이썬에서의 변수",
    "text": "파이썬에서의 변수\n\n파이썬의 변수는 메모리상에 저장된 객체를 참조(reference)합니다.\n따라서 변수는 자바에서 참조변수와 같습니다.\n변수는 객체(object)를 부르는 별칭(다른이름),객체에 붙여진 포스트잇,또다른 레이블 이라고 생각하는 것이 비유적으로 맞습니다.\n앞으로 객체에 접근하기 위해서는 a라는 변수(별칭,객체)를 찾으면 됩니다.\n마치 C언어의 포인터와 유사하게 동작합니다."
  },
  {
    "objectID": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#파이썬에서의-할당문",
    "href": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#파이썬에서의-할당문",
    "title": "파이썬 - 변수,할당문,인터닝",
    "section": "파이썬에서의 할당문(=)",
    "text": "파이썬에서의 할당문(=)\n\n=은 파이썬(뿐만아니라 대부분의 프로그래밍언어)에서 할당문입니다.\n할당문을 실행하면 = 오른쪽에 있는 객체를 먼저 메모리 상에 생성하거나 가져옵니다.\n=의 왼쪽에는 변수가 존재하며 파이썬은 변수에 생성된 객체를 할당합니다.\n변수는 객체에 붙여지는 별칭,레이블로 표현할 수 있습니다. 이렇게 객체에 변수가 할당되고나면 할당된 변수와 객체에 대해서 “변수가 객체에 바인딩(묶이다)되어있다”고 표현합니다.\n\n\na = [1,2,3]\nprint(id(a))\n\n1819154486912\n\n\n위 코드에서 객체[1,2,3]에 변수 a가 바인딩 되었습니다.내부동작은 다음과 같습니다. 1. 메모리 주소(1819161042880)에 리스트 객체[1,2,3]을 생성합니다 2. 생성된 리스트객체를 변수 a에 할당합니다. a는 객체[1,2,3]에 붙여지는 별칭,레이블이라고 할 수 있습니다.\n\n에일리어싱\n에일리어싱은 하나의 객체를 여러개의 변수가 참조하게 하는 것입니다. 하나의 객체에 여러개의 별칭,별명,레이블을 붙이는 것이라고도 할 수 있습니다.\n\nb = a\nprint(id(a));print(id(b))\nprint(a);print(b)\n\n1819154486912\n1819154486912\n[1, 2, 3]\n[1, 2, 3]"
  },
  {
    "objectID": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#idvalue",
    "href": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#idvalue",
    "title": "파이썬 - 변수,할당문,인터닝",
    "section": "id,value",
    "text": "id,value\nid는 객체가 가지는 메모리상의 고유한 주소입니다. 서로다른 객체는 다른 값을 가질수도 같은값을 가질수도 있습니다.\n\na=[1,2,3]\nb=a\na.append(4)\nc=[1,2,3,4]\nprint(f'a:{a} b:{b} c:{c}')\nprint(f'id(a):{id(a)},id(b):{id(b)},id(c):{id(c)}')\n\na:[1, 2, 3, 4] b:[1, 2, 3, 4] c:[1, 2, 3, 4]\nid(a):1819154849280,id(b):1819154849280,id(c):1819155097408\n\n\n변수a,b,c는 모두 같은 value(값)을 가집니다.a와b는 같은 객체에 바인딩되어있지만 c는 또다른 객체에 바인딩되어 있습니다."
  },
  {
    "objectID": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#is-vs",
    "href": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#is-vs",
    "title": "파이썬 - 변수,할당문,인터닝",
    "section": "is vs ==",
    "text": "is vs ==\n- is는 객체비교연산자로 두 변수가 동일한 객체를 참조하는지 아니면 다른객체를 참조하는지 확인한 후 True or False를 반환합니다. 파이썬은 내부적으로 동일한 객체인지 아닌지를 판단할때에는 메모리주소를 확인한다고 합니다. - ==는 값비교연산자로 두 변수가 참조하는 객체의 값이 같은지 아니면 값이 다른지를 확인한 후 True or False를 반환합니다. - 참조하다는 뭔가 잘 와닿는데 참조`라는 용어는 잘 와닿지가 않습니다…변수가 참조하는(또는 가리키는,지칭하는)객체(object) 그 자체입니다.\n\ncode1\n\na=[1,2,3] #1\nprint(\"append하기 전 id(a):\",id(a))\nb=a #2 에일리어싱,동일한 객체를 가리키도록 함.\na.append(4) #3\nc=[1,2,3,4] #4\nprint(f'a:{a} b:{b} c:{c}')\nprint(f'id(a):{id(a)},id(b):{id(b)},id(c):{id(c)}')\nprint(\"a의 참조(reference)와 b의 참조는 동일한 객체인가요??\",a is b)\nprint(\"a의 참조와 b의 참조는 값(value)이 같나요?\",a == b)\nprint(\"a의 참조(reference)와 c의 참조는 동일한 객체인가요??\",a is c)\nprint(\"a의 참조와 c의 참조는 값(value)이 같나요?\",a == c)\n\nappend하기 전 id(a): 1819155097408\na:[1, 2, 3, 4] b:[1, 2, 3, 4] c:[1, 2, 3, 4]\nid(a):1819155097408,id(b):1819155097408,id(c):1819155103296\na의 참조(reference)와 b의 참조는 동일한 객체인가요?? True\na의 참조와 b의 참조는 값(value)이 같나요? True\na의 참조(reference)와 c의 참조는 동일한 객체인가요?? False\na의 참조와 c의 참조는 값(value)이 같나요? True\n\n\n코드설명 1. 변수a에 [1,2,3]을 할당합니다.a는 [1,2,3]을 참조합니다. 2. 에일리어싱으로 변수b도 [1,2,3]을 참조합니다. 3. 변수a가 참조하는 리스트객체[1,2,3]에 4를 추가합니다. 4. 변수c에 [1,2,3,4]를 할당합니다.\n\n\ncode2 - 살짝 심화\n\na=[1,2,3] #1\nprint(\"재할당 하기 전 id(a):\",id(a))\nb=a #2에일리어싱,동일한 객체를 가리키도록 함\na=[1,2,3]+[4] #3재할당\nc=[1,2,3,4] #4\nprint(f'a:{a} b:{b} c:{c}')\nprint(f'id(a):{id(a)},id(b):{id(b)},id(c):{id(c)}')\nprint(\"a의 참조(reference)와 b의 참조는 동일한 객체인가요??\",a is b)\nprint(\"a의 참조와 b의 참조는 값(value)이 같나요?\",a == b)\nprint(\"a의 참조(reference)와 c의 참조는 동일한 객체인가요??\",a is c)\nprint(\"a의 참조와 c의 참조는 값(value)이 같나요?\",a == c)\n\n재할당 하기 전 id(a): 1819155102592\na:[1, 2, 3, 4] b:[1, 2, 3] c:[1, 2, 3, 4]\nid(a):1819184303168,id(b):1819155102592,id(c):1819184334272\na의 참조(reference)와 b의 참조는 동일한 객체인가요?? False\na의 참조와 b의 참조는 값(value)이 같나요? False\na의 참조(reference)와 c의 참조는 동일한 객체인가요?? False\na의 참조와 c의 참조는 값(value)이 같나요? True\n\n\n코드설명 1. 변수a에 [1,2,3]을 할당합니다.a는 [1,2,3]을 참조합니다. 2. 에일리어싱으로 변수b도 [1,2,3]을 참조합니다. 3. 변수a에 리스트객체[1,2,3,4]를 재할당합니다. 4. 변수c에 [1,2,3,4]를 할당합니다.\na,b,c 각각의 값은 code1과 code2에서 모두 같습니다. 차이점은 code1에서는 a가 참조하는 리스트[1,2,3]에 4를 추가하고 code2에서는 a에 리스트[1,2,3,4]를 재할당한다는 점입니다.중요한 차이점은 다음과 같습니다.\n- code1에 append전 후의 a가 참조하는 객체는 주소는 변하지 않은 것으로 보아 동일한 객체에 원소만 추가되었음을 알 수 있습니다. - 반면 code2에서 할당문 전 후의 a가 참조하는 객체의 주소가 변합니다. - 이전에 없었던 1)객체가 메모리에 생성되고 2)변수a는 이전의 [1,2,3]을 더 이상 참조하지 않고 생성된 객체[1,2,3,4]를 참조**하는 것을 알 수 있습니다."
  },
  {
    "objectID": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#인터닝",
    "href": "posts/python/(1) allocation,variable,interning/python - allocation,variable,interning.html#인터닝",
    "title": "파이썬 - 변수,할당문,인터닝",
    "section": "인터닝",
    "text": "인터닝\n인터닝이란 이미 생성된 객체를 재사용하는 것을 말합니다. 객체의 빠른 재사용을 가능하게 하며 메모리를 절약한다고 합니다. 내부적으로는 다음과 같이 구현됩니다. 1. 임의의 할당문을 실행합니다. 2. = 오른쪽에 있는 객체가 Intern 컬렉션에 등록되어 있는지 아닌지 확인합니다. 3. 등록되어 있는 객체의 경우 그 객체를 그대로 참조합니다. 등록되지 않은 경우 메모리에 객체를 생성하며 변수는 생성된 객체의 주소를 참조합니다\n자주 사용하는 객체의 경우 직접 Intern 컬렉션에 등록할 수 있고 빠르게 재사용할 수 있습니다. -5~256사이의 정수이거나 20자 미만의 문자열은 할당문을 실행하면 자동으로 Inter 컬렉션에 등록됩니다. 따라서 해당하는 정수나 문자열을 또다른 할당문에 실행하면 변수는 같은 객체를 참조합니다.\n예제1-인터닝 X\n\na=1+2021\nb=2023-1\nc=2022\nprint(id(a),id(b),id(c))\nprint(a,b,c)\n\n1819155040400 1819155039600 1819155040688\n2022 2022 2022\n\n\na,b,c는 서로다른 객체를 참조하며 객체들은 모두 같은 값을 가집니다.\n예제2-인터닝 O\n\na=1+2 \nb=4-1\nc=3\nprint(id(a),id(b),id(c))\nprint(a,b,c)\n\n1819075897712 1819075897712 1819075897712\n3 3 3\n\n\na,b,c는 모두같은 객체를 참조합니다. 내부적인 동작은 다음과 같습니다. 1. a=1+2 할당문을 실행합니다. 2. 할당되는 객체가 -5~256사이의 정수이므로 자동으로 Intern 컬렉션에 등록됩니다. 3. b와c에도 정수 3을 할당합니다. 3은 Intern 컬렉션 등록되어있는 객체이며 메모리상에 생성되어있는 객체이므로 새로운 3객체가 생성되지 b,c는 이미 생성된 3객체를 가리킵니다.\n참고링크1 : https://guebin.github.io/DL2022/posts/Appendix/2022-12-14-A1.html 참고링크2 : http://pythonstudy.xyz/python/article/512-%ED%8C%8C%EC%9D%B4%EC%8D%AC-Object-Interning"
  },
  {
    "objectID": "posts/RL/Bellman Equation(번외).html",
    "href": "posts/RL/Bellman Equation(번외).html",
    "title": "Bellman Equation",
    "section": "",
    "text": "\\[\\begin{aligned}\nv_{\\pi}(s) &= \\mathbb{E}[G_t|S_t = s]\\\\\n&= \\sum_{g_t}p(g_t|s)g_t \\\\\n&= \\sum_{g_t}\\sum_{a}p(g_t,a|s)g_t\\\\\n&= \\sum_{g_t}\\sum_{a}p(g_t|s,a)p(a|s)g_t\\\\\n&= \\sum_{a}p(a|s)\\sum_{g_t}p(g_t|s,a)g_t \\\\\n&= \\sum_{a}Pr(A_t=a|S_t=s)\\mathbb{E}[G_t|S_t=s,A_t=a] \\\\\n&= \\sum_{a}\\pi(a|s)q_{\\pi}(s,a)\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/RL/Bellman Equation(번외).html#optimal-state-value-function",
    "href": "posts/RL/Bellman Equation(번외).html#optimal-state-value-function",
    "title": "Bellman Equation",
    "section": "Optimal state value function",
    "text": "Optimal state value function\n\\[\\begin{aligned}\nv_{*}(s) = \\underset{\\pi}{\\text{max}}\\,v_{\\pi}(s) , \\forall s \\in S\n\\end{aligned}\\]\n각각의 모든 state에서 모든 policy를 고려했을때 state-value function의 max값을 함숫값으로 가지는 함수이다. 이때 함숫값(max값)은 optimal policy에 의한 값이다."
  },
  {
    "objectID": "posts/RL/Bellman Equation(번외).html#optimal-state-value-function-1",
    "href": "posts/RL/Bellman Equation(번외).html#optimal-state-value-function-1",
    "title": "Bellman Equation",
    "section": "Optimal state value function",
    "text": "Optimal state value function\n\\[\\begin{aligned}\nq_{*}(s,a) = \\underset{\\pi}{\\text{max}}\\,q_{\\pi}(s,a),\\, \\forall s \\in S,\\forall a \\in A(s)\n\\end{aligned}\\]\n각각의 모든 state-action pair에서 모든 policy를 고려했을때 action-value function의 max값을 함숫값으로 가지는 함수. 이때 함숫값(max값)은 마찬가지로 optimal policy에 의한 값이다."
  },
  {
    "objectID": "posts/RL/Bellman Equation(번외).html#optimal-policy",
    "href": "posts/RL/Bellman Equation(번외).html#optimal-policy",
    "title": "Bellman Equation",
    "section": "Optimal policy",
    "text": "Optimal policy\n\nIf \\(v_{\\pi}(s) \\geq v_{\\pi'}(s)\\) for all \\(s \\in S\\) then we say \\(\\pi\\) is better than or equal to \\(\\pi'\\).\nThere is always at least one policy that is better than or equal to all othere policies => 다른 모든 정책들과 비교했을때 모든 state에서 value 같거나 더 나은 policy는 최소 한 개 이상 존재한다. 이러한 policy들을 모두 optimal policy라고 하며 \\(\\pi_*\\) 로 표기한다.\noptimal policy는 여러개일 수 있다.\noptimal policy들은 모두 동일한 optimal state value function과 optimal action value function을 공유한다.\n\n\\[\\begin{aligned}\np(a|s) =\n\\begin{cases}\n1,\\quad a = \\text{argmax}_{a\\in A(s)}q_*(s,a) \\\\\n0,\\quad\\text{else}\n\\end{cases}\n\\end{aligned}\\]\noptimal policy \\(\\pi_*\\)는 state-value function이 모든 s에서 다른 모든 policy들 보다 높거나 같은 값을 가지는 함수이다. 즉,다음과 같다.\nstate-value function은 action-value function으로 표현하는 Bellman equation에 의해 아래처럼 표현할 수 있었다.\n\\[\\begin{aligned}\nv_{\\pi}(s) &= \\sum_{a}\\pi(a|s)q_{\\pi}(s,a)\\\\\n&= \\sum_{a}p(a|s)q_{\\pi}(s,a)\n\\end{aligned}\\]\n\\(v_{\\pi}(s)\\)를 maximize하는 policy는 어떻게 구해야 할까? 먼저 optimal action value function을 구했다고 가정해보자.(실제로 나중에 이를 추정하는 방법이 나온다.)\noptimal action value function을 구했다는 것은 뭘까? optimal action value function은 agent가 어떤 state,action pair를 선택했을때 여러가지 policy를 다 고려해봐서 return(미래에 받을 reward의 총합)의 최댓값을 돌려준다. 즉, agent가 state에서 action을 선택했을 때 가장 많이 받을 수 있는 return이다.\n예시를 들어보자. 임의의 state \\(s\\)에서 가능한 action의 집합을 \\(A(s)= \\{a_1,a_2,a_3,a_4\\}\\)이고 optimal action value function의 값이 다음과 같다고 하자.\n\\[\\begin{aligned}\n&q_{*}(s,a_1) = 4 \\\\\n&q_{*}(s,a_2) = -2 \\\\\n&q_{*}(s,a_3) = 2 \\\\\n&q_{*}(s,a_4) = 9 \\\\\n\\end{aligned}\\]\na1이라는 행동을 하면 가장 많이 return을 받아봤자 4이고 a2행동을 하면 가장 많이 받아봤자 return이 -2로 더 작을것이다. a4를 선택했을때에는 가장많이 받으면 return이 9이므로 a4를 s4에서의 action으로 취하면 가장 합리적일 것이다.\n\\(v_{\\pi}(s)\\)를 maximize하는 policy는 어떻게 구해야 할까? 먼저 state value function자체가 action value function부터 maximize가 되어 있어야 먼저 optimal action value function을 구했다고 가정해보자.(실제로 나중에 이를 추정하는 방법이 나온다.)\n모든 \\(\\pi\\)를 고려했을 때 위의 state-value function을 maximize하는 policy가 optimal policy였다. 다시쓰면 아래와 같다.\n\\[\\pi_* = \\underset{\\pi}{\\text{argmax}}\\,v_{\\pi}(s)\\,,\\forall s\\]"
  },
  {
    "objectID": "posts/RL/RL 1.html",
    "href": "posts/RL/RL 1.html",
    "title": "[강화학습] 1 - 강화학습 용어정리",
    "section": "",
    "text": "강화학습 독학하면서 익숙하지 않거나 모르는 용어들을 정리해놓은 페이지입니다.개선할 부분이 있다면 댓글로 알려주세요..!\n\n 용어정리\n\nagent : 강화학습에서 학습하는 대상(object)를 말한다.\naction : agent가 하는 실제 행동을 말한다. action을 취하면 state가 변화한다.\nstate : agent가 인식하고 있는 자신의 상태이며 action을 취하기 위한 구체적 정보이다.어떠한 action을 취하면 (environment에 의해)변화한다.\nobservation : 실제문제에서 agent는 모든 state를 알기는 불가능하다. agent는 state중 일부정보만을 받는데 이것을 observation이라고 한다.\nreward : agent가 action을 취했을때 받는 보수,보상,값이다. 어떠한 action을 유도하기 위해서는 + 보상을 action을 방지하기 위해서는 -보상을 준다.\nEnvironment  – 1)agent가 놓여있는 world(세계)이다. – 2)agent가 어떤 action을 취하면 state가 변화하는데 이 때 새로운 state를 return해주는 존재를 말한다. – 3)agent가 어떤 행동을 했을때 어떤 보상을 줘야하는지에 대한 setting이다. – 뭔가 직관적으로 이해가 가지 않는다.예시를 들어보자면 말은 안되지만 아주더운 나가기면 하면 땀나는 아프리카 사막에서 1시간 달리는 것과 시원한 헬스장에서 1시간 달리는 것을 비교해보자. 사막에서 달리는게 차원이 다른 힘듦과 체중감량 효과를 줄 것이다. 이는 같은 action을 취해도 서로다른 envirionment가 다른state를 return(제공)해주기에 그렇다. 각각의 환경은 또한 감량에 대하여 서로다른 setting에 의해 reward를 줄것이다.\npolicy  – agent가 어떻게 행동을 해야할지 알려주는 방향,가이드,지표의 느낌이다. 정책라는 의미가 너무 와닿지 않아서 네이버에 검색해보니 개인의 앞으로 나아갈 노선이나 취해야 할 방침라고 한다. (지표의 그냥 어려운 말) – policy는 크게 deterministic policy와 stochastic policy로 나뉜다고 한다. 내가 이해하는대로 쉽게 말해보자면 상황에 따라서 가능한 행동이 단 한가지라면 deterministic(정해져 있는,결정론적인) policy가 있는 것이고 하고 가능한 행동이 여러가지라면 stochastic(안정해져 있는,확률론적인) policy가 있는 것이다.\nreturn  agent는 당장에 받는 reward뿐만 아니라 미래에 받는 reward도 고려해야 한다. return은 현재의 state로부터 미래의 action,state를 전부 고려했을때 내가 미래에 받게 될 discounted reward의 총합,누적합이다. 여기서 discounted가 붙는 이유는 미래에 받게되는 reward에 대해서는 어느정도 discount가 들어가기 때문이다. discount의 양은 discount factor(\\(\\gamma\\))에 의해 결정되는데 이값을 1에 가깝게 할수록 미래에 받는 action 대한 reward의 discount가 커지고 0에 가깝게 할수록 미래의 action에 대한 reward의 discount가 작아진다. 강화학습의 최종 목적은 평균적으로 받는 return이 가장 커지도록(return도 랜덤이기 때문에 평균적으로 커져야 한다.)policy를 학습하는 것이다.\nexploration 현재 agent가 가지고 있는 사전지식,경험을 버리고 틀을깨어 새로운 방식으로 action하여 보는 것을 의미한다. 랜덤한 확률(\\(\\epsilon\\))로 policy를 거슬러서 다른 모든 액션중에 랜덤한 하나의 action을 취하게 된다. locacl optima에서 벗어나 최적의 policy를 탐색할 더 많은 기회를 제공한다.\nexploitation 현재 agent가 가지고 있는 사전지식,경험을 최대한 활용하여 action을 취하는 것을 말한다.\nexploration exploitation trade off 너무 exploitation만 할 경우 사전지식만을 가지고 action하여 더 좋은 policy를 찾지 못하고 너무 exploration 위주인 경우 사전지식은 활용하지 않게되고 학습이 더디게 진행된다.\n\n비유적으로 생각해보자.만약에 내가 엄청 살이찐 상태(state)에서 나 자신을 강화학습?한다고 하자. 2달동안 살을 빼는 것을 목적으로 하고 BMI수치가 좋아지면 reward를 받는다고 하자.나(agent)는 여러가지 운동(action)을 해볼 수 있다. 처음에는 조금 힘드니까 쉬운 운동(걷기?숨쉬기..)정도 하지만 이렇게 하면 나는 절대로 몸무게가 빠지지 않거나 오히려 더 찌는 상황(state)이 발생할 수 있다.(reward가 0이거나 오히려 -reward)\n이렇게 될 경우 해야할 운동의 방향(policy)에 대해 다시 생각해본다. 생각해봤더니 걷기,달리기,근력운동,굶기 같은 더 좋은 방법,운동들이 있었고 이번에는 그러한 방법들을 실천해본다. 이러한 경우들 모두 BMI수치가 개선되어 더 좋아졌는데 그런데 굶기의 경우 당장에 가장 많이 BMI수치가 개선되어 앞으로도 이 방법만 선택한다고 해보자. BMI수치는 근육량도 고려하기 때문에 장기적으로 볼때 굶기만 한다면 몸무게가 빠지긴 하는데 결국에는 근육만 다 빠져서 결국에는 몸이 안좋아질 것이다.(reward의 합인 return을 고려하는 이유!) 그러므로 굶는 방법은 어느정도 자제하고 걷기,뛰기,근력운동하기 위주로 내가 운동해야할 방향이 결정된다.\n\n\nexploration exploitation tradeoff\n살을 빼고 있는데 어느날 갑자기 친구가 내가 정한 운동시간 말고 같이 운동하자고 했다. 근데 나는 여태까지 밤에 산책하는게 좋았기에 (밤에 산책하기가) 거절한다고 하면 이건 exploitation 위주로 학습을 하는 것이다. 이와는 다르게 낮에 친구의 제안을 받아들여 같이 헬스장으로 운동하러 가는거면 이는 exploration위주로 학습을 해봤다고 할 수 있다. 중요한 점은 이 둘 사이에는 tradeoff가 있다는 것이다. 너무 exploitation만 하면 더 좋은 방법(친구가 잘 맞으면 최종적으로는 더 운동을 많이하게 되어 BMI가 낮아질 것이다.)을 놓치게 되고 너무 exploration만 할 경우는(여러명의 친구에게 제안이 왔다면 그 친구중에는 운동은 별로안하는데 끝나고 같이치킨먹는 좋은?친구도 있다.)학습을 더디게 한다. 이러한 tradeoff가 있어서 결국에 2달동안 최대한 살을 많이 빼려는 궁극적인 목적을 이루려면 이 둘 사이의 tradeoff를 잘 조절하는 것이 중요한 요소이다.\n롤로 비유하는 것도 가능하다. 최종적으로 새롭게 시작되는 2023시즌에 챌린저를 가는게 목표라고 하자. 하던챔만 계속하는 것이 exploitation이고 다른챔도 해보는게 exploitation이다. 하던챔만 하면 나는 모르지만 내가 재능을 가진 챔피언을 영원히 모를수도 있고 재능을 가진 챔피언을 찾고자 새로운 챔피언만 계속하다보면 경험치가 잘 쌓이지 않고 학습이 더디게 된다. 여기서도 마찬가지로 2023 - 챌린저라는 목표를 이루기 위해서는 둘 사이의 tradeoff를 적절히 조절하는게 중요하다.\n\n\n 참고자료\n나무위키 - 강화학습용어정리\nFundamental of Reinforcement Learning - 이웅원님 깃북\nMLI\n내가 보려는 기술 블로그"
  },
  {
    "objectID": "posts/RL/RL 2 - MDP.html",
    "href": "posts/RL/RL 2 - MDP.html",
    "title": "[강화학습] 2-1 Markov Decision process and property",
    "section": "",
    "text": "Markov Decision Process\n자기전에 스타를 했더니 상대방에게 핵을 맞았다고 하자…\n\n나는 왜 핵을 맞았을까? 게임안에서 주어지는 여러가지 state에서 action을 취했을 때 가능한 여러가지 결과 중 하나가 나에게 돌아온 것이다.\n조건부 확률과 용어를 빌리면 action들과 state들에 대한 조건이 주어져 있을때 state에 대한 조건부확률분포(conditional distribution)에서 하나의 event가 sample로 뽑힌 것이다.(여기서는 핵을 맞는 사건이 뽑힌것이다.)\n\\[p_{S_t|S_0,A_0\\dots,S_{t-1}A_{t-1}}(s_t|s_0,a_0,\\dots,s_{t-1},a_{t-1})\\]\n이와 비슷하게 내가 핵을 맞기전에 취할 수 있는 판단도 여러가지며 또한 취하는 판단의 근거도 마찬가지로 이전의 상황과 내가 취한 판단에 의해 결정되었을 것이다. action과 state들이 주어졌을때 취할 수 있는 action에 대한 조건부 확률분포는 다음과 같다.\n\\[p_{A_t|S_0,A_0,\\dots,S_{t-1},A_{t-1}}(a_t|s_0,a_0,\\dots,s_t)\\]\n위의 내용은 일반적으로 우리가 생각하는 직관과 일치하는 경우이다. 하지만 (지금까지 연구된)강화학습의 경우 이와는 다르게 Markov Decision Process를 가정한다. 그렇다면 Markov decision process란 뭔가? 위키피디아의 정의에 의하면 “각 사건에 대한 확률이 사건으로부터 얻은 상태에만 의존하는 일련의 가능한 이벤트를 설명하는 확률적 모델”이라고 적혀있다. 강화학습이 MDP를 따르므로 다시 말하자면 현재 내가 놓인 상황(의 확률분포)이나 현재 내가 하는 액션(의 확률분포)은 바로 이전의 상태나 행동의 영향만을 받는다는 것이다. MDP가 따르는 이러한 특성을 Markov property라고 한다.\n\\[\\begin{aligned}\n&\\text{Markov property}\\\\\n&\\forall{t,}\\,\\,p_{\\small{S_t|S_0,A_0\\dots,S_{t-1}A_{t-1}}}(s_t|s_0,a_0,\\dots,s_{t-1},a_{t-1}) = p_{\\small{S_t|S_{t-1}},A_{t-1}}(s_t|s_{t-1},a_{t-1})\\\\\n&\\forall{t,}\\,\\,p_{\\small{A_t|S_0,A_0,\\dots,S_{t-1},A_{t-1}}}(a_t|s_0,a_0,\\dots,s_t)=p_{\\small{A_t|S_{t}}}(a_t|s_t)\n\\end{aligned}\\]\n첫번째 확률은 상태\\(s_{t-1}\\)에서 (\\(a_{t-1}\\)을 취하여) \\(s_{t}\\)로 transition(변할때)에 대한 확률분포이므로 transition probability라고 부른다. 두번째 확률은 policy(정책,지표)로 어떤 상황에서 어떤 액션을 취할지에 대한 기준이 되는 확률분포이다.(후에 optimal policy에 대해 자세히 다룬다.)\n\n\ntransition probability\n\\[\\begin{aligned}\n&\\text{definition of transition probability}\\\\\n&p_{\\small{S_t|S_{t-1}},A_{t-1}}(s_t|s_{t-1},a_{t-1})\\\\\n\\end{aligned}\\]\n\n위와 같은 그림을 살펴보자.왼쪽로봇의 경우 Deterministic Grid World(=Envirion ment)에 놓여있고 앞으로 가는 action을 취할 경우 반드시 앞으로 가므로 state가 결정적(deterministic)이라고 할 수 있다.반면에 오른쪽로봇의 경우 Stochastic Grid World에 놓여있다.이러한 경우에는 action을 취해도 3가지 상황에 취해질 수 있으며 이 경우 state는 Stochastic하다고(바람의 영향이나,로봇이 오작동하거나)할 수 있다.다시말하면 state는 확률분포에 따라 임의적(randomly)이다.\n\n\nPolicy\n정책\\(\\pi(a_t|s_t)\\)는 어떤 상태가 주어질때 어떤 행동을 취할 것인지 명시한 (조건부)확률분포를 말한다.\n\\[\\begin{aligned}\n&\\text{definition of poilcy} \\\\\n&{\\pi}({a_t,s_t}) \\overset{\\Delta}{=}p_{A_t|S_{t}}(a_t|s_t)\n\\end{aligned}\\]\n아래와 같은 그림을 보자 초기 state는 파랑색 위치이며 agent는 왼쪽위나 오른쪽아래의 종료지점까지 가야한다.\n\n\n왼쪽위의 그림에서 모든 policy는 다음과 같다.\n\\[\\begin{aligned}\n\\forall{t},\\pi(a_t,s_t) = p_{\\small{A_t|S_t}}(a_t|s_t) =\n\n\\begin{cases}\np_{\\small{A_t|S_t}}(\\text{right}|s_t) = \\frac{1}{4}\\\\\np_{\\small{A_t|S_t}}(\\text{left}|s_t) = \\frac{1}{4}\\\\\np_{\\small{A_t|S_t}}(\\text{up}|s_t) = \\frac{1}{4}\\\\\np_{\\small{A_t|S_t}}(\\text{down}|s_t) = \\frac{1}{4}\\\\\n\n\\end{cases}\n\n\\end{aligned}\\]\n각각의 state에서 action은 위와 같은 policy를 따르므로 아래와 같은 경로가 예제해로 나올 수 있다.\n왼쪽에서 두번째 있는 그림의 모든 policy는 다음과 같다.\n\\[\\begin{aligned}\np_{\\small{A_t|S_t}}(a_t|s_t)=\n\\begin{cases}\n\\frac{1}{4} \\text{  if } a_t = \\text{down} \\\\\n0\\text{ otherwise}\n\\end{cases}\n\\end{aligned}\\]\n위와 같은 policy를 따르므로 모든 state에 대해서 남쪽방향으로만 나온다.\n오른쪽에서 두번째 그림의 policy는 다음과 같다.\n\n가장 오른쪽 그림의 policy는 다음과 같다.\n\n생각해보면 가장오른쪽 위 사각형같은 policy가 정해지면 가장 빠르게 목표에 도달할 수 있다. 이는 최고의 reward를 받도록 학습된 결과이다.\n\n\n정리\n\n강화학습은 MDP를 가정한다. 이는 이전 state나 액션에 의해서만 확률분포가 영향을 받는다는 것이다.\npolicy는 임의의 state에 취한 action의 확률분포함수로 어떤 action을 할지는 이것에 의해 결정된다.\n\n\n\n참고자료\n위키피디아 - markov chain(=markov process) 혁펜하임-[강화학습] 2-1강. Markov Decision Process (MDP) 쉬운 설명 Fundamental of Reinforcement Learning wordbe"
  },
  {
    "objectID": "posts/RL/RL2-2 value function.html",
    "href": "posts/RL/RL2-2 value function.html",
    "title": "[강화학습] 2-2 Reward & Return & State Value f & Action Value f",
    "section": "",
    "text": "리워드의 정의는 다음과 같다.\n\\[\\mathcal{R}_{t+1} \\overset{\\Delta}{=} \\mathbb{E}({R}_{t+1}|S_t=s,A_t=a)\\]\n이는 \\(s_t\\)에서 \\(a_t\\)를 했을때 t+1에서 얻는 값을 나타내는 확률변수\\(R_{t+1}\\)의 기댓값이다.이다.\n알파고를 예를 들어서 생각해보자. 알파고가 바둑판에(\\(s_t\\))에 검은돌을 놓으면(\\(a_{t}\\)) 상대하는 사람(또는기계)도 어떤 위치에 흰돌을 놓을것이다. 이 흰돌의 위치는 random이기 때문에 따라서 알파고가 확률변수 \\(R_{t+1}\\)이 존재하며 그것의 평균값을 리워드\\(\\mathcal{R}_{t+1}\\)로 정의한다.\n생각해보면 리워드는 뭔가 \\(s_t\\)에서 \\(a_t\\)를 해서 변하는 상황 \\(s_{t+1}\\)에 부여되는게 맞을 것 같다.찾아보니 위키피디아에는 reward를 \\(R_a(s,s')\\)로 쓴다. 변하는 상황에 따라 부여되는것도 맞고 어떤 액션을 취하면 그것에 상응한다고 봐도 무방할 것 같다.(개인적인 의견입니다.)\n그냥 \\(R_{t+1}\\)을 리워드라 하는 경우도 많은 것 같다\n\n\n\n\n\n\nNote\n\n\n\n위에서 인식하는 상황이라고 썼는데 사실 state는 agent가 인식하는 것이 아니라 사실은 environment에가 반환(return)하는 것입니다. agent는 state중 일부를 받는데 이것을 observation이라고 합니다. 그러나 실제 논문에서는 딱히 state와 observation을 구별하지않고 쓰는 경우가 많다고 합니다."
  },
  {
    "objectID": "posts/RL/RL2-2 value function.html#state-value-function",
    "href": "posts/RL/RL2-2 value function.html#state-value-function",
    "title": "[강화학습] 2-2 Reward & Return & State Value f & Action Value f",
    "section": "state value function",
    "text": "state value function\n\nThe value function of a state \\(s\\) under a policy \\(\\pi\\) is the expected return when starting \\(s\\) and following \\(\\pi\\) thereafter. \\(\\leftrightarrow\\) policy \\(\\pi\\)를 따를때 state \\(s\\)의 value function은 state \\(s\\)에서 시작하여 그 후 \\(\\pi\\)를 따를때 return의 기댓값이다.\n각각의 상태가 얼마나 좋은지 그 가치를 expected return으로 계산한 함수이므로 state value function이라는 이름이 붙었다.\n단,\\(s\\)에서 시작하다는 조건하에서의 기댓값이므로 \\(s\\)가 given인 conditional expectation을 구하면 된다.\n\n\\[v_{\\pi}\\overset{\\Delta}{=} \\mathbb{E}_{\\pi}[G_t|S_t=s] = \\mathbb{E_{\\pi}}\\left[{\\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}|S_t=s}\\right],\\text{for all s } \\in S\\]"
  },
  {
    "objectID": "posts/RL/RL2-2 value function.html#action-value-function",
    "href": "posts/RL/RL2-2 value function.html#action-value-function",
    "title": "[강화학습] 2-2 Reward & Return & State Value f & Action Value f",
    "section": "action value function",
    "text": "action value function\n\nSimilary, we define the value of taking action \\(a\\) in state \\(s\\) under a policy \\(\\pi\\) as the expected return starting from s,taking action a,and thereafter following policy \\(\\pi\\) \\(\\leftrightarrow\\) 유사하게 policy \\(\\pi\\)를 따르고 state \\(s\\)에서 action \\(a\\)를 취하는 것의 가치는 state \\(s\\)에서 시작하여 action \\(a\\)를 취하고 그 후 \\(\\pi\\)를 따를때의 기댓값으로 정의할 수 있다.\n각각의 state에서 action을 취했을때 그 가치를 expected return으로 측정하므로 action value function이라는 이름이 붙었다.\n여기서는 state s에서 action a를 취한것에 대한 기댓값을 계산하므로 given s,a일때의 conditional expectation of return을 구하면 된다.\n\n\\[q_{\\pi}(s,a) \\overset{\\Delta}{=} \\mathbb{E}[G_t|S_t = s,A_t = a] = \\mathbb{E}_{\\pi}\\left[\\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}|S_t=s,A_t=a\\right]\\]"
  },
  {
    "objectID": "posts/RL/RL2-2 value function.html#recursive-relationships",
    "href": "posts/RL/RL2-2 value function.html#recursive-relationships",
    "title": "[강화학습] 2-2 Reward & Return & State Value f & Action Value f",
    "section": "recursive relationships",
    "text": "recursive relationships\n\nv를 next v로 표현하기\n\nFor any policy \\(\\pi\\) and any state \\(s\\), the following consistency condition holds between the value of \\(s\\) and the value of its possible succesor states \\(\\leftrightarrow\\) 상태 \\(s\\)의 state value function은 다음 상태 \\(s'\\)에 대한 state value function이 포함된 식으로 표현할 수 있다.즉,현재상태의 가치는 다음상태의 가치와 연관과 관련이 있다.\n\n\\[\\begin{align}\nv_{\\pi}(s) &\\overset{\\Delta}{=} \\mathbb{E}_{\\pi}[G_t|S_t=s] \\\\\n&=\\mathbb{E}_{\\pi}[R_{t+1}+\\gamma G_{t+1}|S_t=s] \\\\\n&=\\sum_a \\pi(a|s)\\sum_{s'}\\sum_{r}p(s',r|s,a)\\left[r + \\gamma E_{\\pi}[G_{t+1}|S_{t+1}=s'\\right]]\\\\\n&=\\sum_a \\pi(a|s)\\sum_{s',r}p(s',r|s,a)\\left[r + \\gamma  v_{\\pi}(s')\\right] , \\text{for all } s \\in S\\\\\n\\end{align}\\]\n\n혹시 2에서 3번식으로 넘어가는게 이해가 잘 안된다면 링크를 참고. 핵심은 law of total expectation을 이해하는 것이다.\n이 식이 기억하기가 상당히 어렵다. 따라서 \\(s \\rightarrow s'\\)을 나타낸 \\(v_{\\pi}\\)의 backup diagram을 통해서 생각해볼 수 있다.\n\n\n\n\nbackup diagram of \\(v_{\\pi}\\)\n\n\n\n각각의 흰색원은 state를 검은색원은 state,action pair를 나타낸다.\n상태s에서 시작하며 policy \\(\\pi\\)에 의하여 action을 취한다.\naction을 취하면 리워드\\(r\\)을 얻고 \\(s \\rightarrow s'\\)으로 상태가 바뀌며 이는 transition \\(p(s',r|s,a)\\)에 의해 결정된다.\n\nThe Bellman equation (3.14) averages over all the possibilities, weighting each by its probability of occurring. It states that the value of the start state must equal the (discounted) value of the expected next state, plus the reward expected along the way. \\(\\leftrightarrow\\)즉, 초기상태 \\(s\\)에서 시작하여 나올 수 있는 모든 \\(r,v_{\\pi'}\\)의 경우에 대해 각각이 나올 확률을 곱하여 averaging(expectation)을 구하면 \\(v_{\\pi}(s)\\)라는 것이다.\n\\[\\begin{align}\nv_{\\pi}(s) &= \\sum_{a,s',r}\\pi(a|s)p(s',r|s,a)\\left[r + \\gamma  v_{\\pi}(s')\\right] , \\\\\n&= \\sum_{a}\\pi(a|s) \\sum_{s',r}(s',r|s,a)\\left[r+\\gamma v_{\\pi}(s')\\right] \\,\\text{for all } s \\in S\\\\\n\\end{align}\\]\n개인적으로 좀 더 자세히 기억하려고 정리해봤다.diagram은 수식자체는 아니기 때문에 그림을 보고 나름대로 기억할 수 있는 방법을 찾으면 된다고 생각한다. 따라서 아래와 같이 정리해봤지만 헷갈리면 pass해도 무방하다.\n\n\\(s \\rightarrow s'\\)는 여러가지 경우가 존재하며 그러므로 상태 \\(s\\)의 가치 \\(v_{\\pi}(s)\\)는 다음상태 \\(s'\\)의 가치 \\(v_{\\pi}(s')\\)에 영향을 받는다.\n그런데 \\(s'\\)은 \\(r\\)이 항상 같이 따라오므로 \\(v_{\\pi}(s)\\)는 \\(r+v_{\\pi}(s')\\)에 영향을 받는다.\n상태s에서 a를 취하며 \\(r\\)과 \\(s'\\)이 나올 확률은 policy와 transition의 곱이다. 즉 \\(\\pi(a|s)p(s',r|s,a)\\)이다.\n모든 경우에 대해 고려해야 하므로 모든 \\(a,r,s'\\)에 곱해준다.\n\n\n\nQ를 next Q로 표현하기\n\n마찬가지로 \\(s,a\\)에서의 action value function도 next \\(s',a'\\)에서의 action value function으로 표현할 수 있다.\n\n\\[\\begin{align}\nq_{\\pi}(s,a) &\\overset{\\Delta}{=} \\mathbb{E}_{\\pi}[G_t|S_t=s,A_t=a] \\\\\n&=\\mathbb{E}_{\\pi}[R_{t+1}+\\gamma G_{t+1}|S_t=s,A_t=a] \\\\\n&=\\sum_{s',r}p(s',r|s,a)\\big[r+\\sum_{a'}p(s',r|s,a)\\pi(a'|s')q_{\\pi}(a',s')]\n\\end{align}\\]\n\nbackup diagram은 다음과 같다.\n\n\n\n\nbackup diagram of \\(q_{\\pi}\\)\n\n\n\nbackup diagram을 보고 나올 수 있는 \\(r,q_{\\pi}(s',a')\\)의 모든 경우에 대하여 계산해보면 다음과 같다.(state value function의 \\(r,s'\\)은 같이 따라오므로 같이 계산해줬지만 action value function은 \\(r,a\\)는 따로이므로 따로 계산하여 더해준다.)\n\n\\[\\begin{aligned}\nq_{\\pi}(s,a)&=\\sum_{s',r}p(s',r|s,a)r + \\sum_{s',r,a'}p(s',r|s,a)\\pi(a'|s')q_{\\pi}(a',s')\\\\\n&=\\sum_{s',r}p(s',r|s,a)\\big[r+\\sum_{a'}p(s',r|s,a)\\pi(a'|s')q_{\\pi}(a',s')]\\,\\text{for all } s \\in S,a \\in A(s)\\\\\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/RL/RL2-2 value function.html#optimal-policy",
    "href": "posts/RL/RL2-2 value function.html#optimal-policy",
    "title": "[강화학습] 2-2 Reward & Return & State Value f & Action Value f",
    "section": "optimal policy",
    "text": "optimal policy\noptimal policy는 value function인 \\(V(s_t)\\)를 가장 크게 하는 policy들(\\(p(a_t|s_t),p(a_{t+1}|s_{t+1}),\\dots,p(a_{\\infty}|s_{\\infty})\\))이다.나중에 더 자세히 공부해야할 것 같다.\naction value function은 state,action의 함수의 입력으로 주어지는 어떤 state에서 (마찬가지로 주어지는)action을 취했을때 특정 policy가 좋은지 나쁜지(가치)를 평가한다. 평가는 action을 취한뒤의 다음 state부터 마지막 시점까지 Agent가 가능한 모든 action과 놓여질 수 있는 모든 state를 고려하여 기대되는 보수의 총합을 계산하는방식이다. 이것도 마찬가지로 결국은 \\(G_t\\)에 대한 조건부 함수이다.\n\\[\\begin{aligned}\nQ^{\\pi}(s_t,a_t) \\underset{=}{\\Delta} \\mathbb{E}[G_t|A_t=a_t,S_t=s_t,\\pi] = \\int_{s_{t+1}:a_{\\infty}}G_tp(s_{t+1},\\dots,a_{\\infty})ds_{t+1}:da_{\\infty}\n\\end{aligned}\\]\n\\[\\begin{aligned}\n\\end{aligned}\\]\n\\[\\begin{aligned}\nv_{\\pi}\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/visualization/plotly_visualization/ploty 시각화 모음.html",
    "href": "posts/visualization/plotly_visualization/ploty 시각화 모음.html",
    "title": "plotly 시각화 모음",
    "section": "",
    "text": "Code\n# %pip install plotly (jupyter notebook)\nfrom plotly.offline import iplot\nimport plotly.graph_objs as go\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\npio.renderers.default = \"plotly_mimetype+notebook\"\n\n\n\n\nCode\nimport pandas as pd\ntimesData = pd.read_csv(\"./timesData.csv\")\ntimesData.head(5)\n\n\n\n\n\n\n  \n    \n      \n      world_rank\n      university_name\n      country\n      teaching\n      international\n      research\n      citations\n      income\n      total_score\n      num_students\n      student_staff_ratio\n      international_students\n      female_male_ratio\n      year\n    \n  \n  \n    \n      0\n      1\n      Harvard University\n      United States of America\n      99.7\n      72.4\n      98.7\n      98.8\n      34.5\n      96.1\n      20,152\n      8.9\n      25%\n      NaN\n      2011\n    \n    \n      1\n      2\n      California Institute of Technology\n      United States of America\n      97.7\n      54.6\n      98.0\n      99.9\n      83.7\n      96.0\n      2,243\n      6.9\n      27%\n      33 : 67\n      2011\n    \n    \n      2\n      3\n      Massachusetts Institute of Technology\n      United States of America\n      97.8\n      82.3\n      91.4\n      99.9\n      87.5\n      95.6\n      11,074\n      9.0\n      33%\n      37 : 63\n      2011\n    \n    \n      3\n      4\n      Stanford University\n      United States of America\n      98.3\n      29.5\n      98.1\n      99.2\n      64.3\n      94.3\n      15,596\n      7.8\n      22%\n      42 : 58\n      2011\n    \n    \n      4\n      5\n      Princeton University\n      United States of America\n      90.9\n      70.3\n      95.4\n      99.9\n      -\n      94.2\n      7,929\n      8.4\n      27%\n      45 : 55\n      2011\n    \n  \n\n\n\n\n\n\nCode\ntimesData.info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2603 entries, 0 to 2602\nData columns (total 14 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   world_rank              2603 non-null   object \n 1   university_name         2603 non-null   object \n 2   country                 2603 non-null   object \n 3   teaching                2603 non-null   float64\n 4   international           2603 non-null   object \n 5   research                2603 non-null   float64\n 6   citations               2603 non-null   float64\n 7   income                  2603 non-null   object \n 8   total_score             2603 non-null   object \n 9   num_students            2544 non-null   object \n 10  student_staff_ratio     2544 non-null   float64\n 11  international_students  2536 non-null   object \n 12  female_male_ratio       2370 non-null   object \n 13  year                    2603 non-null   int64  \ndtypes: float64(4), int64(1), object(9)\nmemory usage: 284.8+ KB"
  },
  {
    "objectID": "posts/visualization/plotly_visualization/ploty 시각화 모음.html#add-markers-and-text",
    "href": "posts/visualization/plotly_visualization/ploty 시각화 모음.html#add-markers-and-text",
    "title": "plotly 시각화 모음",
    "section": "add markers and text",
    "text": "add markers and text\n\n\nCode\n#1 data frame\ndf = timesData.iloc[:100]\n\n#2 trace and data\ntrace = go.Scatter(\n    x = df.world_rank,\n    y = df.citations,\n    mode = \"lines+markers\", #add marker,\n    marker = dict(color = \"rgba(16,112,2,0.8)\"),\n    text = df.university_name #add text\n)\ndata = [trace]\n#3 layout and data\nlayout = go.Layout(\n    title = \"citation\",\n    xaxis = dict(title = \"World Rank\",ticklen = 5)\n)\n\n#4 create figure\nfig = go.Figure(data = data,layout = layout)\n\n#5 plot figure\nfig.show()\n\n\n\n                                                \n\n\nversion2가 뭔가 더 좋을듯?"
  },
  {
    "objectID": "posts/visualization/plotly_visualization/ploty 시각화 모음.html#add-markers-and-text-1",
    "href": "posts/visualization/plotly_visualization/ploty 시각화 모음.html#add-markers-and-text-1",
    "title": "plotly 시각화 모음",
    "section": "add markers and text",
    "text": "add markers and text\n\n\nCode\n#1 data frame\ndf2014 = timesData[timesData.year == 2014].iloc[:100,:]\n\n#2 trace,data\ntrace = go.Scatter(\n    x = df2014.world_rank,\n    y = df2014.citations,\n    mode = \"markers\",\n    #marker = dict(color = \"green\",opacity=0.8), #alpha(불투명도) 조절 vs1\n    marker = dict(color = \"rgba(255,128,2,0.8)\"), #alpha(불투명도) 조절 vs2\n    text = df2014.university_name,\n\n)\ndata = [trace]\n\n#3 layout\nlayout = go.Layout(xaxis = dict(title = \"World Rank\"),yaxis = dict(title = \"Citation\"))\n\n#4 create figure\nfig = go.Figure(data=data,layout=layout)\n\n#5 plot\nfig.show()"
  },
  {
    "objectID": "posts/visualization/plotly_visualization/ploty 시각화 모음.html#여러개의-차트-겹처-그리기",
    "href": "posts/visualization/plotly_visualization/ploty 시각화 모음.html#여러개의-차트-겹처-그리기",
    "title": "plotly 시각화 모음",
    "section": "여러개의 차트 겹처 그리기",
    "text": "여러개의 차트 겹처 그리기\n\n여기서는 histogram으로 했으나 다른차트들도 가능\n\n\n\nCode\n#1.dataframe\nx2011 = timesData.student_staff_ratio[timesData.year == 2011]\nx2012 = timesData.student_staff_ratio[timesData.year == 2012]\n#2.trace&data\ntrace1 = go.Histogram(\n    x=x2011,\n    #opacity=0.7, #불투명도 조절\n    name=\"2011\", #범례(legend)를 설정하기 위한 이름 설정\n    marker=dict(color=\"rgb(171,50,96)\",opacity=0.7)\n)\n\ntrace2 = go.Histogram(\n    x=x2012,\n    name=\"2012\",\n    marker=dict(color=\"blue\",opacity=0.7)\n)\ndata=[trace1,trace2]\n#3.layout\nlayout = go.Layout(\n    barmode = \"overlay\", #trace 겹쳐 그리기\n    xaxis=dict(title=\"students-staff ratio\"),\n    yaxis=dict(title=\"count\"),\n    title = dict(text = \"histogram\",x = 0.5)\n)\n#4 figure\nfig = go.Figure(data=data,layout=layout)\nfig.show()\n\n\n\n                                                \n\n\n참고자료 - Opacity와 alpha? : Opacity는 marker안팎에서 모두 쓰일 수 있으며 alpha는 rgba와 쓸때만 입력,같은 역할을 함. 단,Opacity를 marker의 밖에서 입력하면 trace안에서 밀도를 표현 하지 못함. 다른 trace끼리 겹칠때에는 밀도표현됨.(같은 trace에서만 안됨.)\n\n\nCode\n# 1.data frame\ndataframe = timesData[timesData.year == 2015]\n\n#2.trace and data\ndata = []\nfor col in [\"world_rank\",\"citations\",\"income\",\"total_score\"]:\n    _trace = go.Scatter(\n        x = dataframe[\"world_rank\"],\n        y = dataframe[col],\n        mode = \"lines\"\n    )\n    data.append(_trace)\n\n#3. layout\nlayout = go.Layout(\n    xaxis=dict(\n        domain=[0, 0.45]\n    ),\n    yaxis=dict(\n        domain=[0, 0.45]\n    ),\n    xaxis2=dict(\n        domain=[0.55, 1]\n    ),\n    xaxis3=dict(\n        domain=[0, 0.45],\n        anchor='y3'\n    ),\n    xaxis4=dict(\n        domain=[0.55, 1],\n        anchor='y4'\n    ),\n    yaxis2=dict(\n        domain=[0, 0.45],\n        anchor='x2'\n    ),\n    yaxis3=dict(\n        domain=[0.55, 1]\n    ),\n    yaxis4=dict(\n        domain=[0.55, 1],\n        anchor='x4'\n    ),\n    title = 'Research, citation, income and total score VS World Rank of Universities'\n)\n\n#4. fig\nfig = make_subplots(rows=2,cols=2)\n#5. plot\nrow = 1\ncol = 1\nfor trace in data:\n    fig.append_trace(trace,row=row,col=col)\n    col+=1\n    if col > 2:\n        col = 1\n        row+=1\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(\n    rows=2, cols=2,\n    specs=[[{\"type\": \"xy\"}, {\"type\": \"polar\"}],\n           [{\"type\": \"domain\"}, {\"type\": \"scene\"}]],\n)\n\nfig.add_trace(go.Bar(y=[2, 3, 1]),\n              row=1, col=1)\n\nfig.add_trace(go.Barpolar(theta=[0, 45, 90], r=[2, 3, 1]),\n              row=1, col=2)\n\nfig.add_trace(go.Pie(values=[2, 3, 1]),\n              row=2, col=1)\n\nfig.add_trace(go.Scatter3d(x=[2, 3, 1], y=[0, 0, 0],\n                           z=[0.5, 1, 2], mode=\"lines\"),\n              row=2, col=2)\n\nfig.update_layout(height=700, showlegend=False)\n\nfig.show()"
  },
  {
    "objectID": "posts/visualization/plotly_visualization/ploty 시각화 모음.html#vector-fieldquiver-plot",
    "href": "posts/visualization/plotly_visualization/ploty 시각화 모음.html#vector-fieldquiver-plot",
    "title": "plotly 시각화 모음",
    "section": "Vector field(quiver plot)",
    "text": "Vector field(quiver plot)\n\n사전준비\n\nnp.meshgrid : x좌표,y좌표를 가지는 벡터를 입력했을때, 두 벡터로 만들 수 있는 격자의 좌표(x,y)를 출력\n\n\n\nCode\nimport numpy as np\nx_coord = np.arange(0,2,.2)\ny_coord = np.arange(0,2,.2)\nx,y = np.meshgrid(np.arange(0,2,.2),np.arange(0,2,.2))\nprint(x_coord.shape,y_coord.shape)\nprint(x.shape,y.shape)\n\n\n(10,) (10,)\n(10, 10) (10, 10)\n\n\n\n격자(grid,matrix)에 함수 적용하면? => matrix(x,y 각각의 좌표)의 모든 요소에 함수가 적용됨\n\n\n\nCode\nprint(np.cos(x).shape,np.sin(x).shape)\n\n\n(10, 10) (10, 10)\n\n\n\n배열의 요소 값 차례대로 읽어보기 …\n\n(0,0),(0.2,0),(0.4,0) … (1.8,0) => (0,0.2),(0.2,0.2),(0.4,0.2)… x좌표 다 읽고 y좌표증가 그 다음 x좌표 다 읽고 y좌표 증가 …\n\n\nCode\nx,y\n\n\n(array([[0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8],\n        [0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8]]),\n array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n        [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4],\n        [0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6],\n        [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],\n        [1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ],\n        [1.2, 1.2, 1.2, 1.2, 1.2, 1.2, 1.2, 1.2, 1.2, 1.2],\n        [1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4],\n        [1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6],\n        [1.8, 1.8, 1.8, 1.8, 1.8, 1.8, 1.8, 1.8, 1.8, 1.8]]))\n\n\n\n\nGradient Vector Field\n\n\\(\\nabla f = xe^{-x^2-y^2}\\)\n\n\nCode\n#1.prepare data\nx,y = np.meshgrid(np.arange(-2,2,0.2),np.arange(-2,2,.25)) #좌표\nz = x*np.exp(-x**2-y**2) #함수\n\ndx=0.2;dy=0.25 #dx,dy\nv,u = np.gradient(z,dx,dy) #함수의 그레디언트(각좌표에서의 미분계수)\n\n\n\n\nCode\n#2.trace and data => 생략\n#3.fig\nfig = ff.create_quiver(x,y,u,v,scale=.25,arrow_scale=.4,name=\"quiver\",line_width=1)\nfig.add_trace(go.Scatter(x=[-.7,.75],y=[0,0],\n                         mode=\"markers\",\n                         marker_size=12,\n                         name=\"points\"))\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nx = np.linspace(-1,1,100)\ny = np.linspace(-1,1,100)\nxx,yy = np.meshgrid(x,y)\nfor i in range()\n\n\n(array([[-1.        , -0.97979798, -0.95959596, ...,  0.95959596,\n          0.97979798,  1.        ],\n        [-1.        , -0.97979798, -0.95959596, ...,  0.95959596,\n          0.97979798,  1.        ],\n        [-1.        , -0.97979798, -0.95959596, ...,  0.95959596,\n          0.97979798,  1.        ],\n        ...,\n        [-1.        , -0.97979798, -0.95959596, ...,  0.95959596,\n          0.97979798,  1.        ],\n        [-1.        , -0.97979798, -0.95959596, ...,  0.95959596,\n          0.97979798,  1.        ],\n        [-1.        , -0.97979798, -0.95959596, ...,  0.95959596,\n          0.97979798,  1.        ]]),\n array([[-1.        , -1.        , -1.        , ..., -1.        ,\n         -1.        , -1.        ],\n        [-0.97979798, -0.97979798, -0.97979798, ..., -0.97979798,\n         -0.97979798, -0.97979798],\n        [-0.95959596, -0.95959596, -0.95959596, ..., -0.95959596,\n         -0.95959596, -0.95959596],\n        ...,\n        [ 0.95959596,  0.95959596,  0.95959596, ...,  0.95959596,\n          0.95959596,  0.95959596],\n        [ 0.97979798,  0.97979798,  0.97979798, ...,  0.97979798,\n          0.97979798,  0.97979798],\n        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n          1.        ,  1.        ]]))\n\n\n\n\n\n1. 시점\n\n종점은 화살표로 표시해야 하므로 시점만 만들기\n\n\n\nCode\nimport plotly.graph_objs as go\n\n\n\n\nCode\n#1. prepare data\n\n#첫번째 벡터의 시점 x[0],y[0],z[0] 종점 x[1],y[1],z[1]\n#두번째 벡터의 시점 x[2],y[2],z[2] 종점 x[2],y[2],z[2]\n#두 개씩 묶임\nx = [10.1219, 10.42579, 15.21396, 15.42468, 20.29639,20.46268, 25.36298, 25.49156]\ny = [5.0545,  5.180104, 5.0545,   5.20337,  5.0545,  5.194271, 5.0545,   5.231627]\nz = [5.2713,  5.231409, 5.2713,   5.231409, 5.2713 ,  5.235852,  5.2713, 5.231627]\n#pairs = [(0,1),(2,3),(4,5),(6,7)]\n[coord for coord in range(0,len(x),2)]\n\n\n[0, 2, 4, 6]\n\n\n\n\nCode\n#2. trace,data(trace set)\ntrace1 = go.Scatter3d(\n    x=[x[coord] for coord in range(0,len(x),2)],\n    y=[y[coord] for coord in range(0,len(y),2)],\n    z=[z[coord] for coord in range(0,len(z),2)],\n    mode = \"markers\",\n    line=dict(color=\"red\")\n)\ndata = [trace1]\n\n#3. Layout\nlayout = go.Layout(title=dict(text = \"vectors\"))\n\n#4. figure\nfig = go.Figure(data=data,layout=layout)\nfig.show()\n\n\n\n                                                \n\n\n\n\n2. 선 만들기\n\n\nCode\n#1.prepare data\nx_lines = list()\ny_lines = list()\nz_lines = list()\n\nfor i in range(len(x)):\n    x_lines.append(x[i])\n    y_lines.append(y[i])\n    z_lines.append(z[i])\n    #plotly에서 Scatter의 line mode는 점과 점 사이에 선을 만듦\n    #0,1번째 자리의 좌표에는 시점,종점을 넣고 3번째 자리에 None을 추가하여 점을 만들지 않음 \n    #따라서, 선이 생기지 않음\n    if i % 2 == 1:    \n        x_lines.append(None)\n        y_lines.append(None)\n        z_lines.append(None)\n\n#2.trace and tr_set(=data)\ntrace2 = go.Scatter3d(\n    x=x_lines,\n    y=y_lines,\n    z=z_lines,\n    mode = \"lines\",\n    line = dict(width = 2, color = 'rgb(255, 0,0)')\n)\ndata = [trace2]\n\n#3.layout\nlayout = go.Layout(title = \"lines\")\n#4.figure\nfig = go.Figure(data=data,layout=layout)\n#5.plotting\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\n#중간체크\ndata = [trace1,trace2]\n\n#3.layout\nlayout = go.Layout(title = \"lines\")\n#4.figure\nfig = go.Figure(data=data,layout=layout)\n#5.plotting\nfig.show()\n\n\n\n                                                \n\n\n\n\n3.종점 만들기\n\n\nCode\ndata = [trace1,trace2]\n\n#3.layout\nlayout = go.Layout(title = \"lines\")\n#4.figure\nfig = go.Figure(data=data,layout=layout)\n#5.plotting\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nimport plotly.graph_objs as go\n# plotly.offline.init_notebook_mode()\n\nx = [10.1219, 10.42579, 15.21396, 15.42468, 20.29639,20.46268, 25.36298, 25.49156]\ny = [5.0545,  5.180104, 5.0545,   5.20337,  5.0545,  5.194271, 5.0545,   5.231627]\nz = [5.2713,  5.231409, 5.2713,   5.231409, 5.2713 ,  5.235852,  5.2713, 5.231627]\n\npairs = [(0,1), (2,3),(4,5), (6,7)]\n\n## plot ONLY the first ball in each pair of balls\ntrace1 = go.Scatter3d(\n    x=[x[p[0]] for p in pairs],\n    y=[y[p[0]] for p in pairs],\n    z=[z[p[0]] for p in pairs],\n    mode='markers',\n    name='markers',\n    line=dict(color='red')\n)\n\ngo.Figure(data=trace1)"
  },
  {
    "objectID": "posts/paper study/auto-encoding variational bayes/Auto-Encoding Variational Bayes.html",
    "href": "posts/paper study/auto-encoding variational bayes/Auto-Encoding Variational Bayes.html",
    "title": "Auto-Encoding Variational Bayes",
    "section": "",
    "text": "Problem Setting\nBayesian Neural Network는 parameter와 output의 분포그 자체를 구해내고자 하는 것이 목적이다. 분포를 구한다면 모델의 예측이 얼마나 믿을만한지,얼마나 불확실한지를 알 수 있다는 장점이 있기 때문이다.\n\n이 과정에서 파라미터에 대한 posterior(사후확률분포)를 구하게 되는데 문제는 여기서 발생한다.\n\\[\\begin{aligned}\np(z|x) = \\frac{p(x|{z})p(x)}{p(x)} = \\frac{p(x|z)p(x)}{\\int p(x|z)p(x)dz}\n\\end{aligned}\\]\n\n\\(z\\)는 latent variable로 숨겨져 있으며(이러한 의미에서 hidden variable이라고도 한다.) 관측가능한 변수인 \\(x\\)의 값에 영향을 미치는 확률변수(random variable)이다. observed data로부터 계산을 통해서만 구할 수 있으며 Bayesian Nueral Network에서는 \\(w\\)이다.\n\n분모의 likelyhood와 prior는 MAP나 ML에서와 마찬가지로 우리가 알고있는 비교적 계산이 편리한 분포로 주로 가정한다. 하지만 분모는 수많은 weight에 대한 다중적분이기 때문에 계산하기가 매우 어렵다. 따라서 posterior를 근사적으로 구할 수 있는 방법들이 여러가지가 연구되었으며 Variational Inference는 이 중 한가지 방법이다.\n\n\nMethod\nVariational Inference에서는 posterior를 근사적으로 구하기 위해 \\(z\\)에 또다른 분포 \\(q(z|x)\\)를 먼저 가정한 후 이러한 분포를 true posterior에 점점 다가가게 한다. 두 분포가 차이가 거의 없을정도로 충분히 가까워진다면 \\(q(z|x)\\)를 true posterior 대신에 사용한다.\n두 분포간의 차이는 KL-divergence를 통해 구할 수 있으며 다음과 같다.\n\\[\\begin{aligned}\n\\text{D}_{KL}[q(z|x)||p_{\\theta}(z|x)]\n\\end{aligned}\\]"
  }
]